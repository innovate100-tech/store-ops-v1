"""
Supabase ê¸°ë°˜ ì €ì¥ì†Œ ëª¨ë“ˆ (ê¸°ì¡´ storage.pyì˜ DB ë²„ì „)
auth.uid() ê¸°ë°˜ RLSë¡œ ë³´ì•ˆ ì ìš©
"""
import pandas as pd
import logging
from datetime import datetime, timezone
from typing import Optional, List, Tuple
import json
from zoneinfo import ZoneInfo
from src.utils.time_utils import now_kst, today_kst, current_year_kst, current_month_kst

# auth.pyì—ì„œ í•¨ìˆ˜ import (is_dev_modeëŠ” _is_dev_modeë¡œ aliasí•˜ì—¬ ì´ë¦„ ì¶©ëŒ ë°©ì§€)
from src.auth import get_supabase_client, get_current_store_id, get_read_client, get_read_client_mode, is_dev_mode as _is_dev_mode
import streamlit as st
import time
from functools import wraps

# boot_perfì—ì„œ ë°ì´í„° í˜¸ì¶œ ê³„ì¸¡ í•¨ìˆ˜ import
try:
    from src.utils.boot_perf import record_data_call
except ImportError:
    # boot_perfê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„í•œ fallback
    def record_data_call(name: str, ms: float, rows: int = None, source: str = None):
        pass

# cache_tokensì—ì„œ ë²„ì „ í† í° í•¨ìˆ˜ import
try:
    from src.utils.cache_tokens import bump_data_version, bump_versions
except ImportError:
    # cache_tokensê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„í•œ fallback
    def bump_data_version(name: str):
        pass
    def bump_versions(names: List[str]):
        pass

logger = logging.getLogger(__name__)

# ì¿¼ë¦¬ íƒ€ì´ë° ë¡œê·¸ ì €ì¥ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
_query_timing_log = []
_MAX_QUERY_LOG = 50  # ìµœëŒ€ ì €ì¥í•  ì¿¼ë¦¬ ë¡œê·¸ ê°œìˆ˜

# ìºì‹œ MISS ë¡œê·¸ ì €ì¥ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
_cache_miss_log = []
_MAX_CACHE_LOG = 50  # ìµœëŒ€ ì €ì¥í•  ìºì‹œ MISS ë¡œê·¸ ê°œìˆ˜


def setup_logger():
    """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
    if not logger.handlers:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
    return logger


setup_logger()


# ============================================
# Client Mode & Query Timing Functions
# ============================================

def get_client_mode() -> str:
    """
    í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ DB í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ ë°˜í™˜
    
    Returns:
        "anon" / "auth" / "service_role_dev"
    """
    try:
        return get_read_client_mode()
    except Exception:
        return "unknown"


def timed_select(query_name: str, query_func, *args, **kwargs):
    """
    Supabase select ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  íƒ€ì´ë°ì„ ê¸°ë¡í•˜ëŠ” í—¬í¼
    
    Args:
        query_name: ì¿¼ë¦¬ ì´ë¦„ (ë¡œê·¸ì— í‘œì‹œë  ì´ë¦„)
        query_func: ì‹¤í–‰í•  ì¿¼ë¦¬ í•¨ìˆ˜ (ì˜ˆ: lambda: supabase.table("menu_master").select("*").execute())
        *args, **kwargs: query_funcì— ì „ë‹¬í•  ì¸ì
    
    Returns:
        ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼
    """
    global _query_timing_log  # í•¨ìˆ˜ ìµœìƒë‹¨ì— global ì„ ì–¸
    start_time = time.time()
    try:
        result = query_func(*args, **kwargs)
        elapsed_ms = (time.time() - start_time) * 1000
        row_count = len(result.data) if result.data else 0
        
        # ê°œë°œëª¨ë“œì—ì„œë§Œ ë¡œê·¸ ì €ì¥
        if _is_dev_mode():
            _query_timing_log.append({
                "query_name": query_name,
                "ms": round(elapsed_ms, 2),
                "rows": row_count,
                "timestamp": time.time()
            })
            # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
            if len(_query_timing_log) > _MAX_QUERY_LOG:
                _query_timing_log[:] = _query_timing_log[-_MAX_QUERY_LOG:]
        
        logger.debug(f"Query '{query_name}': {elapsed_ms:.2f}ms, {row_count} rows")
        return result
    except Exception as e:
        elapsed_ms = (time.time() - start_time) * 1000
        logger.error(f"Query '{query_name}' failed after {elapsed_ms:.2f}ms: {e}")
        if _is_dev_mode():
            _query_timing_log.append({
                "query_name": f"{query_name} (ERROR)",
                "ms": round(elapsed_ms, 2),
                "rows": 0,
                "timestamp": time.time(),
                "error": str(e)
            })
        raise


def get_query_timing_log() -> list:
    """
    ì¿¼ë¦¬ íƒ€ì´ë° ë¡œê·¸ ë°˜í™˜ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
    
    Returns:
        ìµœê·¼ ì¿¼ë¦¬ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
    """
    if _is_dev_mode():
        return _query_timing_log.copy()
    return []


def clear_query_timing_log():
    """ì¿¼ë¦¬ íƒ€ì´ë° ë¡œê·¸ ì´ˆê¸°í™”"""
    global _query_timing_log
    _query_timing_log = []


def _log_cache_miss(function_name: str, **kwargs):
    """
    ìºì‹œ MISS ë¡œê·¸ ê¸°ë¡ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
    
    Args:
        function_name: í•¨ìˆ˜ ì´ë¦„ (ì˜ˆ: "load_csv", "load_expense_structure")
        **kwargs: ìºì‹œ í‚¤ì— í¬í•¨ëœ íŒŒë¼ë¯¸í„°ë“¤ (filename, store_id, client_mode, year, month ë“±)
    """
    try:
        if _is_dev_mode():
            global _cache_miss_log
            # ë¯¼ê° ì •ë³´ ì œê±°
            safe_kwargs = {}
            for key, value in kwargs.items():
                if key in ['store_id', 'client_mode', 'filename', 'year', 'month']:
                    # store_idëŠ” ì¼ë¶€ë§Œ í‘œì‹œ (ë³´ì•ˆ)
                    if key == 'store_id' and value:
                        safe_kwargs[key] = f"{str(value)[:8]}..." if len(str(value)) > 8 else str(value)
                    else:
                        safe_kwargs[key] = value
            
            _cache_miss_log.append({
                "function": function_name,
                "timestamp": time.time(),
                "params": safe_kwargs
            })
            # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
            if len(_cache_miss_log) > _MAX_CACHE_LOG:
                _cache_miss_log = _cache_miss_log[-_MAX_CACHE_LOG:]
    except Exception:
        pass  # ë¡œê·¸ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰


def get_cache_miss_log() -> list:
    """
    ìºì‹œ MISS ë¡œê·¸ ë°˜í™˜ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
    
    Returns:
        ìµœê·¼ ìºì‹œ MISS ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
    """
    if _is_dev_mode():
        return _cache_miss_log.copy()
    return []


def clear_cache_miss_log():
    """ìºì‹œ MISS ë¡œê·¸ ì´ˆê¸°í™”"""
    global _cache_miss_log
    _cache_miss_log = []


# ============================================
# Helper Functions
# ============================================

def _get_id_by_name(supabase, table_name: str, name_column: str, name_value: str, store_id: str = None):
    """
    ì´ë¦„ìœ¼ë¡œ ID ì¡°íšŒ (ê³µí†µ í—¬í¼ í•¨ìˆ˜)
    
    Args:
        supabase: Supabase í´ë¼ì´ì–¸íŠ¸
        table_name: í…Œì´ë¸”ëª…
        name_column: ì´ë¦„ ì»¬ëŸ¼ëª… (ì˜ˆ: 'name')
        name_value: ì¡°íšŒí•  ì´ë¦„ ê°’
        store_id: store_id í•„í„° (Noneì´ë©´ ì‚¬ìš© ì•ˆ í•¨)
    
    Returns:
        str: ID (ì—†ìœ¼ë©´ None)
    """
    try:
        query = supabase.table(table_name).select("id")
        if store_id:
            query = query.eq("store_id", store_id)
        query = query.eq(name_column, name_value)
        # timed_selectë¡œ ì¿¼ë¦¬ ì‹¤í–‰ ë° íƒ€ì´ë° ê¸°ë¡
        result = timed_select(
            f"_get_id_by_name({table_name}.{name_column}={name_value})",
            lambda: query.execute()
        )
        if result.data:
            return result.data[0]['id']
        return None
    except Exception as e:
        logger.error(f"Failed to get ID for {table_name}.{name_column}={name_value}: {e}")
        return None


def _check_duplicate(supabase, table_name: str, name_column: str, name_value: str, store_id: str):
    """
    ì¤‘ë³µ ì²´í¬ (ê³µí†µ í—¬í¼ í•¨ìˆ˜)
    
    Args:
        supabase: Supabase í´ë¼ì´ì–¸íŠ¸
        table_name: í…Œì´ë¸”ëª…
        name_column: ì´ë¦„ ì»¬ëŸ¼ëª…
        name_value: ì²´í¬í•  ì´ë¦„ ê°’
        store_id: store_id
    
    Returns:
        bool: ì¤‘ë³µì´ë©´ True
    """
    try:
        query = supabase.table(table_name).select("id").eq("store_id", store_id).eq(name_column, name_value)
        # timed_selectë¡œ ì¿¼ë¦¬ ì‹¤í–‰ ë° íƒ€ì´ë° ê¸°ë¡
        result = timed_select(
            f"_check_duplicate({table_name}.{name_column}={name_value})",
            lambda: query.execute()
        )
        return len(result.data) > 0
    except Exception:
        return False


def _check_supabase_for_dev_mode():
    """
    Supabase í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜ (ì—ëŸ¬ ì²˜ë¦¬)
    
    DEV MODE(st.session_state['dev_mode'] == True)ì—ì„œëŠ”
    Supabaseë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Noneì„ ë°˜í™˜í•˜ê³ ,
    í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ì´ë¥¼ ê°ì§€í•´ ë¡œì»¬/ë¹ˆ ë°ì´í„°ë¡œ ì²˜ë¦¬í•˜ê²Œ í•œë‹¤.
    """
    # DEV MODEì—ì„œëŠ” Supabaseë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    if st.session_state.get("dev_mode", False):
        logger.info("DEV MODE: Supabase client is disabled (returning None).")
        return None
    
    supabase = get_supabase_client()
    if not supabase:
        raise Exception("Supabase not available")
    return supabase


# ============================================
# Session Cache Utilities (ì„¸ì…˜ ìºì‹œ ìœ í‹¸)
# ============================================

def get_session_df(key: str, loader_fn, *args, **kwargs):
    """
    ì„¸ì…˜ ìºì‹œ ê¸°ë°˜ ë°ì´í„° ë¡œë“œ ìœ í‹¸
    ì„¸ì…˜ë‹¹ 1íšŒë§Œ ë¡œë“œí•˜ì—¬ ì¤‘ë³µ ë¡œë“œë¥¼ ì›ì²œ ì°¨ë‹¨
    
    Args:
        key: ì„¸ì…˜ ìºì‹œ í‚¤ (ì˜ˆ: "ss_menu_master_df")
        loader_fn: ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ì˜ˆ: load_csv)
        *args, **kwargs: loader_fnì— ì „ë‹¬í•  ì¸ì
    
    Returns:
        pandas.DataFrame
    """
    # ì„¸ì…˜ ìºì‹œì— ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜ (ë Œë” ì¤‘ ë§¤ë²ˆ ë®ì–´ì“°ê¸° ë°©ì§€)
    if key in st.session_state:
        if _is_dev_mode():
            logger.debug(f"Session cache HIT: {key}")
        return st.session_state[key]
    
    # ì„¸ì…˜ ìºì‹œì— ì—†ìœ¼ë©´ ë¡œë“œ í›„ ì €ì¥ (ì—†ì„ ë•Œë§Œ 1íšŒ ì„¸íŒ…)
    if _is_dev_mode():
        logger.debug(f"Session cache MISS: {key} (ë¡œë”© ì¤‘...)")
    
    try:
        df = loader_fn(*args, **kwargs)
        # ë Œë” ì¤‘ ë§¤ë²ˆ ë®ì–´ì“°ê¸° ë°©ì§€: ì—†ì„ ë•Œë§Œ ì €ì¥
        if key not in st.session_state:
            st.session_state[key] = df
            if _is_dev_mode():
                logger.debug(f"Session cache SET: {key} ({len(df)} rows)")
        return df
    except Exception as e:
        logger.error(f"Session cache load failed for {key}: {e}")
        # ì˜¤ë¥˜ ì‹œ ë¹ˆ DataFrame ë°˜í™˜ (ì—†ì„ ë•Œë§Œ ì €ì¥)
        empty_df = pd.DataFrame()
        if key not in st.session_state:
            st.session_state[key] = empty_df
        return empty_df


def clear_session_cache(*keys: str):
    """
    ì„¸ì…˜ ìºì‹œ ë¬´íš¨í™” (ì €ì¥/ìˆ˜ì •/ì‚­ì œ í›„ í˜¸ì¶œ)
    
    Args:
        *keys: ì‚­ì œí•  ì„¸ì…˜ ìºì‹œ í‚¤ë“¤ (ì˜ˆ: "ss_menu_master_df", "ss_ingredient_master_df")
    """
    for key in keys:
        if key in st.session_state:
            del st.session_state[key]
            if _is_dev_mode():
                logger.debug(f"Session cache CLEARED: {key}")


def hard_clear_all(reason: str = "unknown"):
    """
    ì „ì²´ ìºì‹œ ê°•ì œ ë¬´íš¨í™” (ë¹„ìƒ/ë””ë²„ê¹…ìš©)
    
    Args:
        reason: clear ì´ìœ  (ë””ë²„ê¹…ìš©)
    """
    try:
        # @st.cache_data ìºì‹œ ì „ì²´ ë¬´íš¨í™”
        load_csv.clear()
        load_expense_structure.clear()
        load_key_menus.clear()
        
        # dashboard.pyì˜ compute ìºì‹œë„ ë¬´íš¨í™”
        try:
            import ui_pages.dashboard as dashboard_module
            if hasattr(dashboard_module, 'compute_merged_sales_visitors'):
                dashboard_module.compute_merged_sales_visitors.clear()
            if hasattr(dashboard_module, 'compute_monthly_summary'):
                dashboard_module.compute_monthly_summary.clear()
            if hasattr(dashboard_module, 'compute_menu_sales_summary'):
                dashboard_module.compute_menu_sales_summary.clear()
        except Exception:
            pass
        
        # ì„¸ì…˜ ìºì‹œ ì „ì²´ ì •ë¦¬ (ss_ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ë“¤)
        keys_to_remove = [key for key in st.session_state.keys() if key.startswith('ss_')]
        for key in keys_to_remove:
            del st.session_state[key]
        
        # LAST_INVALIDATION ê¸°ë¡
        try:
            from src.utils.boot_perf import record_invalidation
            record_invalidation(reason=reason, targets=["ALL"], mode="hard")
        except Exception:
            pass
        
        if _is_dev_mode():
            logger.warning(f"HARD CLEAR ALL: {reason}")
    except Exception as e:
        logger.error(f"hard_clear_all ì‹¤íŒ¨: {e}")


def soft_invalidate(reason: str, targets: List[str], session_keys: List[str] = None):
    """
    ì†Œí”„íŠ¸ ë¬´íš¨í™”: token bump + ë¶€ë¶„ ìºì‹œ clear
    
    Args:
        reason: ë¬´íš¨í™” ì´ìœ  (ë””ë²„ê¹…ìš©)
        targets: ë¬´íš¨í™”í•  ë°ì´í„° íƒ€ì… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["sales", "visitors", "menus"])
        session_keys: ë¬´íš¨í™”í•  ì„¸ì…˜ ìºì‹œ í‚¤ ë¦¬ìŠ¤íŠ¸ (ì„ íƒ, Noneì´ë©´ targets ê¸°ë°˜ìœ¼ë¡œ ìë™ ê²°ì •)
    """
    try:
        # 1. ë²„ì „ í† í° ì¦ê°€
        from src.utils.cache_tokens import bump_versions
        bump_versions(targets)
        
        # 2. read ìºì‹œ ë¶€ë¶„ clear (targets ê¸°ë°˜)
        # targets ë§¤í•‘: ì–´ë–¤ ë°ì´í„° íƒ€ì…ì´ ì–´ë–¤ ë¡œë”ì— ì˜í–¥ì„ ì£¼ëŠ”ì§€
        cache_mapping = {
            "sales": ["load_csv"],  # sales.csv
            "visitors": ["load_csv"],  # naver_visitors.csv
            "menus": ["load_csv"],  # menu_master.csv
            "recipes": ["load_csv"],  # recipes.csv
            "ingredients": ["load_csv"],  # ingredient_master.csv
            "cost": ["load_expense_structure"],  # expense_structure
            "expense_structure": ["load_expense_structure"],
        }
        
        loaders_to_clear = set()
        for target in targets:
            if target in cache_mapping:
                loaders_to_clear.update(cache_mapping[target])
        
        # ì‹¤ì œ clear ì‹¤í–‰
        if "load_csv" in loaders_to_clear:
            load_csv.clear()
        if "load_expense_structure" in loaders_to_clear:
            load_expense_structure.clear()
        if "load_key_menus" in loaders_to_clear or "menus" in targets:
            load_key_menus.clear()
        
        # 3. ì„¸ì…˜ ìºì‹œ ë¶€ë¶„ clear
        if session_keys is None:
            # targets ê¸°ë°˜ìœ¼ë¡œ ìë™ ê²°ì •
            session_key_mapping = {
                "sales": ["ss_sales_df"],
                "visitors": ["ss_visitors_df"],
                "menus": ["ss_menu_master_df"],
                "recipes": ["ss_recipes_df"],
                "ingredients": ["ss_ingredient_master_df"],
                "cost": ["ss_expense_structure_df"],
                "expense_structure": ["ss_expense_structure_df"],
                "inventory": ["ss_inventory_df"],
            }
            session_keys = []
            for target in targets:
                if target in session_key_mapping:
                    session_keys.extend(session_key_mapping[target])
        
        for key in session_keys:
            if key in st.session_state:
                del st.session_state[key]
                if _is_dev_mode():
                    logger.debug(f"Session cache CLEARED: {key}")
        
        # 4. LAST_INVALIDATION ê¸°ë¡
        try:
            from src.utils.boot_perf import record_invalidation
            record_invalidation(reason=reason, targets=targets, mode="soft")
        except Exception:
            pass
        
        if _is_dev_mode():
            logger.info(f"SOFT INVALIDATE: {reason}, targets={targets}")
    except Exception as e:
        logger.error(f"soft_invalidate ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ì•ˆì „ì„ ìœ„í•´ hard clearë¡œ í´ë°± (dev_modeì—ì„œë§Œ)
        if _is_dev_mode() and st.session_state.get("force_hard_clear", False):
            hard_clear_all(reason=f"soft_invalidate ì‹¤íŒ¨ í›„ í´ë°±: {reason}")


def _clear_cache_and_session(affected_keys: List[str]):
    """
    ìºì‹œ í´ë¦¬ì–´ ë° ì„¸ì…˜ ìºì‹œ ë¬´íš¨í™” í—¬í¼ í•¨ìˆ˜ (ë ˆê±°ì‹œ í˜¸í™˜)
    
    Args:
        affected_keys: ë¬´íš¨í™”í•  ì„¸ì…˜ ìºì‹œ í‚¤ ë¦¬ìŠ¤íŠ¸
    """
    # force_hard_clear í”Œë˜ê·¸ í™•ì¸ (dev_modeì—ì„œë§Œ)
    if _is_dev_mode() and st.session_state.get("force_hard_clear", False):
        hard_clear_all(reason="force_hard_clear í”Œë˜ê·¸ í™œì„±í™”")
        return
    
    # ê¸°ë³¸ ë™ì‘: soft_invalidateë¡œ ì „í™˜
    # affected_keysì—ì„œ targets ì¶”ë¡  (í‚¤ ì´ë¦„ ê¸°ë°˜)
    targets = []
    if any("menu" in key.lower() for key in affected_keys):
        targets.append("menus")
    if any("recipe" in key.lower() for key in affected_keys):
        targets.append("recipes")
    if any("ingredient" in key.lower() for key in affected_keys):
        targets.append("ingredients")
    if any("expense" in key.lower() for key in affected_keys):
        targets.append("cost")
        targets.append("expense_structure")
    
    if targets:
        soft_invalidate(reason="ë ˆê±°ì‹œ _clear_cache_and_session í˜¸ì¶œ", targets=targets, session_keys=affected_keys)
    else:
        # targetsë¥¼ ì¶”ë¡ í•  ìˆ˜ ì—†ìœ¼ë©´ ì•ˆì „ì„ ìœ„í•´ hard clear (dev_modeì—ì„œë§Œ ê²½ê³ )
        if _is_dev_mode():
            logger.warning(f"_clear_cache_and_session: targets ì¶”ë¡  ì‹¤íŒ¨, hard clear ì‹¤í–‰. affected_keys={affected_keys}")
        hard_clear_all(reason="targets ì¶”ë¡  ì‹¤íŒ¨")


def invalidate_read_caches(table_name: str = None):
    """
    ì½ê¸° ì „ìš© ìºì‹œ ë¬´íš¨í™” (write í›„ í˜¸ì¶œ)
    
    Args:
        table_name: ë¬´íš¨í™”í•  í…Œì´ë¸”ëª… (Noneì´ë©´ ì „ì²´ ë¬´íš¨í™”)
    """
    try:
        if table_name is None:
            # ì „ì²´ ìºì‹œ ë¬´íš¨í™”
            load_csv.clear()
            load_expense_structure.clear()
            load_key_menus.clear()
        else:
            # íŠ¹ì • í…Œì´ë¸”ë§Œ ë¬´íš¨í™” (í•„ìš”ì‹œ êµ¬í˜„)
            # í˜„ì¬ëŠ” ì „ì²´ ë¬´íš¨í™”ë§Œ ì§€ì›
            load_csv.clear()
            load_expense_structure.clear()
            load_key_menus.clear()
        
        # dashboard.pyì˜ compute ìºì‹œë„ ë¬´íš¨í™”
        try:
            import ui_pages.dashboard as dashboard_module
            if hasattr(dashboard_module, 'compute_merged_sales_visitors'):
                dashboard_module.compute_merged_sales_visitors.clear()
            if hasattr(dashboard_module, 'compute_monthly_summary'):
                dashboard_module.compute_monthly_summary.clear()
            if hasattr(dashboard_module, 'compute_menu_sales_summary'):
                dashboard_module.compute_menu_sales_summary.clear()
        except Exception:
            pass  # dashboard ëª¨ë“ˆì´ ì—†ê±°ë‚˜ í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ ë¬´ì‹œ
    except Exception:
        pass


# ============================================
# Load Functions (CSV í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€)
# ============================================

# Phase 2: ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ - ë°ì´í„° íƒ€ì…ë³„ TTL ë¶„ë¦¬
def _get_cache_ttl(filename: str) -> int:
    """
    íŒŒì¼ëª…ì— ë”°ë¼ ì ì ˆí•œ ìºì‹œ TTL ë°˜í™˜
    
    - ë§ˆìŠ¤í„° ë°ì´í„° (ë©”ë‰´, ì¬ë£Œ): 3600ì´ˆ (1ì‹œê°„) - ìì£¼ ë³€ê²½ë˜ì§€ ì•ŠìŒ
    - íŠ¸ëœì­ì…˜ ë°ì´í„° (ë§¤ì¶œ, ë°©ë¬¸ì): 60ì´ˆ (1ë¶„) - ìì£¼ ë³€ê²½ë¨
    - ì¤‘ê°„ ë°ì´í„° (ì¬ê³ , ë°œì£¼): 300ì´ˆ (5ë¶„) - ì¤‘ê°„ ë¹ˆë„
    """
    master_data = ['menu_master.csv', 'ingredient_master.csv', 'recipes.csv', 'suppliers.csv']
    transaction_data = ['sales.csv', 'naver_visitors.csv', 'daily_sales_items.csv']
    
    if filename in master_data:
        return 3600  # 1ì‹œê°„
    elif filename in transaction_data:
        return 60    # 1ë¶„
    else:
        return 300   # 5ë¶„ (ê¸°ë³¸ê°’)

# Phase 3: ìºì‹œ ì „ëµ ê°œì„ 
# Streamlitì˜ @st.cache_dataëŠ” ë°ì½”ë ˆì´í„° ë ˆë²¨ì—ì„œë§Œ TTLì„ ì„¤ì •í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
# íŒŒì¼ëª…ì— ë”°ë¼ ì ì ˆí•œ TTLì„ ì‚¬ìš©í•˜ë„ë¡ ì£¼ì„ìœ¼ë¡œ ê°€ì´ë“œ ì œê³µ
# ì‹¤ì œ êµ¬í˜„ì€ ê¸°ì¡´ load_csv í•¨ìˆ˜ë¥¼ ìœ ì§€í•˜ë˜, TTLì„ 300ì´ˆ(5ë¶„)ë¡œ ì¡°ì •í•˜ì—¬ ê· í˜• ìœ ì§€

def _load_csv_impl(filename: str, store_id: str, client_mode: str, default_columns: Optional[List[str]] = None):
    """
    ìºì‹œëœ load_csv ë‚´ë¶€ êµ¬í˜„ (store_idì™€ client_modeë¥¼ ìºì‹œ í‚¤ì— í¬í•¨)
    ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ë©´ ìºì‹œ MISSì„ì„ ì˜ë¯¸
    """
    # ë°ì´í„° í˜¸ì¶œ ê³„ì¸¡ ì‹œì‘
    start_time = time.perf_counter()
    
    # ìºì‹œ MISS ë¡œê·¸ ê¸°ë¡ (ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ì—ˆë‹¤ëŠ” ê²ƒì€ ìºì‹œê°€ MISSì˜€ë‹¤ëŠ” ì˜ë¯¸)
    _log_cache_miss("load_csv", filename=filename, store_id=store_id, client_mode=client_mode)
    
    # ê°€ë“œ: ì˜¨ë¼ì¸ì—ì„œëŠ” anonìœ¼ë¡œ read ê¸ˆì§€ (DEVì—ì„œë§Œ í—ˆìš©)
    if client_mode == "anon" and not _is_dev_mode():
        error_msg = f"âŒ ë³´ì•ˆ ìœ„ë°˜: ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ anon í´ë¼ì´ì–¸íŠ¸ë¡œ ë°ì´í„° ì¡°íšŒ ì‹œë„ (filename: {filename})"
        logger.error(error_msg)
        st.error(error_msg)
        st.warning("ğŸ’¡ ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”. ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_csv({filename}) [SECURITY_BLOCK]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    # Supabase ì¡°íšŒìš© í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (DEV MODEì—ì„œ service_role_key ì‚¬ìš© ê°€ëŠ¥)
    try:
        supabase = get_read_client()
    except Exception as e:
        logger.error(f"Supabase client init failed in load_csv('{filename}'): {e}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_csv({filename}) [ERROR]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()

    if not supabase:
        logger.warning(f"Supabase not available, returning empty DataFrame for {filename}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_csv({filename}) [NO_CLIENT]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    if not store_id:
        logger.warning(f"No store_id found, returning empty DataFrame for {filename}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_csv({filename}) [NO_STORE_ID]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    try:
        # CSV íŒŒì¼ëª… -> DB í…Œì´ë¸”ëª… ë§¤í•‘
        table_mapping = {
            'sales.csv': 'sales',
            'naver_visitors.csv': 'naver_visitors',
            'menu_master.csv': 'menu_master',
            'ingredient_master.csv': 'ingredients',
            'recipes.csv': 'recipes',
            'daily_sales_items.csv': 'daily_sales_items',
            'inventory.csv': 'inventory',
            'targets.csv': 'targets',
            'abc_history.csv': 'abc_history',
            'daily_close.csv': 'daily_close',
            'actual_settlement.csv': 'actual_settlement',
            # íŒŒì¼ëª… ì—†ì´ í…Œì´ë¸”ëª…ìœ¼ë¡œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥
            'sales': 'sales',
            'naver_visitors': 'naver_visitors',
            'menu_master': 'menu_master',
            'ingredient_master': 'ingredients',
            'recipes': 'recipes',
            'daily_sales_items': 'daily_sales_items',
            'inventory': 'inventory',
            'targets': 'targets',
            'abc_history': 'abc_history',
            'daily_close': 'daily_close',
            'actual_settlement': 'actual_settlement',
        }
        
        actual_table = table_mapping.get(filename, filename.replace('.csv', ''))
        
        # ëŒ€ìš©ëŸ‰ í…Œì´ë¸” í•„í„° ê¸°ë³¸ê°’ ê°•ì œ (ìµœê·¼ 90ì¼)
        large_tables = ['sales', 'daily_close', 'daily_sales_items', 'naver_visitors']
        use_date_filter = actual_table in large_tables
        
        # store_idë¡œ í•„í„°ë§í•˜ì—¬ ì¡°íšŒ (RLSê°€ ìë™ìœ¼ë¡œ ì ìš©ë¨)
        try:
            query = supabase.table(actual_table).select("*").eq("store_id", store_id)
            
            # ëŒ€ìš©ëŸ‰ í…Œì´ë¸”ì€ ìµœê·¼ 90ì¼ í•„í„° ê°•ì œ ì ìš©
            if use_date_filter:
                from datetime import timedelta
                cutoff_date = (now_kst() - timedelta(days=90)).date()
                query = query.gte("date", cutoff_date.isoformat())
            
            # ë””ë²„ê·¸: ì‹¤ì œ ì¿¼ë¦¬ ì •ë³´ ë¡œê¹… (ì˜¨ë¼ì¸ í™˜ê²½ ì§„ë‹¨ìš©)
            logger.info(f"load_csv({filename}): í…Œì´ë¸”={actual_table}, store_id={store_id}, use_date_filter={use_date_filter}")
            if use_date_filter:
                logger.info(f"load_csv({filename}): ë‚ ì§œ í•„í„° ì ìš© (cutoff_date={cutoff_date.isoformat()})")
            
            # timed_selectë¡œ ì¿¼ë¦¬ ì‹¤í–‰ ë° íƒ€ì´ë° ê¸°ë¡
            result = timed_select(
                f"load_csv({filename})",
                lambda: query.execute()
            )
            
            # ê²°ê³¼ ë¡œê¹…
            row_count = len(result.data) if result.data else 0
            logger.info(f"load_csv({filename}): ì¡°íšŒ ê²°ê³¼ {row_count}ê±´")
        except Exception as query_error:
            error_msg = str(query_error)
            logger.error(f"Query failed for {actual_table} (store_id: {store_id}): {error_msg}")
            
            # ê°œë°œ ëª¨ë“œì—ì„œë§Œ ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
            if _is_dev_mode():
                import streamlit as st
                with st.expander(f"âš ï¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {filename}", expanded=False):
                    st.error(f"**í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨:** {actual_table}")
                    st.caption(f"**Store ID:** {store_id}")
                    st.caption(f"**ì—ëŸ¬:** {error_msg}")
                    
                    # ì—ëŸ¬ íƒ€ì…ë³„ ì•ˆë‚´
                    if "RLS" in error_msg or "policy" in error_msg.lower() or "permission" in error_msg.lower():
                        st.warning("ğŸ’¡ **RLS ì •ì±… ë¬¸ì œ ê°€ëŠ¥ì„±**")
                        st.caption("RLS ì •ì±…ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                    elif "JWT" in error_msg or "token" in error_msg.lower() or "authentication" in error_msg.lower():
                        st.warning("ğŸ’¡ **ì¸ì¦ ë¬¸ì œ ê°€ëŠ¥ì„±**")
                        st.caption("ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ë¡œê·¸ì¸í•˜ì„¸ìš”.")
                    elif "network" in error_msg.lower() or "connection" in error_msg.lower():
                        st.warning("ğŸ’¡ **ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ ê°€ëŠ¥ì„±**")
                        st.caption("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
        
            # ë°ì´í„°ê°€ 0ê±´ì¸ ê²½ìš° ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œë„ í‘œì‹œ)
            if not result.data or len(result.data) == 0:
                # ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œë„ ì§„ë‹¨ ì •ë³´ í‘œì‹œ (í•­ìƒ í‘œì‹œ)
                import streamlit as st
                with st.expander(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {filename} (0ê±´)", expanded=True):
                    st.error(f"**í…Œì´ë¸”:** {actual_table}")
                    st.write(f"**Store ID:** `{store_id}`")
                    st.write("**ì‹¤í–‰ëœ ì¿¼ë¦¬:**")
                    if use_date_filter:
                        st.code(f"table('{actual_table}').select('*').eq('store_id', '{store_id}').gte('date', '{cutoff_date.isoformat()}')", language="python")
                    else:
                        st.code(f"table('{actual_table}').select('*').eq('store_id', '{store_id}')", language="python")
                    
                    st.write("**ê°€ëŠ¥í•œ ì›ì¸:**")
                    st.write("1. ì‹¤ì œë¡œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°")
                    st.write("2. RLS ì •ì±…ìœ¼ë¡œ ì¸í•´ ì ‘ê·¼ ë¶ˆê°€")
                    st.write("3. store_id í•„í„° ì¡°ê±´ ë¶ˆì¼ì¹˜")
                    st.write("4. ë¡œê·¸ì¸ ìƒíƒœ ë¬¸ì œ")
                    
                    # ì¶”ê°€ ì§„ë‹¨: í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (store_id í•„í„° ì—†ì´)
                    st.divider()
                    st.write("**ì¶”ê°€ ì§„ë‹¨: í•„í„° ì—†ì´ ì¡°íšŒ:**")
                    try:
                        # í•„í„° ì—†ì´ ì¡°íšŒ ì‹œë„
                        test_result = supabase.table(actual_table).select("*").limit(5).execute()
                        
                        if test_result.data:
                            test_count = len(test_result.data)
                            st.warning(f"âš ï¸ í…Œì´ë¸”ì—ëŠ” ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤ ({test_count}ê±´), í•˜ì§€ë§Œ store_id={store_id} ì¡°ê±´ìœ¼ë¡œëŠ” ì¡°íšŒë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                            
                            # ë°œê²¬ëœ store_id ëª©ë¡
                            store_ids_found = set([row.get('store_id') for row in test_result.data if row.get('store_id')])
                            st.write(f"**ë°œê²¬ëœ store_id ëª©ë¡:** {list(store_ids_found)}")
                            
                            if store_id not in store_ids_found:
                                st.error(f"âŒ í˜„ì¬ store_id(`{store_id}`)ê°€ ë°œê²¬ëœ store_id ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤!")
                                st.info("ğŸ’¡ í•´ê²° ë°©ë²•:")
                                st.info("1. ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸")
                                st.info("2. user_profiles í…Œì´ë¸”ì—ì„œ store_id í™•ì¸")
                                st.info("3. RLS ì •ì±… í™•ì¸")
                            
                            st.write("**ìƒ˜í”Œ ë°ì´í„° (í•„í„° ì—†ì´):**")
                            st.json(test_result.data[0])
                        else:
                            st.error("âŒ í•„í„° ì—†ì´ ì¡°íšŒí•´ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
                            st.warning("ğŸ’¡ ì´ê²ƒì€ RLS ì •ì±…ì´ ëª¨ë“  ë°ì´í„° ì ‘ê·¼ì„ ì°¨ë‹¨í•˜ê³  ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.")
                            st.info("**í™•ì¸ ì‚¬í•­:**")
                            st.info("1. Supabase Dashboard â†’ Authentication â†’ Policies")
                            st.info(f"2. `{actual_table}` í…Œì´ë¸”ì˜ SELECT ì •ì±… í™•ì¸")
                            st.info("3. RLS ì •ì±…ì´ í˜„ì¬ ì‚¬ìš©ì(`auth.uid()`)ì—ê²Œ ë°ì´í„° ì ‘ê·¼ì„ í—ˆìš©í•˜ëŠ”ì§€ í™•ì¸")
                            st.info("4. ì •ì±… ì˜ˆì‹œ:")
                            st.code("""
-- ì˜ˆì‹œ: store_id ê¸°ë°˜ RLS ì •ì±…
CREATE POLICY "Users can view their store data"
ON ingredients FOR SELECT
USING (
  store_id IN (
    SELECT store_id FROM user_profiles 
    WHERE id = auth.uid()
  )
);
                            """, language="sql")
                    except Exception as test_error:
                        error_msg = str(test_error)
                        st.error(f"âŒ í…Œì´ë¸” ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {type(test_error).__name__}: {error_msg}")
                        st.code(str(test_error), language="text")
                        
                        # RLS ê´€ë ¨ ì—ëŸ¬ í™•ì¸
                        if "permission" in error_msg.lower() or "policy" in error_msg.lower() or "RLS" in error_msg:
                            st.error("ğŸš¨ RLS ì •ì±… ë¬¸ì œë¡œ ë³´ì…ë‹ˆë‹¤!")
                            st.info("**í•´ê²° ë°©ë²•:**")
                            st.info(f"1. Supabase Dashboardì—ì„œ `{actual_table}` í…Œì´ë¸”ì˜ RLS ì •ì±… í™•ì¸")
                            st.info("2. SELECT ì •ì±…ì´ í•„ìš”í•©ë‹ˆë‹¤")
                            st.info("3. ì •ì±…ì—ì„œ `auth.uid()`ì™€ `store_id`ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤")
            
            # ë°ì´í„°ê°€ 0ê±´ì´ì–´ë„ ë¹ˆ DataFrame ë°˜í™˜
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            record_data_call(f"load_csv({filename})", elapsed_ms, rows=0, source="supabase")
            return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
        
        if result.data:
            df = pd.DataFrame(result.data)
            
            # ì»¬ëŸ¼ëª… ë³€í™˜ (DB -> CSV í˜¸í™˜)
            if actual_table == 'sales':
                if 'date' in df.columns:
                    df['ë‚ ì§œ'] = pd.to_datetime(df['date'])
                if 'card_sales' in df.columns:
                    df['ì¹´ë“œë§¤ì¶œ'] = df['card_sales']
                if 'cash_sales' in df.columns:
                    df['í˜„ê¸ˆë§¤ì¶œ'] = df['cash_sales']
                if 'total_sales' in df.columns:
                    df['ì´ë§¤ì¶œ'] = df['total_sales']
                # store_idë¡œ ë§¤ì¥ëª… ì¡°íšŒ
                store_result = supabase.table("stores").select("name").eq("id", store_id).execute()
                if store_result.data:
                    df['ë§¤ì¥'] = store_result.data[0]['name']
            
            elif actual_table == 'naver_visitors':
                if 'date' in df.columns:
                    df['ë‚ ì§œ'] = pd.to_datetime(df['date'])
                if 'visitors' in df.columns:
                    df['ë°©ë¬¸ììˆ˜'] = df['visitors']
            
            elif actual_table == 'menu_master':
                if 'name' in df.columns:
                    df['ë©”ë‰´ëª…'] = df['name']
                if 'price' in df.columns:
                    df['íŒë§¤ê°€'] = df['price']
            
            elif actual_table == 'ingredients':
                if 'name' in df.columns:
                    df['ì¬ë£Œëª…'] = df['name']
                if 'unit' in df.columns:
                    df['ë‹¨ìœ„'] = df['unit']
                if 'unit_cost' in df.columns:
                    df['ë‹¨ê°€'] = df['unit_cost']
                if 'order_unit' in df.columns:
                    df['ë°œì£¼ë‹¨ìœ„'] = df['order_unit']
                if 'conversion_rate' in df.columns:
                    df['ë³€í™˜ë¹„ìœ¨'] = df['conversion_rate']
            
            elif actual_table == 'recipes':
                # menu_idì™€ ingredient_idë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
                if 'menu_id' in df.columns:
                    menu_ids = df['menu_id'].dropna().unique().tolist()
                    if menu_ids:
                        menu_result = supabase.table("menu_master").select("id,name").in_("id", menu_ids).execute()
                        menu_map = {m['id']: m['name'] for m in menu_result.data}
                        df['ë©”ë‰´ëª…'] = df['menu_id'].map(menu_map)
                
                if 'ingredient_id' in df.columns:
                    ing_ids = df['ingredient_id'].dropna().unique().tolist()
                    if ing_ids:
                        ing_result = supabase.table("ingredients").select("id,name").in_("id", ing_ids).execute()
                        ing_map = {i['id']: i['name'] for i in ing_result.data}
                        df['ì¬ë£Œëª…'] = df['ingredient_id'].map(ing_map)
                
                if 'qty' in df.columns:
                    df['ì‚¬ìš©ëŸ‰'] = df['qty']
            
            elif actual_table == 'daily_sales_items':
                if 'date' in df.columns:
                    df['ë‚ ì§œ'] = pd.to_datetime(df['date'])
                
                if 'menu_id' in df.columns:
                    menu_ids = df['menu_id'].dropna().unique().tolist()
                    if menu_ids:
                        menu_result = supabase.table("menu_master").select("id,name").in_("id", menu_ids).execute()
                        menu_map = {m['id']: m['name'] for m in menu_result.data}
                        df['ë©”ë‰´ëª…'] = df['menu_id'].map(menu_map)
                
                if 'qty' in df.columns:
                    df['íŒë§¤ìˆ˜ëŸ‰'] = df['qty']
            
            elif actual_table == 'inventory':
                if 'ingredient_id' in df.columns:
                    ing_ids = df['ingredient_id'].dropna().unique().tolist()
                    if ing_ids:
                        ing_result = supabase.table("ingredients").select("id,name").in_("id", ing_ids).execute()
                        ing_map = {i['id']: i['name'] for i in ing_result.data}
                        df['ì¬ë£Œëª…'] = df['ingredient_id'].map(ing_map)
                
                if 'on_hand' in df.columns:
                    df['í˜„ì¬ê³ '] = df['on_hand']
                if 'safety_stock' in df.columns:
                    df['ì•ˆì „ì¬ê³ '] = df['safety_stock']
            
            elif actual_table == 'targets':
                if 'year' in df.columns:
                    df['ì—°ë„'] = df['year']
                if 'month' in df.columns:
                    df['ì›”'] = df['month']
                if 'target_sales' in df.columns:
                    df['ëª©í‘œë§¤ì¶œ'] = df['target_sales']
                if 'target_cost_rate' in df.columns:
                    df['ëª©í‘œì›ê°€ìœ¨'] = df['target_cost_rate']
                if 'target_labor_rate' in df.columns:
                    df['ëª©í‘œì¸ê±´ë¹„ìœ¨'] = df['target_labor_rate']
                if 'target_rent_rate' in df.columns:
                    df['ëª©í‘œì„ëŒ€ë£Œìœ¨'] = df['target_rent_rate']
                if 'target_other_rate' in df.columns:
                    df['ëª©í‘œê¸°íƒ€ë¹„ìš©ìœ¨'] = df['target_other_rate']
                if 'target_profit_rate' in df.columns:
                    df['ëª©í‘œìˆœì´ìµë¥ '] = df['target_profit_rate']
            
            elif actual_table == 'actual_settlement':
                # ì‹¤ì œ ì •ì‚° ë°ì´í„° (ì›”ë³„ ì‹¤ì )
                if 'year' in df.columns:
                    df['ì—°ë„'] = df['year']
                if 'month' in df.columns:
                    df['ì›”'] = df['month']
                if 'actual_sales' in df.columns:
                    df['ì‹¤ì œë§¤ì¶œ'] = df['actual_sales']
                if 'actual_cost' in df.columns:
                    df['ì‹¤ì œë¹„ìš©'] = df['actual_cost']
                if 'actual_profit' in df.columns:
                    df['ì‹¤ì œì´ìµ'] = df['actual_profit']
                if 'profit_margin' in df.columns:
                    df['ì‹¤ì œì´ìµë¥ '] = df['profit_margin']
            
            elif actual_table == 'abc_history':
                # ì»¬ëŸ¼ëª…ì´ ì´ë¯¸ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ë„ ìˆìŒ
                if 'menu_name' in df.columns:
                    df['ë©”ë‰´ëª…'] = df['menu_name']
                if 'sales_qty' in df.columns:
                    df['íŒë§¤ëŸ‰'] = df['sales_qty']
                if 'sales_amount' in df.columns:
                    df['ë§¤ì¶œ'] = df['sales_amount']
                if 'contribution_margin' in df.columns:
                    df['ê³µí—Œì´ìµ'] = df['contribution_margin']
                if 'qty_ratio' in df.columns:
                    df['íŒë§¤ëŸ‰ë¹„ì¤‘'] = df['qty_ratio']
                if 'sales_ratio' in df.columns:
                    df['ë§¤ì¶œë¹„ì¤‘'] = df['sales_ratio']
                if 'margin_ratio' in df.columns:
                    df['ê³µí—Œì´ìµë¹„ì¤‘'] = df['margin_ratio']
                if 'abc_grade' in df.columns:
                    df['ABCë“±ê¸‰'] = df['abc_grade']
                if 'year' in df.columns:
                    df['ì—°ë„'] = df['year']
                if 'month' in df.columns:
                    df['ì›”'] = df['month']
            
            elif actual_table == 'suppliers':
                if 'name' in df.columns:
                    df['ê³µê¸‰ì—…ì²´ëª…'] = df['name']
                if 'phone' in df.columns:
                    df['ì „í™”ë²ˆí˜¸'] = df['phone']
                if 'email' in df.columns:
                    df['ì´ë©”ì¼'] = df['email']
                if 'delivery_days' in df.columns:
                    df['ë°°ì†¡ì¼'] = df['delivery_days']
                if 'min_order_amount' in df.columns:
                    df['ìµœì†Œì£¼ë¬¸ê¸ˆì•¡'] = df['min_order_amount']
                if 'delivery_fee' in df.columns:
                    df['ë°°ì†¡ë¹„'] = df['delivery_fee']
                if 'notes' in df.columns:
                    df['ë¹„ê³ '] = df['notes']
            
            elif actual_table == 'ingredient_suppliers':
                # ì¬ë£Œ ID -> ì¬ë£Œëª… ë³€í™˜
                if 'ingredient_id' in df.columns:
                    ing_ids = df['ingredient_id'].dropna().unique().tolist()
                    if ing_ids:
                        ing_result = supabase.table("ingredients").select("id,name").in_("id", ing_ids).execute()
                        ing_map = {i['id']: i['name'] for i in ing_result.data}
                        df['ì¬ë£Œëª…'] = df['ingredient_id'].map(ing_map)
                
                # ê³µê¸‰ì—…ì²´ ID -> ê³µê¸‰ì—…ì²´ëª… ë³€í™˜
                if 'supplier_id' in df.columns:
                    sup_ids = df['supplier_id'].dropna().unique().tolist()
                    if sup_ids:
                        sup_result = supabase.table("suppliers").select("id,name").in_("id", sup_ids).execute()
                        sup_map = {s['id']: s['name'] for s in sup_result.data}
                        df['ê³µê¸‰ì—…ì²´ëª…'] = df['supplier_id'].map(sup_map)
                
                if 'unit_price' in df.columns:
                    df['ë‹¨ê°€'] = df['unit_price']
                if 'is_default' in df.columns:
                    df['ê¸°ë³¸ê³µê¸‰ì—…ì²´'] = df['is_default']
            
            elif actual_table == 'orders':
                # id ì»¬ëŸ¼ ìœ ì§€
                if 'id' not in df.columns:
                    df['id'] = df.index
                
                # ì¬ë£Œ ID -> ì¬ë£Œëª… ë³€í™˜
                if 'ingredient_id' in df.columns:
                    ing_ids = df['ingredient_id'].dropna().unique().tolist()
                    if ing_ids:
                        ing_result = supabase.table("ingredients").select("id,name").in_("id", ing_ids).execute()
                        ing_map = {i['id']: i['name'] for i in ing_result.data}
                        df['ì¬ë£Œëª…'] = df['ingredient_id'].map(ing_map)
                
                # ê³µê¸‰ì—…ì²´ ID -> ê³µê¸‰ì—…ì²´ëª… ë³€í™˜
                if 'supplier_id' in df.columns:
                    sup_ids = df['supplier_id'].dropna().unique().tolist()
                    if sup_ids:
                        sup_result = supabase.table("suppliers").select("id,name").in_("id", sup_ids).execute()
                        sup_map = {s['id']: s['name'] for s in sup_result.data}
                        df['ê³µê¸‰ì—…ì²´ëª…'] = df['supplier_id'].map(sup_map)
                
                if 'order_date' in df.columns:
                    df['ë°œì£¼ì¼'] = pd.to_datetime(df['order_date'])
                if 'quantity' in df.columns:
                    df['ìˆ˜ëŸ‰'] = df['quantity']
                if 'unit_price' in df.columns:
                    df['ë‹¨ê°€'] = df['unit_price']
                if 'total_amount' in df.columns:
                    df['ì´ê¸ˆì•¡'] = df['total_amount']
                if 'status' in df.columns:
                    df['ìƒíƒœ'] = df['status']
                if 'expected_delivery_date' in df.columns:
                    df['ì…ê³ ì˜ˆì •ì¼'] = pd.to_datetime(df['expected_delivery_date'])
                if 'actual_delivery_date' in df.columns:
                    df['ì…ê³ ì¼'] = pd.to_datetime(df['actual_delivery_date'])
                if 'notes' in df.columns:
                    df['ë¹„ê³ '] = df['notes']
            
            return df
        else:
            return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    except Exception as e:
        logger.error(f"Failed to load {filename}: {e}")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()


# ìºì‹œ ì ìš© (store_idì™€ client_modeë¥¼ ìºì‹œ í‚¤ì— í¬í•¨)
# ì£¼ì˜: ë°ì½”ë ˆì´í„° ë ˆë²¨ì—ì„œ is_dev_mode() í˜¸ì¶œ ì‹œ ëª¨ë“ˆ ë¡œë“œ ì‹œì ì— session_stateê°€ ì—†ì–´ ìºì‹œê°€ ì¬ìƒì„±ë¨
# ë”°ë¼ì„œ TTLì„ ê³ ì •ê°’(300ì´ˆ)ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í™•ë³´
@st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ (ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í™•ë³´)
def load_csv(filename: str, default_columns: Optional[List[str]] = None, store_id: str = None, client_mode: str = None):
    """
    í…Œì´ë¸”ì—ì„œ ë°ì´í„° ë¡œë“œ (CSV í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤)
    ìºì‹œ í‚¤ì— store_idì™€ client_modeë¥¼ í¬í•¨í•˜ì—¬ ë§¤ì¥ë³„/í´ë¼ì´ì–¸íŠ¸ë³„ë¡œ ìºì‹œ ë¶„ë¦¬
    
    Args:
        filename: CSV íŒŒì¼ëª… (ì˜ˆ: "sales.csv") -> í…Œì´ë¸”ëª…ìœ¼ë¡œ ë§¤í•‘
        default_columns: ê¸°ë³¸ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        store_id: store_id (Noneì´ë©´ get_current_store_id() ì‚¬ìš©)
        client_mode: client_mode (Noneì´ë©´ get_read_client_mode() ì‚¬ìš©, ìºì‹œ í‚¤ì— í¬í•¨)
    
    Returns:
        pandas.DataFrame
    """
    # ì„¸ì…˜ ìºì‹œ í‚¤ ë§¤í•‘ (ë§ˆìŠ¤í„° ë°ì´í„°ë§Œ ì„¸ì…˜ ìºì‹œ ì‚¬ìš©)
    session_cache_keys = {
        'menu_master.csv': 'ss_menu_master_df',
        'ingredient_master.csv': 'ss_ingredient_master_df',
        'inventory.csv': 'ss_inventory_df',
        'recipes.csv': 'ss_recipes_df',
        'targets.csv': 'ss_targets_df',
        # íŒŒì¼ëª… ì—†ì´ í…Œì´ë¸”ëª…ìœ¼ë¡œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥
        'menu_master': 'ss_menu_master_df',
        'ingredient_master': 'ss_ingredient_master_df',
        'inventory': 'ss_inventory_df',
        'recipes': 'ss_recipes_df',
        'targets': 'ss_targets_df',
    }
    
    # ì„¸ì…˜ ìºì‹œ í‚¤ í™•ì¸
    session_key = session_cache_keys.get(filename)
    if session_key and session_key in st.session_state:
        # ì„¸ì…˜ ìºì‹œì— ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
        if _is_dev_mode():
            logger.debug(f"load_csv: Session cache HIT for {filename}")
        df = st.session_state[session_key]
        # ìºì‹œ íˆíŠ¸ë„ ê³„ì¸¡ (ë§¤ìš° ë¹ ë¦„)
        record_data_call(f"load_csv({filename})", 0.1, rows=len(df), source="session_cache")
        return df
    
    # store_idì™€ client_modeë¥¼ ìºì‹œ í‚¤ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ê¸° ìœ„í•´ ê°€ì ¸ì˜¤ê¸°
    if store_id is None:
        store_id = get_current_store_id()
    if client_mode is None:
        try:
            client_mode = get_read_client_mode()
        except Exception:
            client_mode = "unknown"
    
    if not store_id:
        logger.warning(f"No store_id found, returning empty DataFrame for {filename}")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    # @st.cache_data ìºì‹œ ë˜ëŠ” DB ì¡°íšŒ
    df = _load_csv_impl(filename, store_id, client_mode, default_columns)
    
    # ì„¸ì…˜ ìºì‹œì— ì €ì¥ (ë§ˆìŠ¤í„° ë°ì´í„°ë§Œ)
    if session_key:
        st.session_state[session_key] = df
        if _is_dev_mode():
            logger.debug(f"load_csv: Session cache SET for {filename} ({len(df)} rows)")
    
    return df


@st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ (ë§ˆìŠ¤í„° ë°ì´í„°, ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í™•ë³´)
def load_key_menus() -> List[str]:
    """í•µì‹¬ ë©”ë‰´ ëª©ë¡ ë¡œë“œ (is_core=Trueì¸ ë©”ë‰´ë“¤)"""
    supabase = get_supabase_client()
    if not supabase:
        return []
    
    store_id = get_current_store_id()
    if not store_id:
        return []
    
    try:
        result = supabase.table("menu_master").select("name").eq("store_id", store_id).eq("is_core", True).execute()
        if result.data:
            return [m['name'] for m in result.data]
        return []
    except Exception as e:
        logger.error(f"Failed to load key menus: {e}")
        return []


# ============================================
# Save Functions
# ============================================

def save_sales(date, store_name, card_sales, cash_sales, total_sales=None):
    """ë§¤ì¶œ ë°ì´í„° ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    if total_sales is None:
        total_sales = card_sales + cash_sales
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        result = supabase.table("sales").upsert({
            "store_id": store_id,
            "date": date_str,
            "card_sales": float(card_sales),
            "cash_sales": float(cash_sales),
            "total_sales": float(total_sales)
        }, on_conflict="store_id,date").execute()
        
        logger.info(f"Sales saved: {date_str}, {total_sales}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_sales: {date_str}",
            targets=["sales"]
        )
        
        # S5: ë§¤ì¶œ ì €ì¥ ì§í›„ ìŠ¤ëƒ…ìƒ· (dev_modeì—ì„œë§Œ)
        try:
            from src.auth import is_dev_mode
            if is_dev_mode():
                from src.utils.boot_perf import snapshot_current_metrics
                snapshot_current_metrics("S5: ë§¤ì¶œ ì €ì¥ ì§í›„ rerun")
        except Exception:
            pass
        
        return True
    except Exception as e:
        logger.error(f"Failed to save sales: {e}")
        raise


def save_visitor(date, visitors):
    """ë°©ë¬¸ì ë°ì´í„° ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        result = supabase.table("naver_visitors").upsert({
            "store_id": store_id,
            "date": date_str,
            "visitors": int(visitors)
        }, on_conflict="store_id,date").execute()
        
        logger.info(f"Visitor saved: {date_str}, {visitors}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_visitor: {date_str}",
            targets=["visitors"]
        )
        
        return True
    except Exception as e:
        logger.error(f"Failed to save visitor: {e}")
        raise


def save_menu(menu_name, price):
    """
    ë©”ë‰´ ì €ì¥
    
    Phase 2: ë™ì‹œì„± ë³´í˜¸ - Optimistic Locking ì ìš©
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¤‘ë³µ ì²´í¬ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if _check_duplicate(supabase, "menu_master", "name", menu_name, store_id):
            return False, f"'{menu_name}' ë©”ë‰´ëŠ” ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        
        result = supabase.table("menu_master").insert({
            "store_id": store_id,
            "name": menu_name,
            "price": float(price),
            "is_core": False
        }).execute()
        
        logger.info(f"Menu saved: {menu_name}, {price}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_menu: {menu_name}",
            targets=["menus", "recipes"],
            session_keys=['ss_menu_master_df', 'ss_recipes_df']
        )
        
        return True, "ì €ì¥ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to save menu: {e}")
        raise


def update_menu(old_menu_name, new_menu_name, new_price, category=None, expected_updated_at=None):
    """
    ë©”ë‰´ ìˆ˜ì •
    
    Phase 2: ë™ì‹œì„± ë³´í˜¸ - Optimistic Locking
    - expected_updated_at: ìˆ˜ì • ì „ì˜ updated_at ê°’ (ì¶©ëŒ ê°ì§€ìš©)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ê¸°ì¡´ ë©”ë‰´ ì°¾ê¸° (updated_at í¬í•¨)
        existing = supabase.table("menu_master").select("id,updated_at").eq("store_id", store_id).eq("name", old_menu_name).execute()
        if not existing.data:
            return False, f"'{old_menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        menu_id = existing.data[0]['id']
        current_updated_at = existing.data[0].get('updated_at')
        
        # Phase 2: ë™ì‹œì„± ë³´í˜¸ - Optimistic Locking
        if expected_updated_at and current_updated_at != expected_updated_at:
            return False, f"ë‹¤ë¥¸ ì‚¬ìš©ìê°€ '{old_menu_name}' ë©”ë‰´ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        # ìƒˆ ë©”ë‰´ëª…ì´ ë‹¤ë¥¸ ê²½ìš° ì¤‘ë³µ ì²´í¬ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if new_menu_name != old_menu_name:
            if _check_duplicate(supabase, "menu_master", "name", new_menu_name, store_id):
                return False, f"'{new_menu_name}' ë©”ë‰´ëª…ì€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤."
        
        # ì—…ë°ì´íŠ¸ ë°ì´í„° ì¤€ë¹„
        update_data = {
            "name": new_menu_name,
            "price": float(new_price)
        }
        if category is not None:
            update_data["category"] = category
        
        # ì—…ë°ì´íŠ¸
        supabase.table("menu_master").update(update_data).eq("id", menu_id).execute()
        
        logger.info(f"Menu updated: {old_menu_name} -> {new_menu_name}")
        
        # ìºì‹œ í´ë¦¬ì–´ (ë°ì´í„° ë³€ê²½ í›„)
        try:
            load_csv.clear()
        except Exception:
            pass
        
        return True, "ìˆ˜ì • ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to update menu: {e}")
        raise


def update_menu_category(menu_name, category):
    """ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ê¸°ì¡´ ë©”ë‰´ ì°¾ê¸°
        existing = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not existing.data:
            return False, f"'{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        menu_id = existing.data[0]['id']
        
        # ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸
        supabase.table("menu_master").update({
            "category": category
        }).eq("id", menu_id).execute()
        
        logger.info(f"Menu category updated: {menu_name} -> {category}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"update_menu_category: {menu_name}",
            targets=["menus"],
            session_keys=['ss_menu_master_df']
        )
        
        return True, "ì¹´í…Œê³ ë¦¬ ìˆ˜ì • ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to update menu category: {e}")
        raise


def update_menu_cooking_method(menu_name, cooking_method):
    """ë©”ë‰´ ì¡°ë¦¬ë°©ë²• ì—…ë°ì´íŠ¸"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ê¸°ì¡´ ë©”ë‰´ ì°¾ê¸°
        existing = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not existing.data:
            return False, f"'{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        menu_id = existing.data[0]['id']
        
        # ì¡°ë¦¬ë°©ë²• ì—…ë°ì´íŠ¸ (cooking_method ì»¬ëŸ¼ì´ ìˆë‹¤ë©´)
        try:
            supabase.table("menu_master").update({
                "cooking_method": cooking_method.strip()
            }).eq("id", menu_id).execute()
            logger.info(f"Menu cooking method updated: {menu_name}")
            return True, "ì¡°ë¦¬ë°©ë²• ì €ì¥ ì„±ê³µ"
        except Exception as e:
            # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê²½ê³ ë§Œ í•˜ê³  ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ë‚˜ì¤‘ì— ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ í•„ìš”)
            logger.warning(f"Cooking method column may not exist: {e}")
            return True, "ì¡°ë¦¬ë°©ë²• ì €ì¥ ì„±ê³µ (ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ í•„ìš”í•  ìˆ˜ ìˆìŒ)"
    except Exception as e:
        logger.error(f"Failed to update menu cooking method: {e}")
        raise


def delete_menu(menu_name, check_references=True):
    """ë©”ë‰´ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ë©”ë‰´ ì°¾ê¸°
        menu_result = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not menu_result.data:
            return False, f"'{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
        
        menu_id = menu_result.data[0]['id']
        
        references = {}
        if check_references:
            # ë ˆì‹œí”¼ ì°¸ì¡° í™•ì¸
            recipe_check = supabase.table("recipes").select("id").eq("menu_id", menu_id).execute()
            if recipe_check.data:
                references['ë ˆì‹œí”¼'] = len(recipe_check.data)
            
            # íŒë§¤ ë‚´ì—­ ì°¸ì¡° í™•ì¸
            sales_check = supabase.table("daily_sales_items").select("id").eq("menu_id", menu_id).execute()
            if sales_check.data:
                references['íŒë§¤ë‚´ì—­'] = len(sales_check.data)
        
        if references:
            ref_info = ", ".join([f"{k}: {v}ê°œ" for k, v in references.items()])
            return False, f"'{menu_name}' ë©”ë‰´ëŠ” ë‹¤ìŒ ë°ì´í„°ì—ì„œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤: {ref_info}", references
        
        # ì‚­ì œ
        supabase.table("menu_master").delete().eq("id", menu_id).execute()
        logger.info(f"Menu deleted: {menu_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_menu: {menu_name}",
            targets=["menus", "recipes"],
            session_keys=['ss_menu_master_df', 'ss_recipes_df']
        )
        
        return True, "ì‚­ì œ ì„±ê³µ", None
    except Exception as e:
        logger.error(f"Failed to delete menu: {e}")
        raise


def save_ingredient(ingredient_name, unit, unit_price, order_unit=None, conversion_rate=1.0):
    """ì¬ë£Œ ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¤‘ë³µ ì²´í¬ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if _check_duplicate(supabase, "ingredients", "name", ingredient_name, store_id):
            return False, f"'{ingredient_name}' ì¬ë£ŒëŠ” ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        
        # ë°œì£¼ ë‹¨ìœ„ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë‹¨ìœ„ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
        if not order_unit:
            order_unit = unit
        
        insert_data = {
            "store_id": store_id,
            "name": ingredient_name,
            "unit": unit,
            "unit_cost": float(unit_price),
            "order_unit": order_unit,
            "conversion_rate": float(conversion_rate)
        }
        
        result = supabase.table("ingredients").insert(insert_data).execute()
        
        logger.info(f"Ingredient saved: {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_ingredient: {ingredient_name}",
            targets=["ingredients", "recipes", "cost"],
            session_keys=['ss_ingredient_master_df', 'ss_recipes_df', 'ss_inventory_df']
        )
        
        return True, "ì €ì¥ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to save ingredient: {e}")
        raise


def update_ingredient(old_ingredient_name, new_ingredient_name, new_unit, new_unit_price):
    """ì¬ë£Œ ìˆ˜ì •"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ê¸°ì¡´ ì¬ë£Œ ì°¾ê¸°
        existing = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", old_ingredient_name).execute()
        if not existing.data:
            return False, f"'{old_ingredient_name}' ì¬ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        ing_id = existing.data[0]['id']
        
        # ìƒˆ ì¬ë£Œëª…ì´ ë‹¤ë¥¸ ê²½ìš° ì¤‘ë³µ ì²´í¬ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if new_ingredient_name != old_ingredient_name:
            if _check_duplicate(supabase, "ingredients", "name", new_ingredient_name, store_id):
                return False, f"'{new_ingredient_name}' ì¬ë£Œëª…ì€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤."
        
        # ì—…ë°ì´íŠ¸
        supabase.table("ingredients").update({
            "name": new_ingredient_name,
            "unit": new_unit,
            "unit_cost": float(new_unit_price)
        }).eq("id", ing_id).execute()
        
        logger.info(f"Ingredient updated: {old_ingredient_name} -> {new_ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"update_ingredient: {old_ingredient_name}",
            targets=["ingredients", "recipes", "cost"],
            session_keys=['ss_ingredient_master_df', 'ss_recipes_df', 'ss_inventory_df']
        )
        
        return True, "ìˆ˜ì • ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to update ingredient: {e}")
        raise


def delete_ingredient(ingredient_name, check_references=True):
    """ì¬ë£Œ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            return False, f"'{ingredient_name}' ì¬ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
        
        ing_id = ing_result.data[0]['id']
        
        references = {}
        if check_references:
            # ë ˆì‹œí”¼ ì°¸ì¡° í™•ì¸
            recipe_check = supabase.table("recipes").select("id").eq("ingredient_id", ing_id).execute()
            if recipe_check.data:
                references['ë ˆì‹œí”¼'] = len(recipe_check.data)
            
            # ì¬ê³  ì •ë³´ ì°¸ì¡° í™•ì¸
            inv_check = supabase.table("inventory").select("id").eq("ingredient_id", ing_id).execute()
            if inv_check.data:
                references['ì¬ê³ ì •ë³´'] = 1
        
        if references:
            ref_info = ", ".join([f"{k}: {v}ê°œ" for k, v in references.items()])
            return False, f"'{ingredient_name}' ì¬ë£ŒëŠ” ë‹¤ìŒ ë°ì´í„°ì—ì„œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤: {ref_info}", references
        
        # ì‚­ì œ
        supabase.table("ingredients").delete().eq("id", ing_id).execute()
        logger.info(f"Ingredient deleted: {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_ingredient: {ingredient_name}",
            targets=["ingredients", "recipes", "cost"],
            session_keys=['ss_ingredient_master_df', 'ss_recipes_df', 'ss_inventory_df']
        )
        
        return True, "ì‚­ì œ ì„±ê³µ", None
    except Exception as e:
        logger.error(f"Failed to delete ingredient: {e}")
        raise


def save_recipe(menu_name, ingredient_name, quantity):
    """ë ˆì‹œí”¼ ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ë©”ë‰´ ID ì°¾ê¸°
        menu_result = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not menu_result.data:
            raise Exception(f"ë©”ë‰´ '{menu_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        menu_id = menu_result.data[0]['id']
        
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_id = ing_result.data[0]['id']
        
        # ë ˆì‹œí”¼ ì €ì¥
        result = supabase.table("recipes").upsert({
            "store_id": store_id,
            "menu_id": menu_id,
            "ingredient_id": ingredient_id,
            "qty": float(quantity)
        }, on_conflict="store_id,menu_id,ingredient_id").execute()
        
        logger.info(f"Recipe saved: {menu_name} - {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_recipe: {menu_name}-{ingredient_name}",
            targets=["recipes", "cost"],
            session_keys=['ss_recipes_df']
        )
        
        return True
    except Exception as e:
        logger.error(f"Failed to save recipe: {e}")
        raise


def delete_recipe(menu_name, ingredient_name):
    """ë ˆì‹œí”¼ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ë©”ë‰´ ID ì°¾ê¸°
        menu_result = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not menu_result.data:
            return False, f"'{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        menu_id = menu_result.data[0]['id']
        
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            return False, f"'{ingredient_name}' ì¬ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        ingredient_id = ing_result.data[0]['id']
        
        # ë ˆì‹œí”¼ ì‚­ì œ
        supabase.table("recipes").delete().eq("store_id", store_id).eq("menu_id", menu_id).eq("ingredient_id", ingredient_id).execute()
        
        logger.info(f"Recipe deleted: {menu_name} - {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_recipe: {menu_name}-{ingredient_name}",
            targets=["recipes", "cost"],
            session_keys=['ss_recipes_df']
        )
        
        return True, "ì‚­ì œ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to delete recipe: {e}")
        raise


def save_daily_sales_item(date, menu_name, quantity):
    """ì¼ì¼ íŒë§¤ ì•„ì´í…œ ì €ì¥ (ê°™ì€ ë‚ ì§œ/ë©”ë‰´ê°€ ìˆìœ¼ë©´ ìˆ˜ëŸ‰ í•©ì‚°)"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        # ë©”ë‰´ ID ì°¾ê¸°
        menu_result = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not menu_result.data:
            raise Exception(f"ë©”ë‰´ '{menu_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        menu_id = menu_result.data[0]['id']
        
        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
        existing = supabase.table("daily_sales_items").select("qty").eq("store_id", store_id).eq("date", date_str).eq("menu_id", menu_id).execute()
        
        if existing.data:
            # ê¸°ì¡´ ìˆ˜ëŸ‰ì— ì¶”ê°€
            new_qty = existing.data[0]['qty'] + quantity
            supabase.table("daily_sales_items").update({"qty": new_qty}).eq("store_id", store_id).eq("date", date_str).eq("menu_id", menu_id).execute()
        else:
            # ìƒˆë¡œ ì¶”ê°€
            supabase.table("daily_sales_items").insert({
                "store_id": store_id,
                "date": date_str,
                "menu_id": menu_id,
                "qty": int(quantity)
            }).execute()
        
        logger.info(f"Daily sales item saved: {date_str}, {menu_name}, {quantity}")
        return True
    except Exception as e:
        logger.error(f"Failed to save daily sales item: {e}")
        raise


def save_inventory(ingredient_name, current_stock, safety_stock):
    """ì¬ê³  ì •ë³´ ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_id = ing_result.data[0]['id']
        
        # ì¬ê³  ì •ë³´ ì €ì¥/ì—…ë°ì´íŠ¸
        supabase.table("inventory").upsert({
            "store_id": store_id,
            "ingredient_id": ingredient_id,
            "on_hand": float(current_stock),
            "safety_stock": float(safety_stock)
        }, on_conflict="store_id,ingredient_id").execute()
        
        logger.info(f"Inventory saved: {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_inventory: {ingredient_name}",
            targets=["inventory"],
            session_keys=['ss_inventory_df']
        )
        
        return True
    except Exception as e:
        logger.error(f"Failed to save inventory: {e}")
        raise


def save_targets(year, month, target_sales, target_cost_rate, target_labor_rate, 
                 target_rent_rate, target_other_rate, target_profit_rate):
    """ëª©í‘œ ë§¤ì¶œ/ë¹„ìš© êµ¬ì¡° ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("targets").upsert({
            "store_id": store_id,
            "year": int(year),
            "month": int(month),
            "target_sales": float(target_sales),
            "target_cost_rate": float(target_cost_rate),
            "target_labor_rate": float(target_labor_rate),
            "target_rent_rate": float(target_rent_rate),
            "target_other_rate": float(target_other_rate),
            "target_profit_rate": float(target_profit_rate)
        }, on_conflict="store_id,year,month").execute()
        
        logger.info(f"Targets saved: {year}-{month}")
        return True
    except Exception as e:
        logger.error(f"Failed to save targets: {e}")
        raise


def save_actual_settlement(year, month, actual_sales, actual_cost, actual_profit, profit_margin):
    """ì›”ë³„ ì‹¤ì œ ì •ì‚° ë°ì´í„° ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("actual_settlement").upsert(
            {
                "store_id": store_id,
                "year": int(year),
                "month": int(month),
                "actual_sales": float(actual_sales),
                "actual_cost": float(actual_cost),
                "actual_profit": float(actual_profit),
                "profit_margin": float(profit_margin),
            },
            on_conflict="store_id,year,month",
        ).execute()
        logger.info(f"Actual settlement saved: {year}-{month}")
        return True
    except Exception as e:
        logger.error(f"Failed to save actual settlement: {e}")
        raise


def save_abc_history(year, month, abc_df):
    """
    ABC ë¶„ì„ íˆìŠ¤í† ë¦¬ ì €ì¥
    
    Phase 2: íŠ¸ëœì­ì…˜ ì²˜ë¦¬ ê°œì„ 
    - ì‚­ì œ í›„ ì‚½ì… ì‘ì—…ì˜ ì›ìì„± ë³´ì¥
    - ì‹¤íŒ¨ ì‹œ ë¡¤ë°± ì‹œë„
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    # Phase 2: íŠ¸ëœì­ì…˜ ì²˜ë¦¬ - ê¸°ì¡´ ë°ì´í„° ë°±ì—…
    old_data_backup = None
    try:
        # ê¸°ì¡´ ë°ì´í„° ë°±ì—… (ë¡¤ë°±ìš©)
        old_result = supabase.table("abc_history").select("*").eq("store_id", store_id).eq("year", year).eq("month", month).execute()
        old_data_backup = old_result.data if old_result.data else []
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (í•´ë‹¹ ì—°ë„/ì›”)
        supabase.table("abc_history").delete().eq("store_id", store_id).eq("year", year).eq("month", month).execute()
        
        # ìƒˆ ë°ì´í„° ì¶”ê°€
        records = []
        for _, row in abc_df.iterrows():
            records.append({
                "store_id": store_id,
                "year": int(year),
                "month": int(month),
                "menu_name": str(row.get('ë©”ë‰´ëª…', '')),
                "sales_qty": int(row.get('íŒë§¤ëŸ‰', 0)),
                "sales_amount": float(row.get('ë§¤ì¶œ', 0)),
                "contribution_margin": float(row.get('ê³µí—Œì´ìµ', 0)),
                "qty_ratio": float(row.get('íŒë§¤ëŸ‰ë¹„ì¤‘', 0)),
                "sales_ratio": float(row.get('ë§¤ì¶œë¹„ì¤‘', 0)),
                "margin_ratio": float(row.get('ê³µí—Œì´ìµë¹„ì¤‘', 0)),
                "abc_grade": str(row.get('ABCë“±ê¸‰', ''))
            })
        
        if records:
            supabase.table("abc_history").insert(records).execute()
        
        logger.info(f"ABC history saved: {year}-{month}")
        return True
    except Exception as e:
        logger.error(f"Failed to save abc history: {e}")
        # Phase 2: íŠ¸ëœì­ì…˜ ì²˜ë¦¬ - ì‹¤íŒ¨ ì‹œ ë¡¤ë°± ì‹œë„
        if old_data_backup:
            try:
                logger.warning(f"Rolling back ABC history for {year}-{month}")
                # ê¸°ì¡´ ë°ì´í„° ë³µì› ì‹œë„
                if old_data_backup:
                    supabase.table("abc_history").insert(old_data_backup).execute()
                logger.info(f"ABC history rollback successful for {year}-{month}")
            except Exception as rollback_error:
                logger.error(f"Failed to rollback ABC history: {rollback_error}")
        raise


def save_key_menus(menu_list):
    """í•µì‹¬ ë©”ë‰´ ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ë¨¼ì € ëª¨ë“  ë©”ë‰´ì˜ is_coreë¥¼ Falseë¡œ
        supabase.table("menu_master").update({"is_core": False}).eq("store_id", store_id).execute()
        
        # ì„ íƒëœ ë©”ë‰´ë“¤ì˜ is_coreë¥¼ Trueë¡œ
        if menu_list:
            for menu_name in menu_list:
                supabase.table("menu_master").update({"is_core": True}).eq("store_id", store_id).eq("name", menu_name).execute()
        
        logger.info(f"Key menus saved: {len(menu_list)} menus")
        return True
    except Exception as e:
        logger.error(f"Failed to save key menus: {e}")
        raise


def save_daily_close(date, store_name, card_sales, cash_sales, total_sales, 
                     visitors, sales_items, issues, memo):
    """
    ì¼ì¼ ë§ˆê° ë°ì´í„° í†µí•© ì €ì¥ (íŠ¸ëœì­ì…˜ ì²˜ë¦¬)
    
    Phase 3: SQL í•¨ìˆ˜ ê¸°ë°˜ íŠ¸ëœì­ì…˜ ì²˜ë¦¬
    - ì—¬ëŸ¬ í…Œì´ë¸” ì €ì¥ ì‘ì—…ì˜ ì›ìì„± ë³´ì¥
    - ì‹¤íŒ¨ ì‹œ ìë™ ë¡¤ë°±
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
    
    try:
        # sales_itemsë¥¼ JSONB í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        sales_items_json = None
        if sales_items:
            # sales_itemsê°€ [(menu_name, qty), ...] í˜•ì‹ì¸ ê²½ìš° JSONB ë°°ì—´ë¡œ ë³€í™˜
            sales_items_array = [
                {"menu_name": menu_name, "quantity": int(qty)}
                for menu_name, qty in sales_items
            ]
            sales_items_json = json.dumps(sales_items_array, ensure_ascii=False)
        
        # íŠ¸ëœì­ì…˜ í•¨ìˆ˜ í˜¸ì¶œ (ì›ìì  ì €ì¥)
        supabase.rpc('save_daily_close_transaction', {
            'p_date': date_str,
            'p_store_id': str(store_id),
            'p_card_sales': float(card_sales),
            'p_cash_sales': float(cash_sales),
            'p_total_sales': float(total_sales),
            'p_visitors': int(visitors),
            'p_out_of_stock': bool(issues.get('í’ˆì ˆ', False)),
            'p_complaint': bool(issues.get('ì»´í”Œë ˆì¸', False)),
            'p_group_customer': bool(issues.get('ë‹¨ì²´ì†ë‹˜', False)),
            'p_staff_issue': bool(issues.get('ì§ì›ì´ìŠˆ', False)),
            'p_memo': str(memo) if memo else None,
            'p_sales_items': sales_items_json
        }).execute()
        
        logger.info(f"Daily close saved (transactional): {date_str}")
        
        # ìºì‹œ í´ë¦¬ì–´ (ë°ì´í„° ë³€ê²½ í›„)
        try:
            load_csv.clear()
        except Exception:
            pass
        
        # ========== ì¬ê³  ìë™ ì°¨ê° ê¸°ëŠ¥ ==========
        # íŒë§¤ëœ ë©”ë‰´ì˜ ë ˆì‹œí”¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¬ë£Œ ì‚¬ìš©ëŸ‰ ê³„ì‚° í›„ ì¬ê³  ì°¨ê°
        # ì£¼ì˜: ì¬ê³  ì°¨ê°ì€ íŠ¸ëœì­ì…˜ ì™¸ë¶€ì—ì„œ ì‹¤í–‰ (ë§ˆê° ì €ì¥ê³¼ ë…ë¦½ì )
        if sales_items:
            try:
                # ë ˆì‹œí”¼ ë°ì´í„° ë¡œë“œ
                recipe_result = supabase.table("recipes").select("menu_id,ingredient_id,qty").eq("store_id", store_id).execute()
                
                if recipe_result.data:
                    # ë©”ë‰´ëª… -> ë©”ë‰´ ID ë§¤í•‘
                    menu_result = supabase.table("menu_master").select("id,name").eq("store_id", store_id).execute()
                    menu_map = {m['name']: m['id'] for m in menu_result.data}
                    
                    # ì¬ë£Œ ID -> ì¬ë£Œëª… ë§¤í•‘
                    ingredient_result = supabase.table("ingredients").select("id,name").eq("store_id", store_id).execute()
                    ingredient_map = {i['id']: i['name'] for i in ingredient_result.data}
                    
                    # ì¬ë£Œë³„ ì‚¬ìš©ëŸ‰ ê³„ì‚°
                    ingredient_usage = {}  # {ingredient_id: total_usage}
                    
                    for menu_name, sales_qty in sales_items:
                        if sales_qty > 0 and menu_name in menu_map:
                            menu_id = menu_map[menu_name]
                            
                            # í•´ë‹¹ ë©”ë‰´ì˜ ë ˆì‹œí”¼ ì°¾ê¸°
                            menu_recipes = [r for r in recipe_result.data if r['menu_id'] == menu_id]
                            
                            for recipe in menu_recipes:
                                ingredient_id = recipe['ingredient_id']
                                recipe_qty = float(recipe['qty'])
                                
                                # ì¬ë£Œ ì‚¬ìš©ëŸ‰ = íŒë§¤ìˆ˜ëŸ‰ Ã— ë ˆì‹œí”¼ ì‚¬ìš©ëŸ‰
                                usage = sales_qty * recipe_qty
                                
                                if ingredient_id in ingredient_usage:
                                    ingredient_usage[ingredient_id] += usage
                                else:
                                    ingredient_usage[ingredient_id] = usage
                    
                    # ì¬ê³  ì°¨ê°
                    for ingredient_id, usage_amount in ingredient_usage.items():
                        # í˜„ì¬ ì¬ê³  ì¡°íšŒ
                        inventory_result = supabase.table("inventory").select("on_hand").eq("store_id", store_id).eq("ingredient_id", ingredient_id).execute()
                        
                        if inventory_result.data:
                            current_stock = float(inventory_result.data[0]['on_hand'])
                            new_stock = max(0, current_stock - usage_amount)  # ìŒìˆ˜ ë°©ì§€
                            
                            # ì¬ê³  ì—…ë°ì´íŠ¸
                            supabase.table("inventory").update({
                                "on_hand": new_stock
                            }).eq("store_id", store_id).eq("ingredient_id", ingredient_id).execute()
                            
                            ingredient_name = ingredient_map.get(ingredient_id, f"ID:{ingredient_id}")
                            logger.info(f"Inventory updated: {ingredient_name} - {current_stock:.2f} â†’ {new_stock:.2f} (ì‚¬ìš©ëŸ‰: {usage_amount:.2f})")
            except Exception as e:
                # ì¬ê³  ì°¨ê° ì‹¤íŒ¨í•´ë„ ë§ˆê° ì €ì¥ì€ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ê²½ê³ ë§Œ ë¡œê¹…)
                logger.warning(f"ì¬ê³  ìë™ ì°¨ê° ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë§ˆê°ì€ ì €ì¥ë¨): {e}")
        
        return True
    except Exception as e:
        logger.error(f"Failed to save daily close: {e}")
        # íŠ¸ëœì­ì…˜ í•¨ìˆ˜ê°€ ì‹¤íŒ¨í•˜ë©´ ìë™ ë¡¤ë°±ë¨
        raise


def delete_sales(date, store=None):
    """ë§¤ì¶œ ë°ì´í„° ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        supabase.table("sales").delete().eq("store_id", store_id).eq("date", date_str).execute()
        logger.info(f"Sales deleted: {date_str}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_sales: {date_str}",
            targets=["sales"]
        )
        
        return True, "ì‚­ì œ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to delete sales: {e}")
        raise


def delete_visitor(date):
    """ë°©ë¬¸ì ë°ì´í„° ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        supabase.table("naver_visitors").delete().eq("store_id", store_id).eq("date", date_str).execute()
        logger.info(f"Visitor deleted: {date_str}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_visitor: {date_str}",
            targets=["visitors"]
        )
        
        return True, "ì‚­ì œ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to delete visitor: {e}")
        raise


def save_expense_item(year, month, category, item_name, amount, notes=None):
    """ë¹„ìš©êµ¬ì¡° í•­ëª© ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("expense_structure").insert({
            "store_id": store_id,
            "year": int(year),
            "month": int(month),
            "category": category,
            "item_name": item_name,
            "amount": float(amount),
            "notes": notes if notes else None
        }).execute()
        
        logger.info(f"Expense item saved: {year}-{month}, {category}, {item_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_expense_item: {year}-{month}",
            targets=["cost", "expense_structure"],
            session_keys=['ss_expense_structure_df']
        )
        
        # S6: ë¹„ìš© ì €ì¥ ì§í›„ ìŠ¤ëƒ…ìƒ· (dev_modeì—ì„œë§Œ)
        try:
            from src.auth import is_dev_mode
            if is_dev_mode():
                from src.utils.boot_perf import snapshot_current_metrics
                snapshot_current_metrics("S6: ë¹„ìš© ì €ì¥ ì§í›„ rerun")
        except Exception:
            pass
        
        return True
    except Exception as e:
        logger.error(f"Failed to save expense item: {e}")
        raise


def update_expense_item(expense_id, item_name, amount, notes=None):
    """ë¹„ìš©êµ¬ì¡° í•­ëª© ìˆ˜ì •"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        update_data = {
            "item_name": item_name,
            "amount": float(amount),
            "updated_at": datetime.now(timezone.utc).isoformat()  # DB ì €ì¥ì€ UTC
        }
        if notes is not None:
            update_data["notes"] = notes
        
        supabase.table("expense_structure")\
            .update(update_data)\
            .eq("id", expense_id)\
            .eq("store_id", store_id)\
            .execute()
        
        logger.info(f"Expense item updated: {expense_id}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"update_expense_item: {expense_id}",
            targets=["cost", "expense_structure"],
            session_keys=['ss_expense_structure_df']
        )
        
        # S6: ë¹„ìš© ì €ì¥ ì§í›„ ìŠ¤ëƒ…ìƒ· (dev_modeì—ì„œë§Œ)
        try:
            from src.auth import is_dev_mode
            if is_dev_mode():
                from src.utils.boot_perf import snapshot_current_metrics
                snapshot_current_metrics("S6: ë¹„ìš© ì €ì¥ ì§í›„ rerun")
        except Exception:
            pass
        
        return True, "ìˆ˜ì • ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to update expense item: {e}")
        raise


def delete_expense_item(expense_id):
    """ë¹„ìš©êµ¬ì¡° í•­ëª© ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("expense_structure").delete().eq("id", expense_id).eq("store_id", store_id).execute()
        logger.info(f"Expense item deleted: {expense_id}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_expense_item: {expense_id}",
            targets=["cost", "expense_structure"],
            session_keys=['ss_expense_structure_df']
        )
        
        return True, "ì‚­ì œ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to delete expense item: {e}")
        raise


def _load_expense_structure_impl(year, month, store_id: str, client_mode: str, bypass_cache: bool = False):
    """
    load_expense_structure ë‚´ë¶€ êµ¬í˜„ (ìºì‹œ ìš°íšŒ ì˜µì…˜)
    ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ë©´ ìºì‹œ MISSì„ì„ ì˜ë¯¸ (bypass_cache=Trueì¼ ë•ŒëŠ” ì œì™¸)
    """
    # ë°ì´í„° í˜¸ì¶œ ê³„ì¸¡ ì‹œì‘
    start_time = time.perf_counter()
    
    # ìºì‹œ MISS ë¡œê·¸ ê¸°ë¡ (bypass_cacheê°€ Falseì¼ ë•Œë§Œ, ì¦‰ ìºì‹œë¥¼ ì‚¬ìš©í•˜ë ¤ê³  í–ˆì„ ë•Œë§Œ)
    if not bypass_cache:
        _log_cache_miss("load_expense_structure", year=year, month=month, store_id=store_id, client_mode=client_mode)
    
    # ì¡°íšŒìš© í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (DEV MODEì—ì„œ service_role_key ì‚¬ìš© ê°€ëŠ¥)
    try:
        supabase = get_read_client()
    except Exception as e:
        logger.error(f"Supabase client init failed in load_expense_structure: {e}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_expense_structure({year}-{month}) [ERROR]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame()
    
    if not supabase:
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_expense_structure({year}-{month}) [NO_CLIENT]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame()
    
    # store_idëŠ” ì´ë¯¸ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•˜ì§€ë§Œ, ê²€ì¦ìš©ìœ¼ë¡œ ë‹¤ì‹œ í™•ì¸
    if not store_id:
        store_id = get_current_store_id()
        if not store_id:
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            record_data_call(f"load_expense_structure({year}-{month}) [NO_STORE_ID]", elapsed_ms, rows=0, source="supabase")
            return pd.DataFrame()
    
    # ê°œë°œëª¨ë“œ ë””ë²„ê·¸ ì •ë³´ ìˆ˜ì§‘
    debug_info = {}
    try:
        from src.auth import get_read_client_mode
        if _is_dev_mode():
            debug_info['store_id'] = store_id
            debug_info['client_mode'] = get_read_client_mode()
            
            # Supabase URL ì¶”ì¶œ (í”„ë¡œì íŠ¸ ì‹ë³„ìš©, ì•ë¶€ë¶„ë§Œ)
            try:
                supabase_url = st.secrets.get("supabase", {}).get("url", "")
                if supabase_url:
                    # https://xxxx.supabase.co ì—ì„œ xxxx ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    import re
                    match = re.search(r'https://([^.]+)\.supabase\.co', supabase_url)
                    if match:
                        debug_info['supabase_project'] = match.group(1)
                    else:
                        debug_info['supabase_project'] = "unknown"
                else:
                    debug_info['supabase_project'] = "not_configured"
            except Exception:
                debug_info['supabase_project'] = "error"
            
            # ì¿¼ë¦¬ í•„í„° ì¡°ê±´ ìˆ˜ì§‘
            debug_info['filters'] = [
                f"store_id={store_id}",
                f"year={int(year)}",
                f"month={int(month)}"
            ]
    except Exception:
        pass
    
    try:
        # ì¿¼ë¦¬ ë¹Œë“œ
        query = supabase.table("expense_structure")\
            .select("*")\
            .eq("store_id", store_id)\
            .eq("year", int(year))\
            .eq("month", int(month))
        
        # timed_selectë¡œ ì¿¼ë¦¬ ì‹¤í–‰ ë° íƒ€ì´ë° ê¸°ë¡
        result = timed_select(
            f"load_expense_structure(year={year}, month={month})",
            lambda: query.execute()
        )
        
        # ê°œë°œëª¨ë“œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
        if debug_info:
            try:
                import streamlit as st
                with st.expander("ğŸ” DEBUG: expense_structure ì¡°íšŒ", expanded=False):
                    st.write(f"**CURRENT STORE ID:** {debug_info.get('store_id', 'N/A')}")
                    st.write(f"**DB CLIENT MODE:** {debug_info.get('client_mode', 'N/A')}")
                    st.write(f"**Supabase í”„ë¡œì íŠ¸:** {debug_info.get('supabase_project', 'N/A')}")
                    st.write("**ì¿¼ë¦¬ í•„í„° ì¡°ê±´:**")
                    for filter_cond in debug_info.get('filters', []):
                        st.caption(f"  - {filter_cond}")
                    
                    st.write("**ì¿¼ë¦¬ ì§í›„ ê²°ê³¼:**")
                    row_count = len(result.data) if result.data else 0
                    st.write(f"  - row_count: {row_count}")
                    if result.data and len(result.data) > 0:
                        st.write("  - data[:3]:")
                        import json
                        # ë¯¼ê°í•œ ì •ë³´ ì œê±°í•˜ê³  í‘œì‹œ
                        display_data = []
                        for item in result.data[:3]:
                            safe_item = {k: v for k, v in item.items() if k not in ['id', 'store_id']}
                            display_data.append(safe_item)
                        st.json(display_data)
                    else:
                        st.caption("  (ë°ì´í„° ì—†ìŒ)")
                    
                    # ìºì‹œ ìƒíƒœ í‘œì‹œ
                    if bypass_cache:
                        st.caption("  âš ï¸ ìºì‹œ ìš°íšŒ ëª¨ë“œë¡œ ì‹¤í–‰ë¨")
                    else:
                        st.caption("  â„¹ï¸ ìºì‹œ ì ìš©ë¨ (ìºì‹œ ìš°íšŒí•˜ë ¤ë©´ ì‚¬ì´ë“œë°” í† ê¸€ ì‚¬ìš©)")
            except Exception:
                pass  # ë””ë²„ê·¸ ì¶œë ¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        if result.data:
            df = pd.DataFrame(result.data)
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            record_data_call(f"load_expense_structure({year}-{month})", elapsed_ms, rows=len(df), source="supabase")
            return df
        else:
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            record_data_call(f"load_expense_structure({year}-{month})", elapsed_ms, rows=0, source="supabase")
            return pd.DataFrame(columns=['id', 'category', 'item_name', 'amount', 'notes'])
    except Exception as e:
        logger.error(f"Failed to load expense structure: {e}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_expense_structure({year}-{month}) [EXCEPTION]", elapsed_ms, rows=0, source="supabase")
        # ì—ëŸ¬ë„ ë””ë²„ê·¸ì— í‘œì‹œ
        if debug_info:
            try:
                import streamlit as st
                with st.expander("ğŸ” DEBUG: expense_structure ì¡°íšŒ", expanded=False):
                    st.error(f"**ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨:** {str(e)}")
            except Exception:
                pass
        return pd.DataFrame()


@st.cache_data(ttl=60)  # 1ë¶„ ìºì‹œ (ë¹„ìš©êµ¬ì¡°ëŠ” ìì£¼ ë³€ê²½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì§§ê²Œ, ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í™•ë³´)
def load_expense_structure(year, month, store_id: str = None, client_mode: str = None):
    """
    ë¹„ìš© êµ¬ì¡° ë°ì´í„° ë¡œë“œ
    
    Args:
        year: ì—°ë„
        month: ì›”
        store_id: store_id (Noneì´ë©´ get_current_store_id() ì‚¬ìš©)
        client_mode: client_mode (Noneì´ë©´ get_read_client_mode() ì‚¬ìš©)
    """
    # ê°€ë“œ: ì˜¨ë¼ì¸ì—ì„œëŠ” anonìœ¼ë¡œ read ê¸ˆì§€ (DEVì—ì„œë§Œ í—ˆìš©)
    if client_mode is None:
        client_mode = get_read_client_mode()
    
    if client_mode == "anon" and not _is_dev_mode():
        error_msg = f"âŒ ë³´ì•ˆ ìœ„ë°˜: ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ anon í´ë¼ì´ì–¸íŠ¸ë¡œ ë°ì´í„° ì¡°íšŒ ì‹œë„ (load_expense_structure)"
        logger.error(error_msg)
        st.error(error_msg)
        st.warning("ğŸ’¡ ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”. ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.")
        return {}
    """
    ë¹„ìš©êµ¬ì¡° ë°ì´í„° ë¡œë“œ (íŠ¹ì • ì—°ë„/ì›”)
    ì„¸ì…˜ ìºì‹œ ìš°ì„  ì‚¬ìš© (í˜„ì¬ ì—°ë„/ì›”ë§Œ) â†’ ì—†ìœ¼ë©´ @st.cache_data ìºì‹œ ì‚¬ìš© â†’ ì—†ìœ¼ë©´ DB ì¡°íšŒ
    """
    from datetime import datetime
    
    # í˜„ì¬ ì—°ë„/ì›”ê³¼ ì¼ì¹˜í•˜ë©´ ì„¸ì…˜ ìºì‹œ í™•ì¸ (KST ê¸°ì¤€)
    current_year = current_year_kst()
    current_month = current_month_kst()
    if year == current_year and month == current_month:
        session_key = 'ss_expense_structure_df'
        if session_key in st.session_state:
            if _is_dev_mode():
                logger.debug(f"load_expense_structure: Session cache HIT for {year}-{month}")
            df = st.session_state[session_key]
            # ìºì‹œ íˆíŠ¸ë„ ê³„ì¸¡ (ë§¤ìš° ë¹ ë¦„)
            record_data_call(f"load_expense_structure({year}-{month})", 0.1, rows=len(df), source="session_cache")
            return df
    
    # store_idì™€ client_modeë¥¼ ìºì‹œ í‚¤ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ê¸° ìœ„í•´ ê°€ì ¸ì˜¤ê¸°
    if store_id is None:
        store_id = get_current_store_id()
    if client_mode is None:
        try:
            client_mode = get_read_client_mode()
        except Exception:
            client_mode = "unknown"
    
    # ê°€ë“œ: ì˜¨ë¼ì¸ì—ì„œëŠ” anonìœ¼ë¡œ read ê¸ˆì§€ (DEVì—ì„œë§Œ í—ˆìš©)
    if client_mode == "anon" and not _is_dev_mode():
        error_msg = f"âŒ ë³´ì•ˆ ìœ„ë°˜: ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ anon í´ë¼ì´ì–¸íŠ¸ë¡œ ë°ì´í„° ì¡°íšŒ ì‹œë„ (load_expense_structure)"
        logger.error(error_msg)
        st.error(error_msg)
        st.warning("ğŸ’¡ ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”. ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    
    # ê°œë°œëª¨ë“œì—ì„œ ìºì‹œ ìš°íšŒ ì˜µì…˜ í™•ì¸
    bypass_cache = False
    try:
        if _is_dev_mode():
            bypass_cache = st.session_state.get("_bypass_cache_expense_structure", False)
    except Exception:
        pass
    
    # @st.cache_data ìºì‹œ ë˜ëŠ” DB ì¡°íšŒ
    df = _load_expense_structure_impl(year, month, store_id, client_mode, bypass_cache=bypass_cache)
    
    # í˜„ì¬ ì—°ë„/ì›”ì´ë©´ ì„¸ì…˜ ìºì‹œì— ì €ì¥
    if year == current_year and month == current_month:
        st.session_state['ss_expense_structure_df'] = df
        if _is_dev_mode():
            logger.debug(f"load_expense_structure: Session cache SET for {year}-{month} ({len(df)} rows)")
    
    return df


@st.cache_data(ttl=60)  # 1ë¶„ ìºì‹œ
def load_expense_structure_range(year_start, month_start, year_end, month_end):
    """ë¹„ìš©êµ¬ì¡° ë°ì´í„° ë¡œë“œ (ê¸°ê°„ ë²”ìœ„)"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return pd.DataFrame()
    
    store_id = get_current_store_id()
    if not store_id:
        return pd.DataFrame()
    
    try:
        # ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ í›„ í•„í„°ë§
        result = supabase.table("expense_structure")\
            .select("*")\
            .eq("store_id", store_id)\
            .execute()
        
        if result.data:
            df = pd.DataFrame(result.data)
            # ê¸°ê°„ í•„í„°ë§
            def in_range(row):
                y, m = row['year'], row['month']
                if y < year_start or y > year_end:
                    return False
                if y == year_start and m < month_start:
                    return False
                if y == year_end and m > month_end:
                    return False
                return True
            
            df = df[df.apply(in_range, axis=1)]
            return df
        else:
            return pd.DataFrame(columns=['id', 'category', 'item_name', 'amount', 'notes', 'year', 'month'])
    except Exception as e:
        logger.error(f"Failed to load expense structure range: {e}")
        return pd.DataFrame()


def copy_expense_structure_from_previous_month(year, month):
    """ì „ì›” ë¹„ìš©êµ¬ì¡° ë°ì´í„°ë¥¼ í˜„ì¬ ì›”ë¡œ ë³µì‚¬"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ë³µì‚¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì „ì›” ê³„ì‚°
        prev_month = month - 1
        prev_year = year
        if prev_month == 0:
            prev_month = 12
            prev_year = year - 1
        
        # ì „ì›” ë°ì´í„° ë¡œë“œ
        prev_data = load_expense_structure(prev_year, prev_month)
        if prev_data.empty:
            return False, "ë³µì‚¬í•  ì „ì›” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # í˜„ì¬ ì›” ë°ì´í„° í™•ì¸
        current_data = load_expense_structure(year, month)
        if not current_data.empty:
            return False, "ì´ë¯¸ í˜„ì¬ ì›”ì— ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ì‚­ì œí•´ì£¼ì„¸ìš”."
        
        # ì „ì›” ë°ì´í„° ë³µì‚¬
        records = []
        for _, row in prev_data.iterrows():
            records.append({
                "store_id": store_id,
                "year": int(year),
                "month": int(month),
                "category": row['category'],
                "item_name": row['item_name'],
                "amount": float(row['amount']),
                "notes": row.get('notes')
            })
        
        if records:
            supabase.table("expense_structure").insert(records).execute()
            logger.info(f"Expense structure copied from {prev_year}-{prev_month} to {year}-{month}")
            return True, f"ì „ì›”({prev_year}ë…„ {prev_month}ì›”) ë°ì´í„°ê°€ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            return False, "ë³µì‚¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.error(f"Failed to copy expense structure: {e}")
        raise


def create_backup():
    """ë°ì´í„° ë°±ì—… (DB ê¸°ë°˜ì—ì„œëŠ” ë‹¨ìˆœ ë¡œê·¸ë§Œ)"""
    logger = logging.getLogger(__name__)
    logger.info("Backup requested (DB mode - data is already persisted in Supabase)")
    return True, "ë°ì´í„°ëŠ” Supabaseì— ìë™ìœ¼ë¡œ ì˜êµ¬ ì €ì¥ë©ë‹ˆë‹¤."


# ============================================
# Phase 1: ê³µê¸‰ì—…ì²´ ë° ë°œì£¼ ì´ë ¥ ê´€ë¦¬ í•¨ìˆ˜
# ============================================

def save_supplier(supplier_name, phone=None, email=None, delivery_days=None, 
                  min_order_amount=0, delivery_fee=0, notes=None):
    """ê³µê¸‰ì—…ì²´ ë“±ë¡/ìˆ˜ì •"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("suppliers").upsert({
            "store_id": store_id,
            "name": supplier_name,
            "phone": phone or "",
            "email": email or "",
            "delivery_days": delivery_days or "",
            "min_order_amount": float(min_order_amount) if min_order_amount else 0,
            "delivery_fee": float(delivery_fee) if delivery_fee else 0,
            "notes": notes or ""
        }, on_conflict="store_id,name").execute()
        
        logger.info(f"Supplier saved: {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to save supplier: {e}")
        raise


def delete_supplier(supplier_name):
    """ê³µê¸‰ì—…ì²´ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("suppliers").delete().eq("store_id", store_id).eq("name", supplier_name).execute()
        logger.info(f"Supplier deleted: {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to delete supplier: {e}")
        raise


def save_ingredient_supplier(ingredient_name, supplier_name, unit_price, is_default=True):
    """ì¬ë£Œ-ê³µê¸‰ì—…ì²´ ë§¤í•‘ ì €ì¥

    Notes
    -----
    - unit_price ì¸ìëŠ” **ë°œì£¼ ë‹¨ìœ„ ê¸°ì¤€ ë‹¨ê°€(ì›/ë°œì£¼ë‹¨ìœ„)** ë¡œ ì „ë‹¬ëœë‹¤ê³  ê°€ì •í•œë‹¤.
    - ingredients í…Œì´ë¸”ì˜ conversion_rate ì»¬ëŸ¼ì„ ì‚¬ìš©í•´
      ê¸°ë³¸ ë‹¨ìœ„ ë‹¨ê°€(ì›/ê¸°ë³¸ë‹¨ìœ„)ë¡œ í™˜ì‚°í•´ì„œ DBì— ì €ì¥í•œë‹¤.
      (1 ë°œì£¼ë‹¨ìœ„ = conversion_rate * ê¸°ë³¸ë‹¨ìœ„)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ID ë° ë³€í™˜ ë¹„ìœ¨ ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id,conversion_rate").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_row = ing_result.data[0]
        ingredient_id = ingredient_row['id']
        conversion_rate = ingredient_row.get('conversion_rate', 1.0) or 1.0
        
        # ê³µê¸‰ì—…ì²´ ID ì°¾ê¸°
        sup_result = supabase.table("suppliers").select("id").eq("store_id", store_id).eq("name", supplier_name).execute()
        if not sup_result.data:
            raise Exception(f"ê³µê¸‰ì—…ì²´ '{supplier_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        supplier_id = sup_result.data[0]['id']
        
        # ê¸°ë³¸ ê³µê¸‰ì—…ì²´ì¸ ê²½ìš°, ë‹¤ë¥¸ ê¸°ë³¸ ê³µê¸‰ì—…ì²´ í•´ì œ
        if is_default:
            # í•´ë‹¹ ì¬ë£Œì˜ ë‹¤ë¥¸ ê¸°ë³¸ ê³µê¸‰ì—…ì²´ í•´ì œ
            existing = supabase.table("ingredient_suppliers").select("id").eq("store_id", store_id).eq("ingredient_id", ingredient_id).eq("is_default", True).execute()
            if existing.data:
                for item in existing.data:
                    supabase.table("ingredient_suppliers").update({"is_default": False}).eq("id", item['id']).execute()
        
        # ë°œì£¼ ë‹¨ê°€(ì›/ë°œì£¼ë‹¨ìœ„)ë¥¼ ê¸°ë³¸ ë‹¨ìœ„ ë‹¨ê°€(ì›/ê¸°ë³¸ë‹¨ìœ„)ë¡œ í™˜ì‚°
        try:
            conv = float(conversion_rate)
            price_per_order_unit = float(unit_price)
            if conv > 0:
                base_unit_price = price_per_order_unit / conv
            else:
                base_unit_price = price_per_order_unit
        except Exception:
            base_unit_price = float(unit_price)

        # ì¬ë£Œ-ê³µê¸‰ì—…ì²´ ë§¤í•‘ ì €ì¥ (ê¸°ë³¸ ë‹¨ìœ„ ë‹¨ê°€ ê¸°ì¤€)
        supabase.table("ingredient_suppliers").upsert({
            "store_id": store_id,
            "ingredient_id": ingredient_id,
            "supplier_id": supplier_id,
            "unit_price": float(base_unit_price),
            "is_default": is_default
        }, on_conflict="store_id,ingredient_id,supplier_id").execute()
        
        logger.info(f"Ingredient-supplier mapping saved: {ingredient_name} -> {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to save ingredient-supplier mapping: {e}")
        raise


def delete_ingredient_supplier(ingredient_name, supplier_name):
    """ì¬ë£Œ-ê³µê¸‰ì—…ì²´ ë§¤í•‘ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_id = ing_result.data[0]['id']
        
        # ê³µê¸‰ì—…ì²´ ID ì°¾ê¸°
        sup_result = supabase.table("suppliers").select("id").eq("store_id", store_id).eq("name", supplier_name).execute()
        if not sup_result.data:
            raise Exception(f"ê³µê¸‰ì—…ì²´ '{supplier_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        supplier_id = sup_result.data[0]['id']
        
        supabase.table("ingredient_suppliers").delete().eq("store_id", store_id).eq("ingredient_id", ingredient_id).eq("supplier_id", supplier_id).execute()
        logger.info(f"Ingredient-supplier mapping deleted: {ingredient_name} -> {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to delete ingredient-supplier mapping: {e}")
        raise


def save_order(order_date, ingredient_name, supplier_name, quantity, unit_price, 
               total_amount, status="ì˜ˆì •", expected_delivery_date=None, notes=None):
    """ë°œì£¼ ì´ë ¥ ì €ì¥
    
    ì£¼ì˜
    ----
    - quantity, unit_price ëŠ” **ê¸°ë³¸ ë‹¨ìœ„ ê¸°ì¤€** ê°’ì´ë‹¤.
      (ì˜ˆ: quantity = g, unit_price = ì›/g)
    - UI ë‹¨ì—ì„œ ë°œì£¼ë‹¨ìœ„(ê°œ, ë°•ìŠ¤ ë“±)ë¥¼ ì‚¬ìš©í•˜ë”ë¼ë„,
      ì´ í•¨ìˆ˜ì— ë“¤ì–´ì˜¬ ë•ŒëŠ” ë°˜ë“œì‹œ ê¸°ë³¸ ë‹¨ìœ„ë¡œ í™˜ì‚°í•´ì„œ ë„£ì–´ì•¼ í•œë‹¤.
      (í™˜ì‚° ë¡œì§ì€ `order_service.py` ë“±ì— ëª¨ì•„ ê´€ë¦¬í•œë‹¤.)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_id = ing_result.data[0]['id']
        
        # ê³µê¸‰ì—…ì²´ ID ì°¾ê¸°
        sup_result = supabase.table("suppliers").select("id").eq("store_id", store_id).eq("name", supplier_name).execute()
        if not sup_result.data:
            raise Exception(f"ê³µê¸‰ì—…ì²´ '{supplier_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        supplier_id = sup_result.data[0]['id']
        
        # ë°œì£¼ ì €ì¥
        result = supabase.table("orders").insert({
            "store_id": store_id,
            "order_date": order_date.strftime("%Y-%m-%d") if isinstance(order_date, datetime) else str(order_date),
            "ingredient_id": ingredient_id,
            "supplier_id": supplier_id,
            "quantity": float(quantity),
            "unit_price": float(unit_price),
            "total_amount": float(total_amount),
            "status": status,
            "expected_delivery_date": expected_delivery_date.strftime("%Y-%m-%d") if expected_delivery_date and isinstance(expected_delivery_date, datetime) else (str(expected_delivery_date) if expected_delivery_date else None),
            "notes": notes or ""
        }).execute()
        
        logger.info(f"Order saved: {ingredient_name} from {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to save order: {e}")
        raise


def update_order_status(order_id, status, actual_delivery_date=None):
    """ë°œì£¼ ìƒíƒœ ì—…ë°ì´íŠ¸
    
    - status ê°€ 'ì…ê³ ì™„ë£Œ' ì´ê³  actual_delivery_date ê°€ ìˆì„ ë•Œ ì¬ê³ (on_hand)ë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤.
    - ì¤‘ë³µ ì…ê³  ë°˜ì˜ì„ ë§‰ê¸° ìœ„í•´ orders.inventory_applied í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•œë‹¤.
      (ë‹¨, í•´ë‹¹ ì»¬ëŸ¼ì´ ì•„ì§ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ, ì—†ìœ¼ë©´ ì¡°ìš©íˆ ê±´ë„ˆë›´ë‹¤.)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        update_data = {"status": status}
        if actual_delivery_date:
            update_data["actual_delivery_date"] = actual_delivery_date.strftime("%Y-%m-%d") if isinstance(actual_delivery_date, datetime) else str(actual_delivery_date)
        
        # ì…ê³  ì™„ë£Œ ì‹œ ì¬ê³  ë°˜ì˜ (inventory_applied í”Œë˜ê·¸ ê¸°ë°˜, idempotent)
        if status == "ì…ê³ ì™„ë£Œ" and actual_delivery_date:
            # ë°œì£¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (inventory_applied í¬í•¨ ì‹œë„)
            order_result = supabase.table("orders")\
                .select("ingredient_id,quantity,inventory_applied")\
                .eq("id", order_id)\
                .eq("store_id", store_id)\
                .execute()
            if order_result.data:
                row = order_result.data[0]
                ingredient_id = row.get("ingredient_id")
                quantity = row.get("quantity", 0)
                inventory_applied = bool(row.get("inventory_applied", False))

                # ì•„ì§ ì¬ê³  ë°˜ì˜ì´ ì•ˆ ëœ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                if ingredient_id and not inventory_applied:
                    inv_result = supabase.table("inventory")\
                        .select("on_hand")\
                        .eq("store_id", store_id)\
                        .eq("ingredient_id", ingredient_id)\
                        .execute()
                    if inv_result.data:
                        current_stock = float(inv_result.data[0].get("on_hand", 0) or 0)
                        new_stock = current_stock + float(quantity or 0)
                        supabase.table("inventory")\
                            .update({"on_hand": new_stock})\
                            .eq("store_id", store_id)\
                            .eq("ingredient_id", ingredient_id)\
                            .execute()

                    # ì¬ê³  ë°˜ì˜ ì™„ë£Œ í‘œì‹œ (ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¡°ìš©íˆ ë¬´ì‹œ)
                    try:
                        supabase.table("orders")\
                            .update({"inventory_applied": True})\
                            .eq("id", order_id)\
                            .eq("store_id", store_id)\
                            .execute()
                    except Exception as e:
                        logger.warning(f"inventory_applied ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”í•  ìˆ˜ ìˆìŒ): {e}")

        # ìƒíƒœ/ì…ê³ ì¼ ì—…ë°ì´íŠ¸
        supabase.table("orders").update(update_data).eq("id", order_id).eq("store_id", store_id).execute()
        logger.info(f"Order status updated: {order_id} -> {status}")
        return True
    except Exception as e:
        logger.error(f"Failed to update order status: {e}")
        raise


# ============================================
# Phase B: ì‹¤ì œì •ì‚° ë¹„ìš© í•­ëª© í…œí”Œë¦¿ ê´€ë¦¬
# ============================================

def load_cost_item_templates(store_id: str):
    """
    ë¹„ìš© í•­ëª© í…œí”Œë¦¿ ë¡œë“œ (is_active=trueë§Œ)
    
    Args:
        store_id: ë§¤ì¥ ID
    
    Returns:
        list: í…œí”Œë¦¿ í•­ëª© ë¦¬ìŠ¤íŠ¸ (category, item_name, item_type, is_recurring, recurring_value, sort_order)
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return []
        
        result = supabase.table("cost_item_templates")\
            .select("*")\
            .eq("store_id", store_id)\
            .eq("is_active", True)\
            .order("category")\
            .order("sort_order")\
            .order("item_name")\
            .execute()
        
        logger.info(f"Loaded {len(result.data) if result.data else 0} cost item templates")
        return result.data if result.data else []
    except Exception as e:
        logger.error(f"Failed to load cost item templates: {e}")
        return []


def save_cost_item_template(
    store_id: str,
    category: str,
    item_name: str,
    item_type: str = 'normal',
    is_recurring: bool = False,
    recurring_value: float = 0.0,
    sort_order: int = 0
):
    """
    ë¹„ìš© í•­ëª© í…œí”Œë¦¿ ì €ì¥/ì—…ë°ì´íŠ¸ (upsert)
    
    Args:
        store_id: ë§¤ì¥ ID
        category: ì¹´í…Œê³ ë¦¬ (ì„ì°¨ë£Œ, ì¸ê±´ë¹„, ì¬ë£Œë¹„, ê³µê³¼ê¸ˆ, ë¶€ê°€ì„¸&ì¹´ë“œìˆ˜ìˆ˜ë£Œ)
        item_name: í•­ëª©ëª…
        item_type: í•­ëª© ìœ í˜• ('normal' | 'fixed' | 'percent')
        is_recurring: ë°˜ë³µ ì—¬ë¶€
        recurring_value: ë°˜ë³µ ê°’
        sort_order: ì •ë ¬ ìˆœì„œ
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return False
        
        # upsert (store_id, category, item_name ê¸°ì¤€)
        supabase.table("cost_item_templates").upsert({
            "store_id": store_id,
            "category": category,
            "item_name": item_name,
            "item_type": item_type,
            "is_recurring": is_recurring,
            "recurring_value": float(recurring_value),
            "sort_order": int(sort_order),
            "is_active": True
        }, on_conflict="store_id,category,item_name").execute()
        
        logger.info(f"Cost item template saved: {category} - {item_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to save cost item template: {e}")
        raise


def soft_delete_cost_item_template(store_id: str, category: str, item_name: str):
    """
    ë¹„ìš© í•­ëª© í…œí”Œë¦¿ Soft Delete (is_active=falseë¡œ ì—…ë°ì´íŠ¸)
    
    Args:
        store_id: ë§¤ì¥ ID
        category: ì¹´í…Œê³ ë¦¬
        item_name: í•­ëª©ëª…
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return False
        
        supabase.table("cost_item_templates")\
            .update({"is_active": False})\
            .eq("store_id", store_id)\
            .eq("category", category)\
            .eq("item_name", item_name)\
            .execute()
        
        logger.info(f"Cost item template soft deleted: {category} - {item_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to soft delete cost item template: {e}")
        raise


# ============================================
# Phase C: ì‹¤ì œì •ì‚° ì›”ë³„ ê¸ˆì•¡/ë¹„ìœ¨ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
# ============================================

def load_actual_settlement_items(store_id: str, year: int, month: int):
    """
    ì‹¤ì œì •ì‚° ì›”ë³„ í•­ëª© ê°’ ë¡œë“œ
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        list: ì €ì¥ëœ í•­ëª© ê°’ ë¦¬ìŠ¤íŠ¸ (template_id, amount, percent, status)
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return []
        
        result = supabase.table("actual_settlement_items")\
            .select("*")\
            .eq("store_id", store_id)\
            .eq("year", int(year))\
            .eq("month", int(month))\
            .execute()
        
        logger.info(f"Loaded {len(result.data) if result.data else 0} actual settlement items for {year}-{month}")
        return result.data if result.data else []
    except Exception as e:
        logger.error(f"Failed to load actual settlement items: {e}")
        return []


def upsert_actual_settlement_item(
    store_id: str,
    year: int,
    month: int,
    template_id: int,
    amount: float = None,
    percent: float = None,
    status: str = 'draft'
):
    """
    ì‹¤ì œì •ì‚° ì›”ë³„ í•­ëª© ê°’ ì €ì¥/ì—…ë°ì´íŠ¸ (upsert)
    Phase C.5: input_typeì— ë”°ë¼ amount ë˜ëŠ” percentë§Œ ì €ì¥ (ë‹¤ë¥¸ ê°’ì€ None ë˜ëŠ” 0)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
        template_id: í…œí”Œë¦¿ ID (cost_item_templates.id)
        amount: ê¸ˆì•¡ (input_type='amount'ì¼ ë•Œ)
        percent: ë¹„ìœ¨ (input_type='rate'ì¼ ë•Œ)
        status: ìƒíƒœ ('draft' | 'final')
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return False
        
        upsert_data = {
            "store_id": store_id,
            "year": int(year),
            "month": int(month),
            "template_id": int(template_id),
            "status": status,
        }
        
        # Phase C.5: input_typeì— ë”°ë¼ ì„ íƒì  ì €ì¥
        # amountê°€ ìˆìœ¼ë©´ amount ì €ì¥, percentëŠ” None (ì˜ë¯¸ ëª…í™•)
        # percentê°€ ìˆìœ¼ë©´ percent ì €ì¥, amountëŠ” None
        if amount is not None:
            upsert_data["amount"] = float(amount)
            upsert_data["percent"] = None  # Phase C.5: ëª…í™•ì„±ì„ ìœ„í•´ None
        elif percent is not None:
            upsert_data["percent"] = float(percent)
            upsert_data["amount"] = None  # Phase C.5: ëª…í™•ì„±ì„ ìœ„í•´ None
        else:
            # ë‘˜ ë‹¤ Noneì´ë©´ 0ìœ¼ë¡œ ì €ì¥ (ê¸°ì¡´ ì •ì±… ìœ ì§€)
            upsert_data["amount"] = 0.0
            upsert_data["percent"] = 0.0
        
        # upsert (store_id, year, month, template_id ê¸°ì¤€)
        supabase.table("actual_settlement_items").upsert(
            upsert_data,
            on_conflict="store_id,year,month,template_id"
        ).execute()
        
        logger.info(f"Actual settlement item saved: {year}-{month}, template_id={template_id}, amount={amount}, percent={percent}")
        return True
    except Exception as e:
        logger.error(f"Failed to upsert actual settlement_item: {e}")
        raise


# ============================================
# Phase D: ì‹¤ì œì •ì‚° - sales í…Œì´ë¸”ì—ì„œ ì›”ë§¤ì¶œ ìë™ ë¶ˆëŸ¬ì˜¤ê¸°
# ============================================

@st.cache_data(ttl=60, show_spinner=False)  # 1ë¶„ ìºì‹œ (ì›”ì´ ë°”ë€Œê±°ë‚˜ ì…ë ¥ ì¦‰ì‹œ ë°˜ì˜)
def load_monthly_sales_total(store_id: str, year: int, month: int) -> int:
    """
    sales í…Œì´ë¸”ì—ì„œ ì›”ë§¤ì¶œ í•©ê³„ ì¡°íšŒ (KST ê¸°ì¤€)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        int: ì›”ë§¤ì¶œ í•©ê³„ (ì› ë‹¨ìœ„)
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return 0
        
        # KST ê¸°ì¤€ ì›” ì‹œì‘/ë ê³„ì‚°
        KST = ZoneInfo("Asia/Seoul")
        start_kst = datetime(year, month, 1, 0, 0, 0, tzinfo=KST)
        
        # ë‹¤ìŒë‹¬ 1ì¼ 0ì‹œ (ë¯¸í¬í•¨)
        if month == 12:
            end_kst = datetime(year + 1, 1, 1, 0, 0, 0, tzinfo=KST)
        else:
            end_kst = datetime(year, month + 1, 1, 0, 0, 0, tzinfo=KST)
        
        # DATE íƒ€ì…ì´ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜ (YYYY-MM-DD)
        start_date_str = start_kst.date().isoformat()
        end_date_str = end_kst.date().isoformat()
        
        # sales í…Œì´ë¸” ì¡°íšŒ: store_id + ë‚ ì§œ ë²”ìœ„ í•„í„°
        # date >= start_date AND date < end_date
        result = supabase.table("sales")\
            .select("total_sales")\
            .eq("store_id", store_id)\
            .gte("date", start_date_str)\
            .lt("date", end_date_str)\
            .execute()
        
        # í•©ì‚° (total_sales ì»¬ëŸ¼ ì‚¬ìš©)
        if result.data:
            total = sum(float(row.get('total_sales', 0) or 0) for row in result.data)
            row_count = len(result.data)
            logger.info(f"Monthly sales total loaded: {year}-{month}, {row_count} rows, total={total:,.0f}ì›")
            return int(total)
        else:
            logger.info(f"Monthly sales total loaded: {year}-{month}, 0 rows, total=0ì›")
            return 0
    except Exception as e:
        logger.error(f"Failed to load monthly sales total: {e}")
        return 0


# ============================================
# Phase F: ì‹¤ì œì •ì‚° í™•ì •(Final) + ì ê¸ˆ(ì½ê¸°ì „ìš©) + í™•ì • í•´ì œ
# ============================================

@st.cache_data(ttl=30, show_spinner=False)  # 30ì´ˆ ìºì‹œ
def get_month_settlement_status(store_id: str, year: int, month: int) -> str:
    """
    ì›”ë³„ ì •ì‚° ìƒíƒœ ì¡°íšŒ (draft | final)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        str: 'draft' ë˜ëŠ” 'final'
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return 'draft'
        
        # status='final'ì´ 1ê°œë¼ë„ ìˆìœ¼ë©´ 'final', ì•„ë‹ˆë©´ 'draft'
        result = supabase.table("actual_settlement_items")\
            .select("status", count='exact')\
            .eq("store_id", store_id)\
            .eq("year", int(year))\
            .eq("month", int(month))\
            .eq("status", "final")\
            .limit(1)\
            .execute()
        
        # finalì´ 1ê°œë¼ë„ ìˆìœ¼ë©´ 'final'
        if result.data and len(result.data) > 0:
            logger.info(f"Month settlement status: {year}-{month} = final")
            return 'final'
        else:
            logger.info(f"Month settlement status: {year}-{month} = draft")
            return 'draft'
    except Exception as e:
        logger.error(f"Failed to get month settlement status: {e}")
        return 'draft'  # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ì€ draft


def set_month_settlement_status(store_id: str, year: int, month: int, status: str) -> int:
    """
    ì›”ë³„ ì •ì‚° ìƒíƒœ ì„¤ì • (draft | final)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
        status: 'draft' ë˜ëŠ” 'final'
    
    Returns:
        int: ì—…ë°ì´íŠ¸ëœ row count
    """
    if status not in ['draft', 'final']:
        raise ValueError(f"Invalid status: {status}. Must be 'draft' or 'final'")
    
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return 0
        
        # ì›” ì „ì²´ ì¼ê´„ ì—…ë°ì´íŠ¸
        result = supabase.table("actual_settlement_items")\
            .update({
                "status": status,
                "updated_at": datetime.now(timezone.utc).isoformat()
            })\
            .eq("store_id", store_id)\
            .eq("year", int(year))\
            .eq("month", int(month))\
            .execute()
        
        affected_count = len(result.data) if result.data else 0
        logger.info(f"Month settlement status updated: {year}-{month} = {status}, affected={affected_count} rows")
        
        # ìºì‹œ ë¬´íš¨í™”
        try:
            get_month_settlement_status.clear()
            # load_actual_settlement_itemsëŠ” í•¨ìˆ˜ê°€ ì•„ë‹ˆë¯€ë¡œ ì§ì ‘ clear ë¶ˆê°€
            # ëŒ€ì‹  ìºì‹œ í‚¤ ê¸°ë°˜ìœ¼ë¡œ ë¬´íš¨í™” (í•„ìš” ì‹œ)
        except Exception:
            pass
        
        return affected_count
    except Exception as e:
        logger.error(f"Failed to set month settlement status: {e}")
        raise
