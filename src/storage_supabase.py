"""
Supabase ê¸°ë°˜ ì €ì¥ì†Œ ëª¨ë“ˆ (ê¸°ì¡´ storage.pyì˜ DB ë²„ì „)
auth.uid() ê¸°ë°˜ RLSë¡œ ë³´ì•ˆ ì ìš©
"""
import pandas as pd
import logging
from datetime import datetime, timezone
from typing import Optional, List, Tuple
import json
from zoneinfo import ZoneInfo
from src.utils.time_utils import now_kst, today_kst, current_year_kst, current_month_kst

# auth.pyì—ì„œ í•¨ìˆ˜ import (is_dev_modeëŠ” _is_dev_modeë¡œ aliasí•˜ì—¬ ì´ë¦„ ì¶©ëŒ ë°©ì§€)
from src.auth import get_supabase_client, get_current_store_id, get_read_client, get_read_client_mode, is_dev_mode as _is_dev_mode
import streamlit as st
import time
from functools import wraps

# boot_perfì—ì„œ ë°ì´í„° í˜¸ì¶œ ê³„ì¸¡ í•¨ìˆ˜ import
try:
    from src.utils.boot_perf import record_data_call
except ImportError:
    # boot_perfê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„í•œ fallback
    def record_data_call(name: str, ms: float, rows: int = None, source: str = None):
        pass

# cache_tokensì—ì„œ ë²„ì „ í† í° í•¨ìˆ˜ import
try:
    from src.utils.cache_tokens import bump_data_version, bump_versions
except ImportError:
    # cache_tokensê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„í•œ fallback
    def bump_data_version(name: str):
        pass
    def bump_versions(names: List[str]):
        pass

logger = logging.getLogger(__name__)

# ì¿¼ë¦¬ íƒ€ì´ë° ë¡œê·¸ ì €ì¥ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
_query_timing_log = []
_MAX_QUERY_LOG = 50  # ìµœëŒ€ ì €ì¥í•  ì¿¼ë¦¬ ë¡œê·¸ ê°œìˆ˜

# ìºì‹œ MISS ë¡œê·¸ ì €ì¥ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
_cache_miss_log = []
_MAX_CACHE_LOG = 50  # ìµœëŒ€ ì €ì¥í•  ìºì‹œ MISS ë¡œê·¸ ê°œìˆ˜


def setup_logger():
    """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
    if not logger.handlers:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
    return logger


setup_logger()


# ============================================
# Client Mode & Query Timing Functions
# ============================================

def get_client_mode() -> str:
    """
    í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ DB í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ ë°˜í™˜
    
    Returns:
        "anon" / "auth" / "service_role_dev"
    """
    try:
        return get_read_client_mode()
    except Exception:
        return "unknown"


def timed_select(query_name: str, query_func, *args, **kwargs):
    """
    Supabase select ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  íƒ€ì´ë°ì„ ê¸°ë¡í•˜ëŠ” í—¬í¼
    
    Args:
        query_name: ì¿¼ë¦¬ ì´ë¦„ (ë¡œê·¸ì— í‘œì‹œë  ì´ë¦„)
        query_func: ì‹¤í–‰í•  ì¿¼ë¦¬ í•¨ìˆ˜ (ì˜ˆ: lambda: supabase.table("menu_master").select("*").execute())
        *args, **kwargs: query_funcì— ì „ë‹¬í•  ì¸ì
    
    Returns:
        ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼
    """
    global _query_timing_log  # í•¨ìˆ˜ ìµœìƒë‹¨ì— global ì„ ì–¸
    start_time = time.time()
    try:
        result = query_func(*args, **kwargs)
        elapsed_ms = (time.time() - start_time) * 1000
        row_count = len(result.data) if result.data else 0
        
        # ê°œë°œëª¨ë“œì—ì„œë§Œ ë¡œê·¸ ì €ì¥
        if _is_dev_mode():
            _query_timing_log.append({
                "query_name": query_name,
                "ms": round(elapsed_ms, 2),
                "rows": row_count,
                "timestamp": time.time()
            })
            # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
            if len(_query_timing_log) > _MAX_QUERY_LOG:
                _query_timing_log[:] = _query_timing_log[-_MAX_QUERY_LOG:]
        
        logger.debug(f"Query '{query_name}': {elapsed_ms:.2f}ms, {row_count} rows")
        return result
    except Exception as e:
        elapsed_ms = (time.time() - start_time) * 1000
        logger.error(f"Query '{query_name}' failed after {elapsed_ms:.2f}ms: {e}")
        if _is_dev_mode():
            _query_timing_log.append({
                "query_name": f"{query_name} (ERROR)",
                "ms": round(elapsed_ms, 2),
                "rows": 0,
                "timestamp": time.time(),
                "error": str(e)
            })
        raise


def get_query_timing_log() -> list:
    """
    ì¿¼ë¦¬ íƒ€ì´ë° ë¡œê·¸ ë°˜í™˜ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
    
    Returns:
        ìµœê·¼ ì¿¼ë¦¬ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
    """
    if _is_dev_mode():
        return _query_timing_log.copy()
    return []


def clear_query_timing_log():
    """ì¿¼ë¦¬ íƒ€ì´ë° ë¡œê·¸ ì´ˆê¸°í™”"""
    global _query_timing_log
    _query_timing_log = []


def _log_cache_miss(function_name: str, **kwargs):
    """
    ìºì‹œ MISS ë¡œê·¸ ê¸°ë¡ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
    
    Args:
        function_name: í•¨ìˆ˜ ì´ë¦„ (ì˜ˆ: "load_csv", "load_expense_structure")
        **kwargs: ìºì‹œ í‚¤ì— í¬í•¨ëœ íŒŒë¼ë¯¸í„°ë“¤ (filename, store_id, client_mode, year, month ë“±)
    """
    try:
        if _is_dev_mode():
            global _cache_miss_log
            # ë¯¼ê° ì •ë³´ ì œê±°
            safe_kwargs = {}
            for key, value in kwargs.items():
                if key in ['store_id', 'client_mode', 'filename', 'year', 'month']:
                    # store_idëŠ” ì¼ë¶€ë§Œ í‘œì‹œ (ë³´ì•ˆ)
                    if key == 'store_id' and value:
                        safe_kwargs[key] = f"{str(value)[:8]}..." if len(str(value)) > 8 else str(value)
                    else:
                        safe_kwargs[key] = value
            
            _cache_miss_log.append({
                "function": function_name,
                "timestamp": time.time(),
                "params": safe_kwargs
            })
            # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
            if len(_cache_miss_log) > _MAX_CACHE_LOG:
                _cache_miss_log = _cache_miss_log[-_MAX_CACHE_LOG:]
    except Exception:
        pass  # ë¡œê·¸ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰


def get_cache_miss_log() -> list:
    """
    ìºì‹œ MISS ë¡œê·¸ ë°˜í™˜ (ê°œë°œëª¨ë“œì—ì„œë§Œ)
    
    Returns:
        ìµœê·¼ ìºì‹œ MISS ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
    """
    if _is_dev_mode():
        return _cache_miss_log.copy()
    return []


def clear_cache_miss_log():
    """ìºì‹œ MISS ë¡œê·¸ ì´ˆê¸°í™”"""
    global _cache_miss_log
    _cache_miss_log = []


# ============================================
# Helper Functions
# ============================================

def _get_id_by_name(supabase, table_name: str, name_column: str, name_value: str, store_id: str = None):
    """
    ì´ë¦„ìœ¼ë¡œ ID ì¡°íšŒ (ê³µí†µ í—¬í¼ í•¨ìˆ˜)
    
    Args:
        supabase: Supabase í´ë¼ì´ì–¸íŠ¸
        table_name: í…Œì´ë¸”ëª…
        name_column: ì´ë¦„ ì»¬ëŸ¼ëª… (ì˜ˆ: 'name')
        name_value: ì¡°íšŒí•  ì´ë¦„ ê°’
        store_id: store_id í•„í„° (Noneì´ë©´ ì‚¬ìš© ì•ˆ í•¨)
    
    Returns:
        str: ID (ì—†ìœ¼ë©´ None)
    """
    try:
        query = supabase.table(table_name).select("id")
        if store_id:
            query = query.eq("store_id", store_id)
        query = query.eq(name_column, name_value)
        # timed_selectë¡œ ì¿¼ë¦¬ ì‹¤í–‰ ë° íƒ€ì´ë° ê¸°ë¡
        result = timed_select(
            f"_get_id_by_name({table_name}.{name_column}={name_value})",
            lambda: query.execute()
        )
        if result.data:
            return result.data[0]['id']
        return None
    except Exception as e:
        logger.error(f"Failed to get ID for {table_name}.{name_column}={name_value}: {e}")
        return None


def _check_duplicate(supabase, table_name: str, name_column: str, name_value: str, store_id: str):
    """
    ì¤‘ë³µ ì²´í¬ (ê³µí†µ í—¬í¼ í•¨ìˆ˜)
    
    Args:
        supabase: Supabase í´ë¼ì´ì–¸íŠ¸
        table_name: í…Œì´ë¸”ëª…
        name_column: ì´ë¦„ ì»¬ëŸ¼ëª…
        name_value: ì²´í¬í•  ì´ë¦„ ê°’
        store_id: store_id
    
    Returns:
        bool: ì¤‘ë³µì´ë©´ True
    """
    try:
        query = supabase.table(table_name).select("id").eq("store_id", store_id).eq(name_column, name_value)
        # timed_selectë¡œ ì¿¼ë¦¬ ì‹¤í–‰ ë° íƒ€ì´ë° ê¸°ë¡
        result = timed_select(
            f"_check_duplicate({table_name}.{name_column}={name_value})",
            lambda: query.execute()
        )
        return len(result.data) > 0
    except Exception:
        return False


def _check_supabase_for_dev_mode():
    """
    Supabase í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜ (ì—ëŸ¬ ì²˜ë¦¬)
    
    DEV MODE(st.session_state['dev_mode'] == True)ì—ì„œëŠ”
    Supabaseë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Noneì„ ë°˜í™˜í•˜ê³ ,
    í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ì´ë¥¼ ê°ì§€í•´ ë¡œì»¬/ë¹ˆ ë°ì´í„°ë¡œ ì²˜ë¦¬í•˜ê²Œ í•œë‹¤.
    """
    # DEV MODEì—ì„œëŠ” Supabaseë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    if st.session_state.get("dev_mode", False):
        logger.info("DEV MODE: Supabase client is disabled (returning None).")
        return None
    
    supabase = get_supabase_client()
    if not supabase:
        raise Exception("Supabase not available")
    return supabase


# ============================================
# Session Cache Utilities (ì„¸ì…˜ ìºì‹œ ìœ í‹¸)
# ============================================

def get_session_df(key: str, loader_fn, *args, **kwargs):
    """
    ì„¸ì…˜ ìºì‹œ ê¸°ë°˜ ë°ì´í„° ë¡œë“œ ìœ í‹¸
    ì„¸ì…˜ë‹¹ 1íšŒë§Œ ë¡œë“œí•˜ì—¬ ì¤‘ë³µ ë¡œë“œë¥¼ ì›ì²œ ì°¨ë‹¨
    
    Args:
        key: ì„¸ì…˜ ìºì‹œ í‚¤ (ì˜ˆ: "ss_menu_master_df")
        loader_fn: ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ì˜ˆ: load_csv)
        *args, **kwargs: loader_fnì— ì „ë‹¬í•  ì¸ì
    
    Returns:
        pandas.DataFrame
    """
    # ì„¸ì…˜ ìºì‹œì— ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜ (ë Œë” ì¤‘ ë§¤ë²ˆ ë®ì–´ì“°ê¸° ë°©ì§€)
    if key in st.session_state:
        if _is_dev_mode():
            logger.debug(f"Session cache HIT: {key}")
        return st.session_state[key]
    
    # ì„¸ì…˜ ìºì‹œì— ì—†ìœ¼ë©´ ë¡œë“œ í›„ ì €ì¥ (ì—†ì„ ë•Œë§Œ 1íšŒ ì„¸íŒ…)
    if _is_dev_mode():
        logger.debug(f"Session cache MISS: {key} (ë¡œë”© ì¤‘...)")
    
    try:
        df = loader_fn(*args, **kwargs)
        # ë Œë” ì¤‘ ë§¤ë²ˆ ë®ì–´ì“°ê¸° ë°©ì§€: ì—†ì„ ë•Œë§Œ ì €ì¥
        if key not in st.session_state:
            st.session_state[key] = df
            if _is_dev_mode():
                logger.debug(f"Session cache SET: {key} ({len(df)} rows)")
        return df
    except Exception as e:
        logger.error(f"Session cache load failed for {key}: {e}")
        # ì˜¤ë¥˜ ì‹œ ë¹ˆ DataFrame ë°˜í™˜ (ì—†ì„ ë•Œë§Œ ì €ì¥)
        empty_df = pd.DataFrame()
        if key not in st.session_state:
            st.session_state[key] = empty_df
        return empty_df


def clear_session_cache(*keys: str):
    """
    ì„¸ì…˜ ìºì‹œ ë¬´íš¨í™” (ì €ì¥/ìˆ˜ì •/ì‚­ì œ í›„ í˜¸ì¶œ)
    
    Args:
        *keys: ì‚­ì œí•  ì„¸ì…˜ ìºì‹œ í‚¤ë“¤ (ì˜ˆ: "ss_menu_master_df", "ss_ingredient_master_df")
    """
    for key in keys:
        if key in st.session_state:
            del st.session_state[key]
            if _is_dev_mode():
                logger.debug(f"Session cache CLEARED: {key}")


def hard_clear_all(reason: str = "unknown"):
    """
    ì „ì²´ ìºì‹œ ê°•ì œ ë¬´íš¨í™” (ë¹„ìƒ/ë””ë²„ê¹…ìš©)
    
    Args:
        reason: clear ì´ìœ  (ë””ë²„ê¹…ìš©)
    """
    try:
        # @st.cache_data ìºì‹œ ì „ì²´ ë¬´íš¨í™”
        load_csv.clear()
        load_expense_structure.clear()
        load_key_menus.clear()
        
        # dashboard.pyëŠ” í‡´ì—­ë˜ì—ˆìœ¼ë¯€ë¡œ ìºì‹œ ë¬´íš¨í™” ì œê±°ë¨
        
        # ì„¸ì…˜ ìºì‹œ ì „ì²´ ì •ë¦¬ (ss_ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ë“¤)
        keys_to_remove = [key for key in st.session_state.keys() if key.startswith('ss_')]
        for key in keys_to_remove:
            del st.session_state[key]
        
        # LAST_INVALIDATION ê¸°ë¡
        try:
            from src.utils.boot_perf import record_invalidation
            record_invalidation(reason=reason, targets=["ALL"], mode="hard")
        except Exception:
            pass
        
        if _is_dev_mode():
            logger.warning(f"HARD CLEAR ALL: {reason}")
    except Exception as e:
        logger.error(f"hard_clear_all ì‹¤íŒ¨: {e}")


def soft_invalidate(reason: str, targets: List[str], session_keys: List[str] = None):
    """
    ì†Œí”„íŠ¸ ë¬´íš¨í™”: token bump + ë¶€ë¶„ ìºì‹œ clear
    
    Args:
        reason: ë¬´íš¨í™” ì´ìœ  (ë””ë²„ê¹…ìš©)
        targets: ë¬´íš¨í™”í•  ë°ì´í„° íƒ€ì… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["sales", "visitors", "menus"])
        session_keys: ë¬´íš¨í™”í•  ì„¸ì…˜ ìºì‹œ í‚¤ ë¦¬ìŠ¤íŠ¸ (ì„ íƒ, Noneì´ë©´ targets ê¸°ë°˜ìœ¼ë¡œ ìë™ ê²°ì •)
    """
    try:
        # 1. ë²„ì „ í† í° ì¦ê°€
        from src.utils.cache_tokens import bump_versions
        bump_versions(targets)
        
        # 2. read ìºì‹œ ë¶€ë¶„ clear (targets ê¸°ë°˜)
        # targets ë§¤í•‘: ì–´ë–¤ ë°ì´í„° íƒ€ì…ì´ ì–´ë–¤ ë¡œë”ì— ì˜í–¥ì„ ì£¼ëŠ”ì§€
        cache_mapping = {
            "sales": ["load_csv", "load_monthly_sales_total", "load_best_available_daily_sales", "load_official_daily_sales"],  # sales.csv + SSOT views
            "daily_close": ["load_csv", "load_monthly_sales_total", "load_best_available_daily_sales", "load_official_daily_sales", "load_monthly_official_sales_total"],  # daily_close + SSOT views
            "visitors": ["load_csv"],  # naver_visitors.csv
            "menus": ["load_csv"],  # menu_master.csv
            "recipes": ["load_csv"],  # recipes.csv
            "ingredients": ["load_csv"],  # ingredient_master.csv
            "cost": ["load_expense_structure"],  # expense_structure
            "expense_structure": ["load_expense_structure"],
        }
        
        loaders_to_clear = set()
        for target in targets:
            if target in cache_mapping:
                loaders_to_clear.update(cache_mapping[target])
        
        # ì‹¤ì œ clear ì‹¤í–‰
        if "load_csv" in loaders_to_clear:
            load_csv.clear()
        if "load_expense_structure" in loaders_to_clear:
            load_expense_structure.clear()
        if "load_key_menus" in loaders_to_clear or "menus" in targets:
            load_key_menus.clear()
        # SSOT í•¨ìˆ˜ ìºì‹œ ë¬´íš¨í™”
        if "load_monthly_sales_total" in loaders_to_clear:
            try:
                load_monthly_sales_total.clear()
            except Exception:
                pass
        if "load_best_available_daily_sales" in loaders_to_clear:
            try:
                load_best_available_daily_sales.clear()
            except Exception:
                pass
        if "load_official_daily_sales" in loaders_to_clear:
            try:
                load_official_daily_sales.clear()
            except Exception:
                pass
        if "load_monthly_official_sales_total" in loaders_to_clear:
            try:
                load_monthly_official_sales_total.clear()
            except Exception:
                pass
        
        # 3. ì„¸ì…˜ ìºì‹œ ë¶€ë¶„ clear
        if session_keys is None:
            # targets ê¸°ë°˜ìœ¼ë¡œ ìë™ ê²°ì •
            session_key_mapping = {
                "sales": ["ss_sales_df"],
                "visitors": ["ss_visitors_df"],
                "menus": ["ss_menu_master_df"],
                "recipes": ["ss_recipes_df"],
                "ingredients": ["ss_ingredient_master_df"],
                "cost": ["ss_expense_structure_df"],
                "expense_structure": ["ss_expense_structure_df"],
                "inventory": ["ss_inventory_df"],
            }
            session_keys = []
            for target in targets:
                if target in session_key_mapping:
                    session_keys.extend(session_key_mapping[target])
        
        for key in session_keys:
            if key in st.session_state:
                del st.session_state[key]
                if _is_dev_mode():
                    logger.debug(f"Session cache CLEARED: {key}")
        
        # 4. LAST_INVALIDATION ê¸°ë¡
        try:
            from src.utils.boot_perf import record_invalidation
            record_invalidation(reason=reason, targets=targets, mode="soft")
        except Exception:
            pass
        
        if _is_dev_mode():
            logger.info(f"SOFT INVALIDATE: {reason}, targets={targets}")
    except Exception as e:
        logger.error(f"soft_invalidate ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ì•ˆì „ì„ ìœ„í•´ hard clearë¡œ í´ë°± (dev_modeì—ì„œë§Œ)
        if _is_dev_mode() and st.session_state.get("force_hard_clear", False):
            hard_clear_all(reason=f"soft_invalidate ì‹¤íŒ¨ í›„ í´ë°±: {reason}")


def _clear_cache_and_session(affected_keys: List[str]):
    """
    ìºì‹œ í´ë¦¬ì–´ ë° ì„¸ì…˜ ìºì‹œ ë¬´íš¨í™” í—¬í¼ í•¨ìˆ˜ (ë ˆê±°ì‹œ í˜¸í™˜)
    
    Args:
        affected_keys: ë¬´íš¨í™”í•  ì„¸ì…˜ ìºì‹œ í‚¤ ë¦¬ìŠ¤íŠ¸
    """
    # force_hard_clear í”Œë˜ê·¸ í™•ì¸ (dev_modeì—ì„œë§Œ)
    if _is_dev_mode() and st.session_state.get("force_hard_clear", False):
        hard_clear_all(reason="force_hard_clear í”Œë˜ê·¸ í™œì„±í™”")
        return
    
    # ê¸°ë³¸ ë™ì‘: soft_invalidateë¡œ ì „í™˜
    # affected_keysì—ì„œ targets ì¶”ë¡  (í‚¤ ì´ë¦„ ê¸°ë°˜)
    targets = []
    if any("menu" in key.lower() for key in affected_keys):
        targets.append("menus")
    if any("recipe" in key.lower() for key in affected_keys):
        targets.append("recipes")
    if any("ingredient" in key.lower() for key in affected_keys):
        targets.append("ingredients")
    if any("expense" in key.lower() for key in affected_keys):
        targets.append("cost")
        targets.append("expense_structure")
    
    if targets:
        soft_invalidate(reason="ë ˆê±°ì‹œ _clear_cache_and_session í˜¸ì¶œ", targets=targets, session_keys=affected_keys)
    else:
        # targetsë¥¼ ì¶”ë¡ í•  ìˆ˜ ì—†ìœ¼ë©´ ì•ˆì „ì„ ìœ„í•´ hard clear (dev_modeì—ì„œë§Œ ê²½ê³ )
        if _is_dev_mode():
            logger.warning(f"_clear_cache_and_session: targets ì¶”ë¡  ì‹¤íŒ¨, hard clear ì‹¤í–‰. affected_keys={affected_keys}")
        hard_clear_all(reason="targets ì¶”ë¡  ì‹¤íŒ¨")


def invalidate_read_caches(table_name: str = None):
    """
    ì½ê¸° ì „ìš© ìºì‹œ ë¬´íš¨í™” (write í›„ í˜¸ì¶œ)
    
    Args:
        table_name: ë¬´íš¨í™”í•  í…Œì´ë¸”ëª… (Noneì´ë©´ ì „ì²´ ë¬´íš¨í™”)
    """
    try:
        if table_name is None:
            # ì „ì²´ ìºì‹œ ë¬´íš¨í™”
            load_csv.clear()
            load_expense_structure.clear()
            load_key_menus.clear()
        else:
            # íŠ¹ì • í…Œì´ë¸”ë§Œ ë¬´íš¨í™” (í•„ìš”ì‹œ êµ¬í˜„)
            # í˜„ì¬ëŠ” ì „ì²´ ë¬´íš¨í™”ë§Œ ì§€ì›
            load_csv.clear()
            load_expense_structure.clear()
            load_key_menus.clear()
        
        # dashboard.pyëŠ” í‡´ì—­ë˜ì—ˆìœ¼ë¯€ë¡œ ìºì‹œ ë¬´íš¨í™” ì œê±°ë¨
    except Exception:
        pass


# ============================================
# Load Functions (CSV í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€)
# ============================================

# Phase 2: ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ - ë°ì´í„° íƒ€ì…ë³„ TTL ë¶„ë¦¬
def _get_cache_ttl(filename: str) -> int:
    """
    íŒŒì¼ëª…ì— ë”°ë¼ ì ì ˆí•œ ìºì‹œ TTL ë°˜í™˜
    
    - ë§ˆìŠ¤í„° ë°ì´í„° (ë©”ë‰´, ì¬ë£Œ): 3600ì´ˆ (1ì‹œê°„) - ìì£¼ ë³€ê²½ë˜ì§€ ì•ŠìŒ
    - íŠ¸ëœì­ì…˜ ë°ì´í„° (ë§¤ì¶œ, ë°©ë¬¸ì): 60ì´ˆ (1ë¶„) - ìì£¼ ë³€ê²½ë¨
    - ì¤‘ê°„ ë°ì´í„° (ì¬ê³ , ë°œì£¼): 300ì´ˆ (5ë¶„) - ì¤‘ê°„ ë¹ˆë„
    """
    master_data = ['menu_master.csv', 'ingredient_master.csv', 'recipes.csv', 'suppliers.csv']
    transaction_data = ['sales.csv', 'naver_visitors.csv', 'daily_sales_items.csv']
    
    if filename in master_data:
        return 3600  # 1ì‹œê°„
    elif filename in transaction_data:
        return 60    # 1ë¶„
    else:
        return 300   # 5ë¶„ (ê¸°ë³¸ê°’)

# Phase 3: ìºì‹œ ì „ëµ ê°œì„ 
# Streamlitì˜ @st.cache_dataëŠ” ë°ì½”ë ˆì´í„° ë ˆë²¨ì—ì„œë§Œ TTLì„ ì„¤ì •í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
# íŒŒì¼ëª…ì— ë”°ë¼ ì ì ˆí•œ TTLì„ ì‚¬ìš©í•˜ë„ë¡ ì£¼ì„ìœ¼ë¡œ ê°€ì´ë“œ ì œê³µ
# ì‹¤ì œ êµ¬í˜„ì€ ê¸°ì¡´ load_csv í•¨ìˆ˜ë¥¼ ìœ ì§€í•˜ë˜, TTLì„ 300ì´ˆ(5ë¶„)ë¡œ ì¡°ì •í•˜ì—¬ ê· í˜• ìœ ì§€

def _load_csv_impl(filename: str, store_id: str, client_mode: str, default_columns: Optional[List[str]] = None):
    """
    ìºì‹œëœ load_csv ë‚´ë¶€ êµ¬í˜„ (store_idì™€ client_modeë¥¼ ìºì‹œ í‚¤ì— í¬í•¨)
    ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ë©´ ìºì‹œ MISSì„ì„ ì˜ë¯¸
    """
    # ë°ì´í„° í˜¸ì¶œ ê³„ì¸¡ ì‹œì‘
    start_time = time.perf_counter()
    
    # ìºì‹œ MISS ë¡œê·¸ ê¸°ë¡ (ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ì—ˆë‹¤ëŠ” ê²ƒì€ ìºì‹œê°€ MISSì˜€ë‹¤ëŠ” ì˜ë¯¸)
    _log_cache_miss("load_csv", filename=filename, store_id=store_id, client_mode=client_mode)
    
    # ê°€ë“œ: ì˜¨ë¼ì¸ì—ì„œëŠ” anonìœ¼ë¡œ read ê¸ˆì§€ (DEVì—ì„œë§Œ í—ˆìš©)
    if client_mode == "anon" and not _is_dev_mode():
        error_msg = f"âŒ ë³´ì•ˆ ìœ„ë°˜: ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ anon í´ë¼ì´ì–¸íŠ¸ë¡œ ë°ì´í„° ì¡°íšŒ ì‹œë„ (filename: {filename})"
        logger.error(error_msg)
        st.error(error_msg)
        st.warning("ğŸ’¡ ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”. ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_csv({filename}) [SECURITY_BLOCK]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    # Supabase ì¡°íšŒìš© í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (DEV MODEì—ì„œ service_role_key ì‚¬ìš© ê°€ëŠ¥)
    try:
        supabase = get_read_client()
    except Exception as e:
        logger.error(f"Supabase client init failed in load_csv('{filename}'): {e}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_csv({filename}) [ERROR]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()

    if not supabase:
        logger.warning(f"Supabase not available, returning empty DataFrame for {filename}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_csv({filename}) [NO_CLIENT]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    if not store_id:
        logger.warning(f"No store_id found, returning empty DataFrame for {filename}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_csv({filename}) [NO_STORE_ID]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    # STEP 2: ë·°ê°€ ì—†ì„ ê²½ìš° fallback (ì•ˆì •ì„± ìš°ì„ ) - ë³€ìˆ˜ë¥¼ try ë¸”ë¡ ë°–ì—ì„œ ì´ˆê¸°í™”
    is_view_fallback = False
    
    try:
        # CSV íŒŒì¼ëª… -> DB í…Œì´ë¸”ëª… ë§¤í•‘
        table_mapping = {
            'sales.csv': 'sales',
            'naver_visitors.csv': 'naver_visitors',
            'menu_master.csv': 'menu_master',
            'ingredient_master.csv': 'ingredients',
            'recipes.csv': 'recipes',
            'daily_sales_items.csv': 'v_daily_sales_items_effective',  # STEP 2: ìš°ì„ ìˆœìœ„ ë·° ì‚¬ìš©
            'inventory.csv': 'inventory',
            'targets.csv': 'targets',
            'abc_history.csv': 'abc_history',
            'daily_close.csv': 'daily_close',
            'actual_settlement.csv': 'actual_settlement',
            # íŒŒì¼ëª… ì—†ì´ í…Œì´ë¸”ëª…ìœ¼ë¡œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥
            'sales': 'sales',
            'naver_visitors': 'naver_visitors',
            'menu_master': 'menu_master',
            'ingredient_master': 'ingredients',
            'recipes': 'recipes',
            'daily_sales_items': 'v_daily_sales_items_effective',  # STEP 2: ìš°ì„ ìˆœìœ„ ë·° ì‚¬ìš©
            'inventory': 'inventory',
            'targets': 'targets',
            'abc_history': 'abc_history',
            'daily_close': 'daily_close',
            'actual_settlement': 'actual_settlement',
        }
        
        actual_table = table_mapping.get(filename, filename.replace('.csv', ''))
        
        # STEP 2: ë·°ê°€ ì—†ì„ ê²½ìš° fallback (ì•ˆì •ì„± ìš°ì„ )
        # v_daily_sales_items_effective ë·°ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ daily_sales_items í…Œì´ë¸” ì‚¬ìš©
        if actual_table == 'v_daily_sales_items_effective':
            try:
                # ë·° ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸)
                test_result = supabase.table("v_daily_sales_items_effective").select("date").limit(1).execute()
                # ì„±ê³µí•˜ë©´ ë·° ì‚¬ìš©
                logger.info("v_daily_sales_items_effective ë·° ì‚¬ìš© ì¤‘")
            except Exception as e:
                # ë·°ê°€ ì—†ê±°ë‚˜ ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ì¡´ í…Œì´ë¸”ë¡œ fallback
                logger.warning(f"v_daily_sales_items_effective ë·°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. daily_sales_itemsë¡œ fallback: {e}")
                actual_table = 'daily_sales_items'
                is_view_fallback = True
        
        # ëŒ€ìš©ëŸ‰ í…Œì´ë¸” í•„í„° ê¸°ë³¸ê°’ ê°•ì œ (ìµœê·¼ 90ì¼)
        large_tables = ['sales', 'daily_close', 'daily_sales_items', 'v_daily_sales_items_effective', 'naver_visitors']
        use_date_filter = actual_table in large_tables
        
        # store_idë¡œ í•„í„°ë§í•˜ì—¬ ì¡°íšŒ (RLSê°€ ìë™ìœ¼ë¡œ ì ìš©ë¨)
        try:
            query = supabase.table(actual_table).select("*").eq("store_id", store_id)
            
            # ëŒ€ìš©ëŸ‰ í…Œì´ë¸”ì€ ìµœê·¼ 90ì¼ í•„í„° ê°•ì œ ì ìš©
            if use_date_filter:
                from datetime import timedelta
                cutoff_date = (now_kst() - timedelta(days=90)).date()
                query = query.gte("date", cutoff_date.isoformat())
            
            # ë””ë²„ê·¸: ì‹¤ì œ ì¿¼ë¦¬ ì •ë³´ ë¡œê¹… (ì˜¨ë¼ì¸ í™˜ê²½ ì§„ë‹¨ìš©)
            logger.info(f"load_csv({filename}): í…Œì´ë¸”={actual_table}, store_id={store_id}, use_date_filter={use_date_filter}")
            if use_date_filter:
                logger.info(f"load_csv({filename}): ë‚ ì§œ í•„í„° ì ìš© (cutoff_date={cutoff_date.isoformat()})")
            
            # timed_selectë¡œ ì¿¼ë¦¬ ì‹¤í–‰ ë° íƒ€ì´ë° ê¸°ë¡
            result = timed_select(
                f"load_csv({filename})",
                lambda: query.execute()
            )
            
            # ê²°ê³¼ ë¡œê¹…
            row_count = len(result.data) if result.data else 0
            logger.info(f"load_csv({filename}): ì¡°íšŒ ê²°ê³¼ {row_count}ê±´")
        except Exception as query_error:
            error_msg = str(query_error)
            logger.error(f"Query failed for {actual_table} (store_id: {store_id}): {error_msg}")
            
            # ê°œë°œ ëª¨ë“œì—ì„œë§Œ ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
            if _is_dev_mode():
                import streamlit as st
                with st.expander(f"âš ï¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {filename}", expanded=False):
                    st.error(f"**í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨:** {actual_table}")
                    st.caption(f"**Store ID:** {store_id}")
                    st.caption(f"**ì—ëŸ¬:** {error_msg}")
                    
                    # ì—ëŸ¬ íƒ€ì…ë³„ ì•ˆë‚´
                    if "RLS" in error_msg or "policy" in error_msg.lower() or "permission" in error_msg.lower():
                        st.warning("ğŸ’¡ **RLS ì •ì±… ë¬¸ì œ ê°€ëŠ¥ì„±**")
                        st.caption("RLS ì •ì±…ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                    elif "JWT" in error_msg or "token" in error_msg.lower() or "authentication" in error_msg.lower():
                        st.warning("ğŸ’¡ **ì¸ì¦ ë¬¸ì œ ê°€ëŠ¥ì„±**")
                        st.caption("ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ë¡œê·¸ì¸í•˜ì„¸ìš”.")
                    elif "network" in error_msg.lower() or "connection" in error_msg.lower():
                        st.warning("ğŸ’¡ **ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ ê°€ëŠ¥ì„±**")
                        st.caption("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
        
        # ë°ì´í„°ê°€ 0ê±´ì¸ ê²½ìš° ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œë„ í‘œì‹œ)
        if not result.data or len(result.data) == 0:
            # ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œë„ ì§„ë‹¨ ì •ë³´ í‘œì‹œ (í•­ìƒ í‘œì‹œ)
            import streamlit as st
            with st.expander(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {filename} (0ê±´)", expanded=True):
                st.error(f"**í…Œì´ë¸”:** {actual_table}")
                st.write(f"**Store ID:** `{store_id}`")
                st.write("**ì‹¤í–‰ëœ ì¿¼ë¦¬:**")
                if use_date_filter:
                    st.code(f"table('{actual_table}').select('*').eq('store_id', '{store_id}').gte('date', '{cutoff_date.isoformat()}')", language="python")
                else:
                    st.code(f"table('{actual_table}').select('*').eq('store_id', '{store_id}')", language="python")
                
                st.write("**ê°€ëŠ¥í•œ ì›ì¸:**")
                st.write("1. ì‹¤ì œë¡œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°")
                st.write("2. RLS ì •ì±…ìœ¼ë¡œ ì¸í•´ ì ‘ê·¼ ë¶ˆê°€")
                st.write("3. store_id í•„í„° ì¡°ê±´ ë¶ˆì¼ì¹˜")
                st.write("4. ë¡œê·¸ì¸ ìƒíƒœ ë¬¸ì œ")
                
                # ì¶”ê°€ ì§„ë‹¨: í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (store_id í•„í„° ì—†ì´)
                st.divider()
                st.write("**ì¶”ê°€ ì§„ë‹¨: í•„í„° ì—†ì´ ì¡°íšŒ:**")
                try:
                    # í•„í„° ì—†ì´ ì¡°íšŒ ì‹œë„
                    test_result = supabase.table(actual_table).select("*").limit(5).execute()
                    
                    if test_result.data:
                        test_count = len(test_result.data)
                        st.warning(f"âš ï¸ í…Œì´ë¸”ì—ëŠ” ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤ ({test_count}ê±´), í•˜ì§€ë§Œ store_id={store_id} ì¡°ê±´ìœ¼ë¡œëŠ” ì¡°íšŒë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        
                        # ë°œê²¬ëœ store_id ëª©ë¡
                        store_ids_found = set([row.get('store_id') for row in test_result.data if row.get('store_id')])
                        st.write(f"**ë°œê²¬ëœ store_id ëª©ë¡:** {list(store_ids_found)}")
                        
                        if store_id not in store_ids_found:
                            st.error(f"âŒ í˜„ì¬ store_id(`{store_id}`)ê°€ ë°œê²¬ëœ store_id ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤!")
                            st.info("ğŸ’¡ í•´ê²° ë°©ë²•:")
                            st.info("1. ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸")
                            st.info("2. user_profiles í…Œì´ë¸”ì—ì„œ store_id í™•ì¸")
                            st.info("3. RLS ì •ì±… í™•ì¸")
                        
                        st.write("**ìƒ˜í”Œ ë°ì´í„° (í•„í„° ì—†ì´):**")
                        st.json(test_result.data[0])
                    else:
                        st.error("âŒ í•„í„° ì—†ì´ ì¡°íšŒí•´ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
                        st.warning("ğŸ’¡ ì´ê²ƒì€ RLS ì •ì±…ì´ ëª¨ë“  ë°ì´í„° ì ‘ê·¼ì„ ì°¨ë‹¨í•˜ê³  ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.")
                        st.info("**í™•ì¸ ì‚¬í•­:**")
                        st.info("1. Supabase Dashboard â†’ Authentication â†’ Policies")
                        st.info(f"2. `{actual_table}` í…Œì´ë¸”ì˜ SELECT ì •ì±… í™•ì¸")
                        st.info("3. RLS ì •ì±…ì´ í˜„ì¬ ì‚¬ìš©ì(`auth.uid()`)ì—ê²Œ ë°ì´í„° ì ‘ê·¼ì„ í—ˆìš©í•˜ëŠ”ì§€ í™•ì¸")
                        st.info("4. ì •ì±… ì˜ˆì‹œ:")
                        st.code("""
-- ì˜ˆì‹œ: store_id ê¸°ë°˜ RLS ì •ì±…
CREATE POLICY "Users can view their store data"
ON ingredients FOR SELECT
USING (
  store_id IN (
    SELECT store_id FROM user_profiles 
    WHERE id = auth.uid()
  )
);
                        """, language="sql")
                except Exception as test_error:
                    error_msg = str(test_error)
                    st.error(f"âŒ í…Œì´ë¸” ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {type(test_error).__name__}: {error_msg}")
                    st.code(str(test_error), language="text")
                    
                    # RLS ê´€ë ¨ ì—ëŸ¬ í™•ì¸
                    if "permission" in error_msg.lower() or "policy" in error_msg.lower() or "RLS" in error_msg:
                        st.error("ğŸš¨ RLS ì •ì±… ë¬¸ì œë¡œ ë³´ì…ë‹ˆë‹¤!")
                        st.info("**í•´ê²° ë°©ë²•:**")
                        st.info(f"1. Supabase Dashboardì—ì„œ `{actual_table}` í…Œì´ë¸”ì˜ RLS ì •ì±… í™•ì¸")
                        st.info("2. SELECT ì •ì±…ì´ í•„ìš”í•©ë‹ˆë‹¤")
                        st.info("3. ì •ì±…ì—ì„œ `auth.uid()`ì™€ `store_id`ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤")
            
            # ë°ì´í„°ê°€ 0ê±´ì´ì–´ë„ ë¹ˆ DataFrame ë°˜í™˜
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            record_data_call(f"load_csv({filename})", elapsed_ms, rows=0, source="supabase")
            return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
        
        if result.data:
            df = pd.DataFrame(result.data)
            
            # ì»¬ëŸ¼ëª… ë³€í™˜ (DB -> CSV í˜¸í™˜)
            if actual_table == 'sales':
                if 'date' in df.columns:
                    df['ë‚ ì§œ'] = pd.to_datetime(df['date'])
                if 'card_sales' in df.columns:
                    df['ì¹´ë“œë§¤ì¶œ'] = df['card_sales']
                if 'cash_sales' in df.columns:
                    df['í˜„ê¸ˆë§¤ì¶œ'] = df['cash_sales']
                if 'total_sales' in df.columns:
                    df['ì´ë§¤ì¶œ'] = df['total_sales']
                # store_idë¡œ ë§¤ì¥ëª… ì¡°íšŒ
                store_result = supabase.table("stores").select("name").eq("id", store_id).execute()
                if store_result.data:
                    df['ë§¤ì¥'] = store_result.data[0]['name']
            
            elif actual_table == 'naver_visitors':
                if 'date' in df.columns:
                    df['ë‚ ì§œ'] = pd.to_datetime(df['date'])
                if 'visitors' in df.columns:
                    df['ë°©ë¬¸ììˆ˜'] = df['visitors']
            
            elif actual_table == 'menu_master':
                if 'name' in df.columns:
                    df['ë©”ë‰´ëª…'] = df['name']
                if 'price' in df.columns:
                    df['íŒë§¤ê°€'] = df['price']
            
            elif actual_table == 'ingredients':
                if 'name' in df.columns:
                    df['ì¬ë£Œëª…'] = df['name']
                if 'unit' in df.columns:
                    df['ë‹¨ìœ„'] = df['unit']
                if 'unit_cost' in df.columns:
                    df['ë‹¨ê°€'] = df['unit_cost']
                if 'order_unit' in df.columns:
                    df['ë°œì£¼ë‹¨ìœ„'] = df['order_unit']
                if 'conversion_rate' in df.columns:
                    df['ë³€í™˜ë¹„ìœ¨'] = df['conversion_rate']
            
            elif actual_table == 'recipes':
                # menu_idì™€ ingredient_idë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
                if 'menu_id' in df.columns:
                    menu_ids = df['menu_id'].dropna().unique().tolist()
                    if menu_ids:
                        menu_result = supabase.table("menu_master").select("id,name").in_("id", menu_ids).execute()
                        menu_map = {m['id']: m['name'] for m in menu_result.data}
                        df['ë©”ë‰´ëª…'] = df['menu_id'].map(menu_map)
                
                if 'ingredient_id' in df.columns:
                    ing_ids = df['ingredient_id'].dropna().unique().tolist()
                    if ing_ids:
                        ing_result = supabase.table("ingredients").select("id,name").in_("id", ing_ids).execute()
                        ing_map = {i['id']: i['name'] for i in ing_result.data}
                        df['ì¬ë£Œëª…'] = df['ingredient_id'].map(ing_map)
                
                if 'qty' in df.columns:
                    df['ì‚¬ìš©ëŸ‰'] = df['qty']
            
            elif actual_table == 'v_daily_sales_items_effective':
                # STEP 2: ë·° ì‚¬ìš© (ì»¬ëŸ¼ëª…: date, menu_id, qty)
                if 'date' in df.columns:
                    df['ë‚ ì§œ'] = pd.to_datetime(df['date'])
                
                if 'menu_id' in df.columns:
                    menu_ids = df['menu_id'].dropna().unique().tolist()
                    if menu_ids:
                        menu_result = supabase.table("menu_master").select("id,name").in_("id", menu_ids).execute()
                        menu_map = {m['id']: m['name'] for m in menu_result.data}
                        df['ë©”ë‰´ëª…'] = df['menu_id'].map(menu_map)
                
                if 'qty' in df.columns:
                    df['íŒë§¤ìˆ˜ëŸ‰'] = df['qty']
            
            elif actual_table == 'daily_sales_items' and is_view_fallback:
                # STEP 2: fallback (ê¸°ì¡´ daily_sales_items í…Œì´ë¸” ì‚¬ìš©)
                # ì»¬ëŸ¼ëª…ì€ date, menu_id, qty
                if 'date' in df.columns:
                    df['ë‚ ì§œ'] = pd.to_datetime(df['date'])
                
                if 'menu_id' in df.columns:
                    menu_ids = df['menu_id'].dropna().unique().tolist()
                    if menu_ids:
                        menu_result = supabase.table("menu_master").select("id,name").in_("id", menu_ids).execute()
                        menu_map = {m['id']: m['name'] for m in menu_result.data}
                        df['ë©”ë‰´ëª…'] = df['menu_id'].map(menu_map)
                
                if 'qty' in df.columns:
                    df['íŒë§¤ìˆ˜ëŸ‰'] = df['qty']
            
            elif actual_table == 'inventory':
                if 'ingredient_id' in df.columns:
                    ing_ids = df['ingredient_id'].dropna().unique().tolist()
                    if ing_ids:
                        ing_result = supabase.table("ingredients").select("id,name").in_("id", ing_ids).execute()
                        ing_map = {i['id']: i['name'] for i in ing_result.data}
                        df['ì¬ë£Œëª…'] = df['ingredient_id'].map(ing_map)
                
                if 'on_hand' in df.columns:
                    df['í˜„ì¬ê³ '] = df['on_hand']
                if 'safety_stock' in df.columns:
                    df['ì•ˆì „ì¬ê³ '] = df['safety_stock']
            
            elif actual_table == 'targets':
                if 'year' in df.columns:
                    df['ì—°ë„'] = df['year']
                if 'month' in df.columns:
                    df['ì›”'] = df['month']
                if 'target_sales' in df.columns:
                    df['ëª©í‘œë§¤ì¶œ'] = df['target_sales']
                if 'target_cost_rate' in df.columns:
                    df['ëª©í‘œì›ê°€ìœ¨'] = df['target_cost_rate']
                if 'target_labor_rate' in df.columns:
                    df['ëª©í‘œì¸ê±´ë¹„ìœ¨'] = df['target_labor_rate']
                if 'target_rent_rate' in df.columns:
                    df['ëª©í‘œì„ëŒ€ë£Œìœ¨'] = df['target_rent_rate']
                if 'target_other_rate' in df.columns:
                    df['ëª©í‘œê¸°íƒ€ë¹„ìš©ìœ¨'] = df['target_other_rate']
                if 'target_profit_rate' in df.columns:
                    df['ëª©í‘œìˆœì´ìµë¥ '] = df['target_profit_rate']
            
            elif actual_table == 'actual_settlement':
                # ì‹¤ì œ ì •ì‚° ë°ì´í„° (ì›”ë³„ ì‹¤ì )
                if 'year' in df.columns:
                    df['ì—°ë„'] = df['year']
                if 'month' in df.columns:
                    df['ì›”'] = df['month']
                if 'actual_sales' in df.columns:
                    df['ì‹¤ì œë§¤ì¶œ'] = df['actual_sales']
                if 'actual_cost' in df.columns:
                    df['ì‹¤ì œë¹„ìš©'] = df['actual_cost']
                if 'actual_profit' in df.columns:
                    df['ì‹¤ì œì´ìµ'] = df['actual_profit']
                if 'profit_margin' in df.columns:
                    df['ì‹¤ì œì´ìµë¥ '] = df['profit_margin']
            
            elif actual_table == 'abc_history':
                # ì»¬ëŸ¼ëª…ì´ ì´ë¯¸ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ë„ ìˆìŒ
                if 'menu_name' in df.columns:
                    df['ë©”ë‰´ëª…'] = df['menu_name']
                if 'sales_qty' in df.columns:
                    df['íŒë§¤ëŸ‰'] = df['sales_qty']
                if 'sales_amount' in df.columns:
                    df['ë§¤ì¶œ'] = df['sales_amount']
                if 'contribution_margin' in df.columns:
                    df['ê³µí—Œì´ìµ'] = df['contribution_margin']
                if 'qty_ratio' in df.columns:
                    df['íŒë§¤ëŸ‰ë¹„ì¤‘'] = df['qty_ratio']
                if 'sales_ratio' in df.columns:
                    df['ë§¤ì¶œë¹„ì¤‘'] = df['sales_ratio']
                if 'margin_ratio' in df.columns:
                    df['ê³µí—Œì´ìµë¹„ì¤‘'] = df['margin_ratio']
                if 'abc_grade' in df.columns:
                    df['ABCë“±ê¸‰'] = df['abc_grade']
                if 'year' in df.columns:
                    df['ì—°ë„'] = df['year']
                if 'month' in df.columns:
                    df['ì›”'] = df['month']
            
            elif actual_table == 'suppliers':
                if 'name' in df.columns:
                    df['ê³µê¸‰ì—…ì²´ëª…'] = df['name']
                if 'phone' in df.columns:
                    df['ì „í™”ë²ˆí˜¸'] = df['phone']
                if 'email' in df.columns:
                    df['ì´ë©”ì¼'] = df['email']
                if 'delivery_days' in df.columns:
                    df['ë°°ì†¡ì¼'] = df['delivery_days']
                if 'min_order_amount' in df.columns:
                    df['ìµœì†Œì£¼ë¬¸ê¸ˆì•¡'] = df['min_order_amount']
                if 'delivery_fee' in df.columns:
                    df['ë°°ì†¡ë¹„'] = df['delivery_fee']
                if 'notes' in df.columns:
                    df['ë¹„ê³ '] = df['notes']
            
            elif actual_table == 'ingredient_suppliers':
                # ì¬ë£Œ ID -> ì¬ë£Œëª… ë³€í™˜
                if 'ingredient_id' in df.columns:
                    ing_ids = df['ingredient_id'].dropna().unique().tolist()
                    if ing_ids:
                        ing_result = supabase.table("ingredients").select("id,name").in_("id", ing_ids).execute()
                        ing_map = {i['id']: i['name'] for i in ing_result.data}
                        df['ì¬ë£Œëª…'] = df['ingredient_id'].map(ing_map)
                
                # ê³µê¸‰ì—…ì²´ ID -> ê³µê¸‰ì—…ì²´ëª… ë³€í™˜
                if 'supplier_id' in df.columns:
                    sup_ids = df['supplier_id'].dropna().unique().tolist()
                    if sup_ids:
                        sup_result = supabase.table("suppliers").select("id,name").in_("id", sup_ids).execute()
                        sup_map = {s['id']: s['name'] for s in sup_result.data}
                        df['ê³µê¸‰ì—…ì²´ëª…'] = df['supplier_id'].map(sup_map)
                
                if 'unit_price' in df.columns:
                    df['ë‹¨ê°€'] = df['unit_price']
                if 'is_default' in df.columns:
                    df['ê¸°ë³¸ê³µê¸‰ì—…ì²´'] = df['is_default']
            
            elif actual_table == 'orders':
                # id ì»¬ëŸ¼ ìœ ì§€
                if 'id' not in df.columns:
                    df['id'] = df.index
                
                # ì¬ë£Œ ID -> ì¬ë£Œëª… ë³€í™˜
                if 'ingredient_id' in df.columns:
                    ing_ids = df['ingredient_id'].dropna().unique().tolist()
                    if ing_ids:
                        ing_result = supabase.table("ingredients").select("id,name").in_("id", ing_ids).execute()
                        ing_map = {i['id']: i['name'] for i in ing_result.data}
                        df['ì¬ë£Œëª…'] = df['ingredient_id'].map(ing_map)
                
                # ê³µê¸‰ì—…ì²´ ID -> ê³µê¸‰ì—…ì²´ëª… ë³€í™˜
                if 'supplier_id' in df.columns:
                    sup_ids = df['supplier_id'].dropna().unique().tolist()
                    if sup_ids:
                        sup_result = supabase.table("suppliers").select("id,name").in_("id", sup_ids).execute()
                        sup_map = {s['id']: s['name'] for s in sup_result.data}
                        df['ê³µê¸‰ì—…ì²´ëª…'] = df['supplier_id'].map(sup_map)
                
                if 'order_date' in df.columns:
                    df['ë°œì£¼ì¼'] = pd.to_datetime(df['order_date'])
                if 'quantity' in df.columns:
                    df['ìˆ˜ëŸ‰'] = df['quantity']
                if 'unit_price' in df.columns:
                    df['ë‹¨ê°€'] = df['unit_price']
                if 'total_amount' in df.columns:
                    df['ì´ê¸ˆì•¡'] = df['total_amount']
                if 'status' in df.columns:
                    df['ìƒíƒœ'] = df['status']
                if 'expected_delivery_date' in df.columns:
                    df['ì…ê³ ì˜ˆì •ì¼'] = pd.to_datetime(df['expected_delivery_date'])
                if 'actual_delivery_date' in df.columns:
                    df['ì…ê³ ì¼'] = pd.to_datetime(df['actual_delivery_date'])
                if 'notes' in df.columns:
                    df['ë¹„ê³ '] = df['notes']
            
            return df
        else:
            return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    except Exception as e:
        logger.error(f"Failed to load {filename}: {e}")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()


# ìºì‹œ ì ìš© (store_idì™€ client_modeë¥¼ ìºì‹œ í‚¤ì— í¬í•¨)
# ì£¼ì˜: ë°ì½”ë ˆì´í„° ë ˆë²¨ì—ì„œ is_dev_mode() í˜¸ì¶œ ì‹œ ëª¨ë“ˆ ë¡œë“œ ì‹œì ì— session_stateê°€ ì—†ì–´ ìºì‹œê°€ ì¬ìƒì„±ë¨
# ë”°ë¼ì„œ TTLì„ ê³ ì •ê°’(300ì´ˆ)ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í™•ë³´
@st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ (ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í™•ë³´)
def load_csv(filename: str, default_columns: Optional[List[str]] = None, store_id: str = None, client_mode: str = None):
    """
    í…Œì´ë¸”ì—ì„œ ë°ì´í„° ë¡œë“œ (CSV í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤)
    ìºì‹œ í‚¤ì— store_idì™€ client_modeë¥¼ í¬í•¨í•˜ì—¬ ë§¤ì¥ë³„/í´ë¼ì´ì–¸íŠ¸ë³„ë¡œ ìºì‹œ ë¶„ë¦¬
    
    Args:
        filename: CSV íŒŒì¼ëª… (ì˜ˆ: "sales.csv") -> í…Œì´ë¸”ëª…ìœ¼ë¡œ ë§¤í•‘
        default_columns: ê¸°ë³¸ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        store_id: store_id (Noneì´ë©´ get_current_store_id() ì‚¬ìš©)
        client_mode: client_mode (Noneì´ë©´ get_read_client_mode() ì‚¬ìš©, ìºì‹œ í‚¤ì— í¬í•¨)
    
    Returns:
        pandas.DataFrame
    """
    # ì„¸ì…˜ ìºì‹œ í‚¤ ë§¤í•‘ (ë§ˆìŠ¤í„° ë°ì´í„°ë§Œ ì„¸ì…˜ ìºì‹œ ì‚¬ìš©)
    session_cache_keys = {
        'menu_master.csv': 'ss_menu_master_df',
        'ingredient_master.csv': 'ss_ingredient_master_df',
        'inventory.csv': 'ss_inventory_df',
        'recipes.csv': 'ss_recipes_df',
        'targets.csv': 'ss_targets_df',
        # íŒŒì¼ëª… ì—†ì´ í…Œì´ë¸”ëª…ìœ¼ë¡œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥
        'menu_master': 'ss_menu_master_df',
        'ingredient_master': 'ss_ingredient_master_df',
        'inventory': 'ss_inventory_df',
        'recipes': 'ss_recipes_df',
        'targets': 'ss_targets_df',
    }
    
    # ì„¸ì…˜ ìºì‹œ í‚¤ í™•ì¸
    session_key = session_cache_keys.get(filename)
    if session_key and session_key in st.session_state:
        # ì„¸ì…˜ ìºì‹œì— ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
        if _is_dev_mode():
            logger.debug(f"load_csv: Session cache HIT for {filename}")
        df = st.session_state[session_key]
        # ìºì‹œ íˆíŠ¸ë„ ê³„ì¸¡ (ë§¤ìš° ë¹ ë¦„)
        record_data_call(f"load_csv({filename})", 0.1, rows=len(df), source="session_cache")
        return df
    
    # store_idì™€ client_modeë¥¼ ìºì‹œ í‚¤ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ê¸° ìœ„í•´ ê°€ì ¸ì˜¤ê¸°
    if store_id is None:
        store_id = get_current_store_id()
    if client_mode is None:
        try:
            client_mode = get_read_client_mode()
        except Exception:
            client_mode = "unknown"
    
    if not store_id:
        logger.warning(f"No store_id found, returning empty DataFrame for {filename}")
        return pd.DataFrame(columns=default_columns) if default_columns else pd.DataFrame()
    
    # @st.cache_data ìºì‹œ ë˜ëŠ” DB ì¡°íšŒ
    df = _load_csv_impl(filename, store_id, client_mode, default_columns)
    
    # ì„¸ì…˜ ìºì‹œì— ì €ì¥ (ë§ˆìŠ¤í„° ë°ì´í„°ë§Œ)
    if session_key:
        st.session_state[session_key] = df
        if _is_dev_mode():
            logger.debug(f"load_csv: Session cache SET for {filename} ({len(df)} rows)")
    
    return df


@st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ (ë§ˆìŠ¤í„° ë°ì´í„°, ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í™•ë³´)
def load_key_menus() -> List[str]:
    """í•µì‹¬ ë©”ë‰´ ëª©ë¡ ë¡œë“œ (is_core=Trueì¸ ë©”ë‰´ë“¤)"""
    supabase = get_supabase_client()
    if not supabase:
        return []
    
    store_id = get_current_store_id()
    if not store_id:
        return []
    
    try:
        result = supabase.table("menu_master").select("name").eq("store_id", store_id).eq("is_core", True).execute()
        if result.data:
            return [m['name'] for m in result.data]
        return []
    except Exception as e:
        logger.error(f"Failed to load key menus: {e}")
        return []


# ============================================
# Save Functions
# ============================================

def save_sales(date, store_name, card_sales, cash_sales, total_sales=None, check_conflict=True):
    """
    ë§¤ì¶œ ë°ì´í„° ì €ì¥ (ë§¤ì¶œ ë³´ì •)
    
    SSOT ì •ì±…:
    - salesë§Œ upsert (ë³´ì¡° ì…ë ¥ ì±„ë„)
    - daily_closeëŠ” ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ (ê³µì‹ SSOT)
    - daily_closeê°€ ìˆìœ¼ë©´ ì¶©ëŒ ê²½ê³ ë§Œ í‘œì‹œ
    
    Args:
        date: ë‚ ì§œ
        store_name: ë§¤ì¥ëª…
        card_sales: ì¹´ë“œ ë§¤ì¶œ
        cash_sales: í˜„ê¸ˆ ë§¤ì¶œ
        total_sales: ì´ ë§¤ì¶œ (Noneì´ë©´ card_sales + cash_sales)
        check_conflict: Trueë©´ ê¸°ì¡´ ê°’ê³¼ ì¶©ëŒ í™•ì¸ (ê¸°ë³¸ê°’: True)
    
    Returns:
        tuple: (ì„±ê³µ ì—¬ë¶€, ì¶©ëŒ ì •ë³´) ë˜ëŠ” (True, None) - ì¶©ëŒ ì—†ìŒ
        ì¶©ëŒ ì •ë³´: {"existing_total_sales": float, "new_total_sales": float, "has_daily_close": bool}
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, None
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    if total_sales is None:
        total_sales = card_sales + cash_sales
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        # ì¶©ëŒ í™•ì¸: ê¸°ì¡´ sales ê°’ê³¼ daily_close ê°’ í™•ì¸
        conflict_info = None
        if check_conflict:
            # ê¸°ì¡´ sales ê°’ í™•ì¸
            existing_sales = supabase.table("sales")\
                .select("total_sales")\
                .eq("store_id", store_id)\
                .eq("date", date_str)\
                .execute()
            
            existing_total = None
            if existing_sales.data and len(existing_sales.data) > 0:
                existing_total = float(existing_sales.data[0].get('total_sales', 0) or 0)
            
            # daily_close ê°’ í™•ì¸ (ë§ˆê°ë³´ê³ ê°€ ìˆëŠ”ì§€)
            existing_daily_close = supabase.table("daily_close")\
                .select("total_sales")\
                .eq("store_id", store_id)\
                .eq("date", date_str)\
                .execute()
            
            has_daily_close = existing_daily_close.data and len(existing_daily_close.data) > 0
            daily_close_total = None
            if has_daily_close:
                daily_close_total = float(existing_daily_close.data[0].get('total_sales', 0) or 0)
            
            # ì¶©ëŒ ê°ì§€: ê¸°ì¡´ ê°’ì´ ìˆê³  ìƒˆ ê°’ê³¼ ë‹¤ë¥´ë©´ ì¶©ëŒ
            if existing_total is not None and existing_total > 0 and abs(existing_total - float(total_sales)) > 0.01:
                conflict_info = {
                    "existing_total_sales": existing_total,
                    "new_total_sales": float(total_sales),
                    "has_daily_close": has_daily_close,
                    "daily_close_total_sales": daily_close_total
                }
                logger.warning(f"Sales conflict detected: {date_str}, existing={existing_total}, new={total_sales}, has_daily_close={has_daily_close}")
        
        # SSOT ì •ì±…: ë§¤ì¶œ ë³´ì •ì€ salesë§Œ upsert, daily_closeëŠ” ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
        # daily_closeëŠ” ê³µì‹ SSOTì´ë¯€ë¡œ ë§¤ì¶œ ë³´ì •ìœ¼ë¡œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŒ
        supabase.table("sales").upsert({
            "store_id": store_id,
            "date": date_str,
            "card_sales": float(card_sales),
            "cash_sales": float(cash_sales),
            "total_sales": float(total_sales)
        }, on_conflict="store_id,date").execute()
        
        logger.info(f"Sales saved (ë³´ì¡° ì…ë ¥ ì±„ë„): {date_str}, {total_sales}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        # daily_closeëŠ” ë¬´íš¨í™”í•˜ì§€ ì•ŠìŒ (ìˆ˜ì •í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ)
        soft_invalidate(
            reason=f"save_sales: {date_str}",
            targets=["sales"]  # salesë§Œ ë¬´íš¨í™”
        )
        
        # Phase G: load_monthly_sales_total ìºì‹œë„ ë¬´íš¨í™” (ë§¤ì¶œ ì €ì¥ ì‹œ ì›”í•©ê³„ë„ ê°±ì‹  í•„ìš”)
        try:
            load_monthly_sales_total.clear()
        except Exception:
            pass  # í•¨ìˆ˜ê°€ ì—†ê±°ë‚˜ ì—ëŸ¬ ë°œìƒ ì‹œ ë¬´ì‹œ
        
        # S5: ë§¤ì¶œ ì €ì¥ ì§í›„ ìŠ¤ëƒ…ìƒ· (dev_modeì—ì„œë§Œ)
        try:
            from src.auth import is_dev_mode
            if is_dev_mode():
                from src.utils.boot_perf import snapshot_current_metrics
                snapshot_current_metrics("S5: ë§¤ì¶œ ì €ì¥ ì§í›„ rerun")
        except Exception:
            pass
        
        return True, conflict_info
    except Exception as e:
        logger.error(f"Failed to save sales: {e}")
        raise


def save_visitor(date, visitors):
    """ë„¤ì´ë²„ ë°©ë¬¸ì ë°ì´í„° ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        result = supabase.table("naver_visitors").upsert({
            "store_id": store_id,
            "date": date_str,
            "visitors": int(visitors)
        }, on_conflict="store_id,date").execute()
        
        logger.info(f"Visitor saved: {date_str}, {visitors}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_visitor: {date_str}",
            targets=["visitors"]
        )
        
        return True
    except Exception as e:
        logger.error(f"Failed to save visitor: {e}")
        raise


def save_sales_entry(date, store_name, card_sales, cash_sales, total_sales, visitors=None):
    """
    ë§¤ì¶œë³´ì • ì €ì¥ (í†µí•© í•¨ìˆ˜)
    
    SSOT ì •ì±…:
    - í•­ìƒ sales / naver_visitors upsert
    - has_close=trueì¸ ê²½ìš° daily_closeë„ ë™ê¸°í™” (ë§¤ì¶œ + ë„¤ì´ë²„ ë°©ë¬¸ì)
    - memo / sales_itemsëŠ” ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
    
    Args:
        date: ë‚ ì§œ
        store_name: ë§¤ì¥ëª…
        card_sales: ì¹´ë“œ ë§¤ì¶œ
        cash_sales: í˜„ê¸ˆ ë§¤ì¶œ
        total_sales: ì´ ë§¤ì¶œ
        visitors: ë„¤ì´ë²„ ë°©ë¬¸ì ìˆ˜ (ì„ íƒ)
    
    Returns:
        dict: {
            success: bool,
            synced_to_close: bool,
            has_close: bool,
            message: str
        }
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return {
            "success": False,
            "synced_to_close": False,
            "has_close": False,
            "message": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"
        }
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        # 1. ë‚ ì§œ ìƒíƒœ í™•ì¸
        status = get_day_record_status(store_id, date_str)
        has_close = status["has_close"]
        
        # 2. sales upsert
        supabase.table("sales").upsert({
            "store_id": store_id,
            "date": date_str,
            "card_sales": float(card_sales),
            "cash_sales": float(cash_sales),
            "total_sales": float(total_sales)
        }, on_conflict="store_id,date").execute()
        
        # 3. naver_visitors upsert (visitorsê°€ ì œê³µëœ ê²½ìš°)
        if visitors is not None:
            supabase.table("naver_visitors").upsert({
                "store_id": store_id,
                "date": date_str,
                "visitors": int(visitors)
            }, on_conflict="store_id,date").execute()
        
        # 4. has_close=trueì¸ ê²½ìš° daily_close ë™ê¸°í™”
        synced_to_close = False
        if has_close:
            # daily_closeì˜ ë§¤ì¶œê³¼ ë„¤ì´ë²„ ë°©ë¬¸ìë§Œ ì—…ë°ì´íŠ¸
            # memo, sales_itemsëŠ” ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
            update_data = {
                "card_sales": float(card_sales),
                "cash_sales": float(cash_sales),
                "total_sales": float(total_sales)
            }
            if visitors is not None:
                update_data["visitors"] = int(visitors)
            
            supabase.table("daily_close")\
                .update(update_data)\
                .eq("store_id", store_id)\
                .eq("date", date_str)\
                .execute()
            
            synced_to_close = True
            logger.info(f"Daily close synced: {date_str}")
        
        # 5. ìºì‹œ ë¬´íš¨í™”
        soft_invalidate(
            reason=f"save_sales_entry: {date_str}",
            targets=["sales", "visitors", "daily_close"] if has_close else ["sales", "visitors"]
        )
        
        # ë©”ì‹œì§€ êµ¬ì„±
        if synced_to_close:
            message = "ê³µì‹ ë§ˆê° ë§¤ì¶œì´ í•¨ê»˜ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            message = "ì„ì‹œ ë§¤ì¶œ/ë„¤ì´ë²„ ë°©ë¬¸ìê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        
        logger.info(f"Sales entry saved: {date_str}, synced_to_close={synced_to_close}")
        
        return {
            "success": True,
            "synced_to_close": synced_to_close,
            "has_close": has_close,
            "message": message
        }
    except Exception as e:
        logger.error(f"Failed to save sales entry: {e}")
        raise


def save_menu(menu_name, price):
    """
    ë©”ë‰´ ì €ì¥
    
    Phase 2: ë™ì‹œì„± ë³´í˜¸ - Optimistic Locking ì ìš©
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¤‘ë³µ ì²´í¬ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if _check_duplicate(supabase, "menu_master", "name", menu_name, store_id):
            return False, f"'{menu_name}' ë©”ë‰´ëŠ” ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        
        result = supabase.table("menu_master").insert({
            "store_id": store_id,
            "name": menu_name,
            "price": float(price),
            "is_core": False
        }).execute()
        
        logger.info(f"Menu saved: {menu_name}, {price}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_menu: {menu_name}",
            targets=["menus", "recipes"],
            session_keys=['ss_menu_master_df', 'ss_recipes_df']
        )
        
        return True, "ì €ì¥ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to save menu: {e}")
        raise


def update_menu(old_menu_name, new_menu_name, new_price, category=None, expected_updated_at=None):
    """
    ë©”ë‰´ ìˆ˜ì •
    
    Phase 2: ë™ì‹œì„± ë³´í˜¸ - Optimistic Locking
    - expected_updated_at: ìˆ˜ì • ì „ì˜ updated_at ê°’ (ì¶©ëŒ ê°ì§€ìš©)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ê¸°ì¡´ ë©”ë‰´ ì°¾ê¸° (updated_at í¬í•¨)
        existing = supabase.table("menu_master").select("id,updated_at").eq("store_id", store_id).eq("name", old_menu_name).execute()
        if not existing.data:
            return False, f"'{old_menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        menu_id = existing.data[0]['id']
        current_updated_at = existing.data[0].get('updated_at')
        
        # Phase 2: ë™ì‹œì„± ë³´í˜¸ - Optimistic Locking
        if expected_updated_at and current_updated_at != expected_updated_at:
            return False, f"ë‹¤ë¥¸ ì‚¬ìš©ìê°€ '{old_menu_name}' ë©”ë‰´ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        # ìƒˆ ë©”ë‰´ëª…ì´ ë‹¤ë¥¸ ê²½ìš° ì¤‘ë³µ ì²´í¬ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if new_menu_name != old_menu_name:
            if _check_duplicate(supabase, "menu_master", "name", new_menu_name, store_id):
                return False, f"'{new_menu_name}' ë©”ë‰´ëª…ì€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤."
        
        # ì—…ë°ì´íŠ¸ ë°ì´í„° ì¤€ë¹„
        update_data = {
            "name": new_menu_name,
            "price": float(new_price)
        }
        if category is not None:
            update_data["category"] = category
        
        # ì—…ë°ì´íŠ¸
        supabase.table("menu_master").update(update_data).eq("id", menu_id).execute()
        
        logger.info(f"Menu updated: {old_menu_name} -> {new_menu_name}")
        
        # ìºì‹œ í´ë¦¬ì–´ (ë°ì´í„° ë³€ê²½ í›„)
        try:
            load_csv.clear()
        except Exception:
            pass
        
        return True, "ìˆ˜ì • ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to update menu: {e}")
        raise


def update_menu_category(menu_name, category):
    """ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ê¸°ì¡´ ë©”ë‰´ ì°¾ê¸°
        existing = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not existing.data:
            return False, f"'{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        menu_id = existing.data[0]['id']
        
        # ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸
        supabase.table("menu_master").update({
            "category": category
        }).eq("id", menu_id).execute()
        
        logger.info(f"Menu category updated: {menu_name} -> {category}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"update_menu_category: {menu_name}",
            targets=["menus"],
            session_keys=['ss_menu_master_df']
        )
        
        return True, "ì¹´í…Œê³ ë¦¬ ìˆ˜ì • ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to update menu category: {e}")
        raise


def update_menu_cooking_method(menu_name, cooking_method):
    """ë©”ë‰´ ì¡°ë¦¬ë°©ë²• ì—…ë°ì´íŠ¸"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ê¸°ì¡´ ë©”ë‰´ ì°¾ê¸°
        existing = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not existing.data:
            return False, f"'{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        menu_id = existing.data[0]['id']
        
        # ì¡°ë¦¬ë°©ë²• ì—…ë°ì´íŠ¸ (cooking_method ì»¬ëŸ¼ì´ ìˆë‹¤ë©´)
        try:
            supabase.table("menu_master").update({
                "cooking_method": cooking_method.strip()
            }).eq("id", menu_id).execute()
            logger.info(f"Menu cooking method updated: {menu_name}")
            return True, "ì¡°ë¦¬ë°©ë²• ì €ì¥ ì„±ê³µ"
        except Exception as e:
            # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê²½ê³ ë§Œ í•˜ê³  ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ë‚˜ì¤‘ì— ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ í•„ìš”)
            logger.warning(f"Cooking method column may not exist: {e}")
            return True, "ì¡°ë¦¬ë°©ë²• ì €ì¥ ì„±ê³µ (ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ í•„ìš”í•  ìˆ˜ ìˆìŒ)"
    except Exception as e:
        logger.error(f"Failed to update menu cooking method: {e}")
        raise


def delete_menu(menu_name, check_references=True):
    """ë©”ë‰´ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ë©”ë‰´ ì°¾ê¸°
        menu_result = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not menu_result.data:
            return False, f"'{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
        
        menu_id = menu_result.data[0]['id']
        
        references = {}
        if check_references:
            # ë ˆì‹œí”¼ ì°¸ì¡° í™•ì¸
            recipe_check = supabase.table("recipes").select("id").eq("menu_id", menu_id).execute()
            if recipe_check.data:
                references['ë ˆì‹œí”¼'] = len(recipe_check.data)
            
            # íŒë§¤ ë‚´ì—­ ì°¸ì¡° í™•ì¸ (ë·° ì‚¬ìš©)
            sales_check = supabase.table("v_daily_sales_items_effective").select("menu_id").eq("menu_id", menu_id).limit(1).execute()
            if sales_check.data:
                references['íŒë§¤ë‚´ì—­'] = len(sales_check.data)
        
        if references:
            ref_info = ", ".join([f"{k}: {v}ê°œ" for k, v in references.items()])
            return False, f"'{menu_name}' ë©”ë‰´ëŠ” ë‹¤ìŒ ë°ì´í„°ì—ì„œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤: {ref_info}", references
        
        # ì‚­ì œ
        supabase.table("menu_master").delete().eq("id", menu_id).execute()
        logger.info(f"Menu deleted: {menu_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_menu: {menu_name}",
            targets=["menus", "recipes"],
            session_keys=['ss_menu_master_df', 'ss_recipes_df']
        )
        
        return True, "ì‚­ì œ ì„±ê³µ", None
    except Exception as e:
        logger.error(f"Failed to delete menu: {e}")
        raise


def save_ingredient(ingredient_name, unit, unit_price, order_unit=None, conversion_rate=1.0):
    """ì¬ë£Œ ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¤‘ë³µ ì²´í¬ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if _check_duplicate(supabase, "ingredients", "name", ingredient_name, store_id):
            return False, f"'{ingredient_name}' ì¬ë£ŒëŠ” ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        
        # ë°œì£¼ ë‹¨ìœ„ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë‹¨ìœ„ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
        if not order_unit:
            order_unit = unit
        
        insert_data = {
            "store_id": store_id,
            "name": ingredient_name,
            "unit": unit,
            "unit_cost": float(unit_price),
            "order_unit": order_unit,
            "conversion_rate": float(conversion_rate)
        }
        
        result = supabase.table("ingredients").insert(insert_data).execute()
        
        logger.info(f"Ingredient saved: {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_ingredient: {ingredient_name}",
            targets=["ingredients", "recipes", "cost"],
            session_keys=['ss_ingredient_master_df', 'ss_recipes_df', 'ss_inventory_df']
        )
        
        return True, "ì €ì¥ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to save ingredient: {e}")
        raise


def update_ingredient(old_ingredient_name, new_ingredient_name, new_unit, new_unit_price):
    """ì¬ë£Œ ìˆ˜ì •"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ê¸°ì¡´ ì¬ë£Œ ì°¾ê¸°
        existing = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", old_ingredient_name).execute()
        if not existing.data:
            return False, f"'{old_ingredient_name}' ì¬ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        ing_id = existing.data[0]['id']
        
        # ìƒˆ ì¬ë£Œëª…ì´ ë‹¤ë¥¸ ê²½ìš° ì¤‘ë³µ ì²´í¬ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if new_ingredient_name != old_ingredient_name:
            if _check_duplicate(supabase, "ingredients", "name", new_ingredient_name, store_id):
                return False, f"'{new_ingredient_name}' ì¬ë£Œëª…ì€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤."
        
        # ì—…ë°ì´íŠ¸
        supabase.table("ingredients").update({
            "name": new_ingredient_name,
            "unit": new_unit,
            "unit_cost": float(new_unit_price)
        }).eq("id", ing_id).execute()
        
        logger.info(f"Ingredient updated: {old_ingredient_name} -> {new_ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"update_ingredient: {old_ingredient_name}",
            targets=["ingredients", "recipes", "cost"],
            session_keys=['ss_ingredient_master_df', 'ss_recipes_df', 'ss_inventory_df']
        )
        
        return True, "ìˆ˜ì • ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to update ingredient: {e}")
        raise


def delete_ingredient(ingredient_name, check_references=True):
    """ì¬ë£Œ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            return False, f"'{ingredient_name}' ì¬ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
        
        ing_id = ing_result.data[0]['id']
        
        references = {}
        if check_references:
            # ë ˆì‹œí”¼ ì°¸ì¡° í™•ì¸
            recipe_check = supabase.table("recipes").select("id").eq("ingredient_id", ing_id).execute()
            if recipe_check.data:
                references['ë ˆì‹œí”¼'] = len(recipe_check.data)
            
            # ì¬ê³  ì •ë³´ ì°¸ì¡° í™•ì¸
            inv_check = supabase.table("inventory").select("id").eq("ingredient_id", ing_id).execute()
            if inv_check.data:
                references['ì¬ê³ ì •ë³´'] = 1
        
        if references:
            ref_info = ", ".join([f"{k}: {v}ê°œ" for k, v in references.items()])
            return False, f"'{ingredient_name}' ì¬ë£ŒëŠ” ë‹¤ìŒ ë°ì´í„°ì—ì„œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤: {ref_info}", references
        
        # ì‚­ì œ
        supabase.table("ingredients").delete().eq("id", ing_id).execute()
        logger.info(f"Ingredient deleted: {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_ingredient: {ingredient_name}",
            targets=["ingredients", "recipes", "cost"],
            session_keys=['ss_ingredient_master_df', 'ss_recipes_df', 'ss_inventory_df']
        )
        
        return True, "ì‚­ì œ ì„±ê³µ", None
    except Exception as e:
        logger.error(f"Failed to delete ingredient: {e}")
        raise


def save_recipe(menu_name, ingredient_name, quantity):
    """ë ˆì‹œí”¼ ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ë©”ë‰´ ID ì°¾ê¸°
        menu_result = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not menu_result.data:
            raise Exception(f"ë©”ë‰´ '{menu_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        menu_id = menu_result.data[0]['id']
        
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_id = ing_result.data[0]['id']
        
        # ë ˆì‹œí”¼ ì €ì¥
        result = supabase.table("recipes").upsert({
            "store_id": store_id,
            "menu_id": menu_id,
            "ingredient_id": ingredient_id,
            "qty": float(quantity)
        }, on_conflict="store_id,menu_id,ingredient_id").execute()
        
        logger.info(f"Recipe saved: {menu_name} - {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_recipe: {menu_name}-{ingredient_name}",
            targets=["recipes", "cost"],
            session_keys=['ss_recipes_df']
        )
        
        return True
    except Exception as e:
        logger.error(f"Failed to save recipe: {e}")
        raise


def delete_recipe(menu_name, ingredient_name):
    """ë ˆì‹œí”¼ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ë©”ë‰´ ID ì°¾ê¸°
        menu_result = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not menu_result.data:
            return False, f"'{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        menu_id = menu_result.data[0]['id']
        
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            return False, f"'{ingredient_name}' ì¬ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        ingredient_id = ing_result.data[0]['id']
        
        # ë ˆì‹œí”¼ ì‚­ì œ
        supabase.table("recipes").delete().eq("store_id", store_id).eq("menu_id", menu_id).eq("ingredient_id", ingredient_id).execute()
        
        logger.info(f"Recipe deleted: {menu_name} - {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_recipe: {menu_name}-{ingredient_name}",
            targets=["recipes", "cost"],
            session_keys=['ss_recipes_df']
        )
        
        return True, "ì‚­ì œ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to delete recipe: {e}")
        raise


def save_daily_sales_item(date, menu_name, quantity, reason=None):
    """
    ì¼ì¼ íŒë§¤ ì•„ì´í…œ ì €ì¥ (íŒë§¤ëŸ‰ ë³´ì •)
    
    SSOT ì •ì±… ë³€ê²½:
    - âŒ DELETE ê¸ˆì§€: daily_sales_itemsì—ì„œ DELETE ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    - âœ… UPSERT êµ¬ì¡°: ë©”ë‰´ ë‹¨ìœ„ë¡œ upsertí•˜ë©° ë³€ê²½ ì´ë ¥ ê¸°ë¡
    - âœ… Audit ë¡œê¹…: ëª¨ë“  ë³€ê²½ì‚¬í•­ì„ daily_sales_items_auditì— ê¸°ë¡
    
    Args:
        date: íŒë§¤ ë‚ ì§œ
        menu_name: ë©”ë‰´ëª…
        quantity: íŒë§¤ ìˆ˜ëŸ‰ (0ì´ë©´ soft_delete ì²˜ë¦¬)
        reason: ë³€ê²½ ì‚¬ìœ  (ì„ íƒì‚¬í•­)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        raise Exception(
            "DEV MODEì—ì„œëŠ” Supabaseë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
            "íŒë§¤ëŸ‰ë“±ë¡ ì €ì¥ì„ í•˜ë ¤ë©´ DEV MODEë¥¼ ë„ê±°ë‚˜ Supabase ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”."
        )
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        # ë©”ë‰´ ID ì°¾ê¸°
        menu_result = supabase.table("menu_master").select("id").eq("store_id", store_id).eq("name", menu_name).execute()
        if not menu_result.data:
            raise Exception(f"ë©”ë‰´ '{menu_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        menu_id = menu_result.data[0]['id']
        
        # í˜„ì¬ ì‚¬ìš©ì ID ê°€ì ¸ì˜¤ê¸° (auditìš©)
        changed_by = None
        try:
            session = supabase.auth.get_session()
            if session and getattr(session, "user", None):
                u = getattr(session.user, "id", None)
                if u:
                    changed_by = str(u)
        except Exception:
            pass
        
        # ê¸°ì¡´ qty ì¡°íšŒ (auditìš©)
        old_qty = None
        try:
            existing = supabase.table("daily_sales_items").select("qty").eq("store_id", store_id).eq("date", date_str).eq("menu_id", menu_id).execute()
            if existing.data:
                old_qty = existing.data[0].get('qty', 0)
        except Exception:
            old_qty = None
        
        if old_qty is None:
            old_qty = 0
        
        new_qty = int(quantity)
        
        # UPSERT: daily_sales_itemsì— ì§ì ‘ ì €ì¥
        if new_qty > 0:
            # INSERT or UPDATE
            supabase.table("daily_sales_items").upsert({
                "store_id": store_id,
                "date": date_str,
                "menu_id": menu_id,
                "qty": new_qty
            }, on_conflict="store_id,date,menu_id").execute()
            
            # Audit ê¸°ë¡
            action = 'insert' if old_qty == 0 else 'update'
            audit_reason = reason or 'íŒë§¤ëŸ‰ ë³´ì •'
            
            # RPCë¡œ audit ë¡œê¹…
            try:
                supabase.rpc('log_daily_sales_item_change', {
                    'p_store_id': str(store_id),
                    'p_date': date_str,
                    'p_menu_id': str(menu_id),
                    'p_action': action,
                    'p_old_qty': old_qty,
                    'p_new_qty': new_qty,
                    'p_source': 'override',
                    'p_reason': audit_reason,
                    'p_changed_by': changed_by
                }).execute()
            except Exception as audit_error:
                logger.warning(f"Audit ë¡œê¹… ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {audit_error}")
        else:
            # qtyê°€ 0ì´ë©´ soft_delete (ì‹¤ì œ ì‚­ì œëŠ” í•˜ì§€ ì•Šê³  auditë§Œ ê¸°ë¡)
            if old_qty > 0:
                # qty=0ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                supabase.table("daily_sales_items").upsert({
                    "store_id": store_id,
                    "date": date_str,
                    "menu_id": menu_id,
                    "qty": 0
                }, on_conflict="store_id,date,menu_id").execute()
                
                # Audit ê¸°ë¡
                audit_reason = reason or 'íŒë§¤ëŸ‰ ë³´ì • (qty=0)'
                try:
                    supabase.rpc('log_daily_sales_item_change', {
                        'p_store_id': str(store_id),
                        'p_date': date_str,
                        'p_menu_id': str(menu_id),
                        'p_action': 'soft_delete',
                        'p_old_qty': old_qty,
                        'p_new_qty': 0,
                        'p_source': 'override',
                        'p_reason': audit_reason,
                        'p_changed_by': changed_by
                    }).execute()
                except Exception as audit_error:
                    logger.warning(f"Audit ë¡œê¹… ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {audit_error}")
        
        logger.info(f"Daily sales item saved (override): {date_str}, {menu_name}, {quantity}")
        
        soft_invalidate(
            reason=f"save_daily_sales_item: {date_str}",
            targets=["daily_sales_items"],
        )
        
        return True
    except Exception as e:
        logger.error(f"Failed to save daily sales item: {e}")
        raise


def verify_overrides_saved(store_id: str, sale_date, expected_count: int) -> bool:
    """
    ì €ì¥ ì§í›„ overridesì— ë™ì¼ (store_id, sale_date) ê±´ìˆ˜ê°€ expected_count ì´ìƒì¸ì§€ í™•ì¸.
    DEV ëª¨ë“œ ê²€ì¦ìš©. ì¡°íšŒ ì‹¤íŒ¨ ì‹œ False ë°˜í™˜.
    """
    try:
        supabase = get_read_client()
        if not supabase or not store_id:
            return False
        date_str = sale_date.strftime('%Y-%m-%d') if hasattr(sale_date, 'strftime') else str(sale_date)
        r = supabase.table("daily_sales_items_overrides").select("menu_id", count="exact").eq("store_id", store_id).eq("sale_date", date_str).execute()
        n = r.count if hasattr(r, 'count') and r.count is not None else (len(r.data) if r.data else 0)
        return n >= expected_count
    except Exception as e:
        logger.debug(f"verify_overrides_saved failed: {e}")
        return False


def save_inventory(ingredient_name, current_stock, safety_stock):
    """ì¬ê³  ì •ë³´ ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_id = ing_result.data[0]['id']
        
        # ì¬ê³  ì •ë³´ ì €ì¥/ì—…ë°ì´íŠ¸
        supabase.table("inventory").upsert({
            "store_id": store_id,
            "ingredient_id": ingredient_id,
            "on_hand": float(current_stock),
            "safety_stock": float(safety_stock)
        }, on_conflict="store_id,ingredient_id").execute()
        
        logger.info(f"Inventory saved: {ingredient_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_inventory: {ingredient_name}",
            targets=["inventory"],
            session_keys=['ss_inventory_df']
        )
        
        return True
    except Exception as e:
        logger.error(f"Failed to save inventory: {e}")
        raise


def save_targets(year, month, target_sales, target_cost_rate, target_labor_rate, 
                 target_rent_rate, target_other_rate, target_profit_rate):
    """ëª©í‘œ ë§¤ì¶œ/ë¹„ìš© êµ¬ì¡° ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("targets").upsert({
            "store_id": store_id,
            "year": int(year),
            "month": int(month),
            "target_sales": float(target_sales),
            "target_cost_rate": float(target_cost_rate),
            "target_labor_rate": float(target_labor_rate),
            "target_rent_rate": float(target_rent_rate),
            "target_other_rate": float(target_other_rate),
            "target_profit_rate": float(target_profit_rate)
        }, on_conflict="store_id,year,month").execute()
        
        logger.info(f"Targets saved: {year}-{month}")
        return True
    except Exception as e:
        logger.error(f"Failed to save targets: {e}")
        raise


def save_actual_settlement(year, month, actual_sales, actual_cost, actual_profit, profit_margin):
    """ì›”ë³„ ì‹¤ì œ ì •ì‚° ë°ì´í„° ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("actual_settlement").upsert(
            {
                "store_id": store_id,
                "year": int(year),
                "month": int(month),
                "actual_sales": float(actual_sales),
                "actual_cost": float(actual_cost),
                "actual_profit": float(actual_profit),
                "profit_margin": float(profit_margin),
            },
            on_conflict="store_id,year,month",
        ).execute()
        logger.info(f"Actual settlement saved: {year}-{month}")
        return True
    except Exception as e:
        logger.error(f"Failed to save actual settlement: {e}")
        raise


def save_abc_history(year, month, abc_df):
    """
    ABC ë¶„ì„ íˆìŠ¤í† ë¦¬ ì €ì¥
    
    Phase 2: íŠ¸ëœì­ì…˜ ì²˜ë¦¬ ê°œì„ 
    - ì‚­ì œ í›„ ì‚½ì… ì‘ì—…ì˜ ì›ìì„± ë³´ì¥
    - ì‹¤íŒ¨ ì‹œ ë¡¤ë°± ì‹œë„
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    # Phase 2: íŠ¸ëœì­ì…˜ ì²˜ë¦¬ - ê¸°ì¡´ ë°ì´í„° ë°±ì—…
    old_data_backup = None
    try:
        # ê¸°ì¡´ ë°ì´í„° ë°±ì—… (ë¡¤ë°±ìš©)
        old_result = supabase.table("abc_history").select("*").eq("store_id", store_id).eq("year", year).eq("month", month).execute()
        old_data_backup = old_result.data if old_result.data else []
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (í•´ë‹¹ ì—°ë„/ì›”)
        supabase.table("abc_history").delete().eq("store_id", store_id).eq("year", year).eq("month", month).execute()
        
        # ìƒˆ ë°ì´í„° ì¶”ê°€
        records = []
        for _, row in abc_df.iterrows():
            records.append({
                "store_id": store_id,
                "year": int(year),
                "month": int(month),
                "menu_name": str(row.get('ë©”ë‰´ëª…', '')),
                "sales_qty": int(row.get('íŒë§¤ëŸ‰', 0)),
                "sales_amount": float(row.get('ë§¤ì¶œ', 0)),
                "contribution_margin": float(row.get('ê³µí—Œì´ìµ', 0)),
                "qty_ratio": float(row.get('íŒë§¤ëŸ‰ë¹„ì¤‘', 0)),
                "sales_ratio": float(row.get('ë§¤ì¶œë¹„ì¤‘', 0)),
                "margin_ratio": float(row.get('ê³µí—Œì´ìµë¹„ì¤‘', 0)),
                "abc_grade": str(row.get('ABCë“±ê¸‰', ''))
            })
        
        if records:
            supabase.table("abc_history").insert(records).execute()
        
        logger.info(f"ABC history saved: {year}-{month}")
        return True
    except Exception as e:
        logger.error(f"Failed to save abc history: {e}")
        # Phase 2: íŠ¸ëœì­ì…˜ ì²˜ë¦¬ - ì‹¤íŒ¨ ì‹œ ë¡¤ë°± ì‹œë„
        if old_data_backup:
            try:
                logger.warning(f"Rolling back ABC history for {year}-{month}")
                # ê¸°ì¡´ ë°ì´í„° ë³µì› ì‹œë„
                if old_data_backup:
                    supabase.table("abc_history").insert(old_data_backup).execute()
                logger.info(f"ABC history rollback successful for {year}-{month}")
            except Exception as rollback_error:
                logger.error(f"Failed to rollback ABC history: {rollback_error}")
        raise


def save_key_menus(menu_list):
    """í•µì‹¬ ë©”ë‰´ ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ë¨¼ì € ëª¨ë“  ë©”ë‰´ì˜ is_coreë¥¼ Falseë¡œ
        supabase.table("menu_master").update({"is_core": False}).eq("store_id", store_id).execute()
        
        # ì„ íƒëœ ë©”ë‰´ë“¤ì˜ is_coreë¥¼ Trueë¡œ
        if menu_list:
            for menu_name in menu_list:
                supabase.table("menu_master").update({"is_core": True}).eq("store_id", store_id).eq("name", menu_name).execute()
        
        logger.info(f"Key menus saved: {len(menu_list)} menus")
        return True
    except Exception as e:
        logger.error(f"Failed to save key menus: {e}")
        raise


def save_daily_close(date, store_name, card_sales, cash_sales, total_sales, 
                     visitors, sales_items, issues, memo):
    """
    ì¼ì¼ ë§ˆê° ë°ì´í„° í†µí•© ì €ì¥ (íŠ¸ëœì­ì…˜ ì²˜ë¦¬)
    
    SSOT ì •ì±…:
    - daily_closeê°€ ê³µì‹ ë§¤ì¶œ SSOT
    - daily_sales_itemsëŠ” DELETE ê¸ˆì§€, UPSERT + audit êµ¬ì¡°
    - sales, naver_visitorsëŠ” íŒŒìƒ ë™ê¸°í™”ìš©
    
    Phase 3: SQL í•¨ìˆ˜ ê¸°ë°˜ íŠ¸ëœì­ì…˜ ì²˜ë¦¬
    - ì—¬ëŸ¬ í…Œì´ë¸” ì €ì¥ ì‘ì—…ì˜ ì›ìì„± ë³´ì¥
    - ì‹¤íŒ¨ ì‹œ ìë™ ë¡¤ë°±
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
    
    try:
        # í˜„ì¬ ì‚¬ìš©ì ID ê°€ì ¸ì˜¤ê¸° (auditìš©)
        changed_by = None
        try:
            session = supabase.auth.get_session()
            if session and getattr(session, "user", None):
                u = getattr(session.user, "id", None)
                if u:
                    changed_by = str(u)
        except Exception:
            pass
        
        # sales_itemsë¥¼ JSONB ë°°ì—´ë¡œ ì „ë‹¬ (ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì „ë‹¬ â†’ DBì—ì„œ ë°°ì—´ë¡œ ìˆ˜ì‹ )
        # json.dumps ë¬¸ìì—´ë¡œ ë³´ë‚´ë©´ ìŠ¤ì¹¼ë¼ë¡œ ë“¤ì–´ê°€ jsonb_array_length ì‹œ "cannot get array length of a scalar" ë°œìƒ
        sales_items_payload = None
        if sales_items:
            sales_items_payload = [
                {"menu_name": menu_name, "quantity": int(qty)}
                for menu_name, qty in sales_items
            ]
        
        supabase.rpc('save_daily_close_transaction', {
            'p_date': date_str,
            'p_store_id': str(store_id),
            'p_card_sales': float(card_sales),
            'p_cash_sales': float(cash_sales),
            'p_total_sales': float(total_sales),
            'p_visitors': int(visitors),
            'p_out_of_stock': bool(issues.get('í’ˆì ˆ', False)),
            'p_complaint': bool(issues.get('ì»´í”Œë ˆì¸', False)),
            'p_group_customer': bool(issues.get('ë‹¨ì²´ì†ë‹˜', False)),
            'p_staff_issue': bool(issues.get('ì§ì›ì´ìŠˆ', False)),
            'p_memo': str(memo) if memo else None,
            'p_sales_items': sales_items_payload,
            'p_changed_by': changed_by,  # auditìš© ì‚¬ìš©ì ID
        }).execute()
        
        logger.info(f"Daily close saved (transactional): {date_str}")
        
        # ìºì‹œ ë¬´íš¨í™” (SSOT ì •ì±…: daily_close ë³€ê²½ ì‹œ best_available/official ëª¨ë‘ ë¬´íš¨í™”)
        soft_invalidate(
            reason=f"save_daily_close: {date_str}",
            targets=["daily_close"]  # daily_close ë³€ê²½ ì‹œ ê´€ë ¨ ëª¨ë“  ìºì‹œ ë¬´íš¨í™”
        )
        
        # ========== ì¬ê³  ìë™ ì°¨ê° ê¸°ëŠ¥ ==========
        # ê³µì‹ ì—”ì§„ í•¨ìˆ˜ ì‚¬ìš© (í—Œë²• ì¤€ìˆ˜)
        # ì£¼ì˜: ì¬ê³  ì°¨ê°ì€ íŠ¸ëœì­ì…˜ ì™¸ë¶€ì—ì„œ ì‹¤í–‰ (ë§ˆê° ì €ì¥ê³¼ ë…ë¦½ì )
        if sales_items:
            try:
                from src.analytics import calculate_ingredient_usage
                
                # sales_itemsë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (ê³µì‹ í•¨ìˆ˜ ì…ë ¥ í˜•ì‹)
                daily_sales_list = []
                for menu_name, sales_qty in sales_items:
                    if sales_qty > 0:
                        daily_sales_list.append({
                            'ë‚ ì§œ': date_str,
                            'ë©”ë‰´ëª…': menu_name,
                            'íŒë§¤ìˆ˜ëŸ‰': int(sales_qty)
                        })
                
                if daily_sales_list:
                    daily_sales_df = pd.DataFrame(daily_sales_list)
                    
                    # ë ˆì‹œí”¼ ë°ì´í„° ë¡œë“œ (DataFrame í˜•ì‹)
                    recipe_result = supabase.table("recipes").select("menu_id,ingredient_id,qty").eq("store_id", store_id).execute()
                    menu_result = supabase.table("menu_master").select("id,name").eq("store_id", store_id).execute()
                    ingredient_result = supabase.table("ingredients").select("id,name").eq("store_id", store_id).execute()
                    
                    if recipe_result.data and menu_result.data:
                        # ë©”ë‰´ ID -> ë©”ë‰´ëª… ë§¤í•‘
                        menu_map = {m['id']: m['name'] for m in menu_result.data}
                        # ì¬ë£Œ ID -> ì¬ë£Œëª… ë§¤í•‘
                        ingredient_map = {i['id']: i['name'] for i in ingredient_result.data}
                        
                        # ë ˆì‹œí”¼ DataFrame ìƒì„±
                        recipe_list = []
                        for r in recipe_result.data:
                            menu_id = r.get('menu_id')
                            menu_name = menu_map.get(menu_id)
                            if menu_name:
                                recipe_list.append({
                                    'ë©”ë‰´ëª…': menu_name,
                                    'ì¬ë£Œëª…': ingredient_map.get(r.get('ingredient_id'), f"ID:{r.get('ingredient_id')}"),
                                    'ì‚¬ìš©ëŸ‰': float(r.get('qty', 0))
                                })
                        
                        if recipe_list:
                            recipe_df = pd.DataFrame(recipe_list)
                            
                            # ê³µì‹ ì—”ì§„ í•¨ìˆ˜ í˜¸ì¶œ (í—Œë²• ì¤€ìˆ˜)
                            usage_df = calculate_ingredient_usage(daily_sales_df, recipe_df)
                            
                            if not usage_df.empty:
                                # ì¬ë£Œëª… -> ì¬ë£Œ ID ì—­ë§¤í•‘
                                ingredient_name_to_id = {name: iid for iid, name in ingredient_map.items()}
                                
                                # ì¬ë£Œë³„ ì‚¬ìš©ëŸ‰ ì§‘ê³„ (ingredient_id ê¸°ì¤€)
                                ingredient_usage = {}  # {ingredient_id: total_usage}
                                for _, row in usage_df.iterrows():
                                    ingredient_name = row['ì¬ë£Œëª…']
                                    total_usage = float(row['ì´ì‚¬ìš©ëŸ‰'])
                                    
                                    # ì¬ë£Œëª…ìœ¼ë¡œ ì¬ë£Œ ID ì°¾ê¸°
                                    ingredient_id = None
                                    for iid, name in ingredient_map.items():
                                        if name == ingredient_name:
                                            ingredient_id = iid
                                            break
                                    
                                    if ingredient_id:
                                        if ingredient_id in ingredient_usage:
                                            ingredient_usage[ingredient_id] += total_usage
                                        else:
                                            ingredient_usage[ingredient_id] = total_usage
                                
                                # ì¬ê³  ì°¨ê°
                                for ingredient_id, usage_amount in ingredient_usage.items():
                                    # í˜„ì¬ ì¬ê³  ì¡°íšŒ
                                    inventory_result = supabase.table("inventory").select("on_hand").eq("store_id", store_id).eq("ingredient_id", ingredient_id).execute()
                                    
                                    if inventory_result.data:
                                        current_stock = float(inventory_result.data[0]['on_hand'])
                                        new_stock = max(0, current_stock - usage_amount)  # ìŒìˆ˜ ë°©ì§€
                                        
                                        # ì¬ê³  ì—…ë°ì´íŠ¸
                                        supabase.table("inventory").update({
                                            "on_hand": new_stock
                                        }).eq("store_id", store_id).eq("ingredient_id", ingredient_id).execute()
                                        
                                        ingredient_name = ingredient_map.get(ingredient_id, f"ID:{ingredient_id}")
                                        logger.info(f"Inventory updated: {ingredient_name} - {current_stock:.2f} â†’ {new_stock:.2f} (ì‚¬ìš©ëŸ‰: {usage_amount:.2f})")
            except Exception as e:
                # ì¬ê³  ì°¨ê° ì‹¤íŒ¨í•´ë„ ë§ˆê° ì €ì¥ì€ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ê²½ê³ ë§Œ ë¡œê¹…)
                logger.warning(f"ì¬ê³  ìë™ ì°¨ê° ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë§ˆê°ì€ ì €ì¥ë¨): {e}")
        
        return True
    except Exception as e:
        logger.error(f"Failed to save daily close: {e}")
        # íŠ¸ëœì­ì…˜ í•¨ìˆ˜ê°€ ì‹¤íŒ¨í•˜ë©´ ìë™ ë¡¤ë°±ë¨
        raise


def delete_sales(date, store=None):
    """ë§¤ì¶œ ë°ì´í„° ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        supabase.table("sales").delete().eq("store_id", store_id).eq("date", date_str).execute()
        logger.info(f"Sales deleted: {date_str}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_sales: {date_str}",
            targets=["sales"]
        )
        
        return True, "ì‚­ì œ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to delete sales: {e}")
        raise


def delete_visitor(date):
    """ë°©ë¬¸ì ë°ì´í„° ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        supabase.table("naver_visitors").delete().eq("store_id", store_id).eq("date", date_str).execute()
        logger.info(f"Visitor deleted: {date_str}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_visitor: {date_str}",
            targets=["visitors"]
        )
        
        return True, "ì‚­ì œ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to delete visitor: {e}")
        raise


def save_expense_item(year, month, category, item_name, amount, notes=None):
    """ë¹„ìš©êµ¬ì¡° í•­ëª© ì €ì¥"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("expense_structure").insert({
            "store_id": store_id,
            "year": int(year),
            "month": int(month),
            "category": category,
            "item_name": item_name,
            "amount": float(amount),
            "notes": notes if notes else None
        }).execute()
        
        logger.info(f"Expense item saved: {year}-{month}, {category}, {item_name}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"save_expense_item: {year}-{month}",
            targets=["cost", "expense_structure"],
            session_keys=['ss_expense_structure_df']
        )
        
        # S6: ë¹„ìš© ì €ì¥ ì§í›„ ìŠ¤ëƒ…ìƒ· (dev_modeì—ì„œë§Œ)
        try:
            from src.auth import is_dev_mode
            if is_dev_mode():
                from src.utils.boot_perf import snapshot_current_metrics
                snapshot_current_metrics("S6: ë¹„ìš© ì €ì¥ ì§í›„ rerun")
        except Exception:
            pass
        
        return True
    except Exception as e:
        logger.error(f"Failed to save expense item: {e}")
        raise


def update_expense_item(expense_id, item_name, amount, notes=None):
    """ë¹„ìš©êµ¬ì¡° í•­ëª© ìˆ˜ì •"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        update_data = {
            "item_name": item_name,
            "amount": float(amount),
            "updated_at": datetime.now(timezone.utc).isoformat()  # DB ì €ì¥ì€ UTC
        }
        if notes is not None:
            update_data["notes"] = notes
        
        supabase.table("expense_structure")\
            .update(update_data)\
            .eq("id", expense_id)\
            .eq("store_id", store_id)\
            .execute()
        
        logger.info(f"Expense item updated: {expense_id}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"update_expense_item: {expense_id}",
            targets=["cost", "expense_structure"],
            session_keys=['ss_expense_structure_df']
        )
        
        # S6: ë¹„ìš© ì €ì¥ ì§í›„ ìŠ¤ëƒ…ìƒ· (dev_modeì—ì„œë§Œ)
        try:
            from src.auth import is_dev_mode
            if is_dev_mode():
                from src.utils.boot_perf import snapshot_current_metrics
                snapshot_current_metrics("S6: ë¹„ìš© ì €ì¥ ì§í›„ rerun")
        except Exception:
            pass
        
        return True, "ìˆ˜ì • ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to update expense item: {e}")
        raise


def delete_expense_item(expense_id):
    """ë¹„ìš©êµ¬ì¡° í•­ëª© ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("expense_structure").delete().eq("id", expense_id).eq("store_id", store_id).execute()
        logger.info(f"Expense item deleted: {expense_id}")
        
        # ì†Œí”„íŠ¸ ë¬´íš¨í™” (token bump + ë¶€ë¶„ clear)
        soft_invalidate(
            reason=f"delete_expense_item: {expense_id}",
            targets=["cost", "expense_structure"],
            session_keys=['ss_expense_structure_df']
        )
        
        return True, "ì‚­ì œ ì„±ê³µ"
    except Exception as e:
        logger.error(f"Failed to delete expense item: {e}")
        raise


def _load_expense_structure_impl(year, month, store_id: str, client_mode: str, bypass_cache: bool = False):
    """
    load_expense_structure ë‚´ë¶€ êµ¬í˜„ (ìºì‹œ ìš°íšŒ ì˜µì…˜)
    ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ë©´ ìºì‹œ MISSì„ì„ ì˜ë¯¸ (bypass_cache=Trueì¼ ë•ŒëŠ” ì œì™¸)
    """
    # ë°ì´í„° í˜¸ì¶œ ê³„ì¸¡ ì‹œì‘
    start_time = time.perf_counter()
    
    # ìºì‹œ MISS ë¡œê·¸ ê¸°ë¡ (bypass_cacheê°€ Falseì¼ ë•Œë§Œ, ì¦‰ ìºì‹œë¥¼ ì‚¬ìš©í•˜ë ¤ê³  í–ˆì„ ë•Œë§Œ)
    if not bypass_cache:
        _log_cache_miss("load_expense_structure", year=year, month=month, store_id=store_id, client_mode=client_mode)
    
    # ì¡°íšŒìš© í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (DEV MODEì—ì„œ service_role_key ì‚¬ìš© ê°€ëŠ¥)
    try:
        supabase = get_read_client()
    except Exception as e:
        logger.error(f"Supabase client init failed in load_expense_structure: {e}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_expense_structure({year}-{month}) [ERROR]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame()
    
    if not supabase:
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_expense_structure({year}-{month}) [NO_CLIENT]", elapsed_ms, rows=0, source="supabase")
        return pd.DataFrame()
    
    # store_idëŠ” ì´ë¯¸ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•˜ì§€ë§Œ, ê²€ì¦ìš©ìœ¼ë¡œ ë‹¤ì‹œ í™•ì¸
    if not store_id:
        store_id = get_current_store_id()
        if not store_id:
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            record_data_call(f"load_expense_structure({year}-{month}) [NO_STORE_ID]", elapsed_ms, rows=0, source="supabase")
            return pd.DataFrame()
    
    # ê°œë°œëª¨ë“œ ë””ë²„ê·¸ ì •ë³´ ìˆ˜ì§‘
    debug_info = {}
    try:
        from src.auth import get_read_client_mode
        if _is_dev_mode():
            debug_info['store_id'] = store_id
            debug_info['client_mode'] = get_read_client_mode()
            
            # Supabase URL ì¶”ì¶œ (í”„ë¡œì íŠ¸ ì‹ë³„ìš©, ì•ë¶€ë¶„ë§Œ)
            try:
                supabase_url = st.secrets.get("supabase", {}).get("url", "")
                if supabase_url:
                    # https://xxxx.supabase.co ì—ì„œ xxxx ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    import re
                    match = re.search(r'https://([^.]+)\.supabase\.co', supabase_url)
                    if match:
                        debug_info['supabase_project'] = match.group(1)
                    else:
                        debug_info['supabase_project'] = "unknown"
                else:
                    debug_info['supabase_project'] = "not_configured"
            except Exception:
                debug_info['supabase_project'] = "error"
            
            # ì¿¼ë¦¬ í•„í„° ì¡°ê±´ ìˆ˜ì§‘
            debug_info['filters'] = [
                f"store_id={store_id}",
                f"year={int(year)}",
                f"month={int(month)}"
            ]
    except Exception:
        pass
    
    try:
        # ì¿¼ë¦¬ ë¹Œë“œ
        query = supabase.table("expense_structure")\
            .select("*")\
            .eq("store_id", store_id)\
            .eq("year", int(year))\
            .eq("month", int(month))
        
        # timed_selectë¡œ ì¿¼ë¦¬ ì‹¤í–‰ ë° íƒ€ì´ë° ê¸°ë¡
        result = timed_select(
            f"load_expense_structure(year={year}, month={month})",
            lambda: query.execute()
        )
        
        # ê°œë°œëª¨ë“œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
        if debug_info:
            try:
                import streamlit as st
                with st.expander("ğŸ” DEBUG: expense_structure ì¡°íšŒ", expanded=False):
                    st.write(f"**CURRENT STORE ID:** {debug_info.get('store_id', 'N/A')}")
                    st.write(f"**DB CLIENT MODE:** {debug_info.get('client_mode', 'N/A')}")
                    st.write(f"**Supabase í”„ë¡œì íŠ¸:** {debug_info.get('supabase_project', 'N/A')}")
                    st.write("**ì¿¼ë¦¬ í•„í„° ì¡°ê±´:**")
                    for filter_cond in debug_info.get('filters', []):
                        st.caption(f"  - {filter_cond}")
                    
                    st.write("**ì¿¼ë¦¬ ì§í›„ ê²°ê³¼:**")
                    row_count = len(result.data) if result.data else 0
                    st.write(f"  - row_count: {row_count}")
                    if result.data and len(result.data) > 0:
                        st.write("  - data[:3]:")
                        import json
                        # ë¯¼ê°í•œ ì •ë³´ ì œê±°í•˜ê³  í‘œì‹œ
                        display_data = []
                        for item in result.data[:3]:
                            safe_item = {k: v for k, v in item.items() if k not in ['id', 'store_id']}
                            display_data.append(safe_item)
                        st.json(display_data)
                    else:
                        st.caption("  (ë°ì´í„° ì—†ìŒ)")
                    
                    # ìºì‹œ ìƒíƒœ í‘œì‹œ
                    if bypass_cache:
                        st.caption("  âš ï¸ ìºì‹œ ìš°íšŒ ëª¨ë“œë¡œ ì‹¤í–‰ë¨")
                    else:
                        st.caption("  â„¹ï¸ ìºì‹œ ì ìš©ë¨ (ìºì‹œ ìš°íšŒí•˜ë ¤ë©´ ì‚¬ì´ë“œë°” í† ê¸€ ì‚¬ìš©)")
            except Exception:
                pass  # ë””ë²„ê·¸ ì¶œë ¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        if result.data:
            df = pd.DataFrame(result.data)
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            record_data_call(f"load_expense_structure({year}-{month})", elapsed_ms, rows=len(df), source="supabase")
            return df
        else:
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            record_data_call(f"load_expense_structure({year}-{month})", elapsed_ms, rows=0, source="supabase")
            return pd.DataFrame(columns=['id', 'category', 'item_name', 'amount', 'notes'])
    except Exception as e:
        logger.error(f"Failed to load expense structure: {e}")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        record_data_call(f"load_expense_structure({year}-{month}) [EXCEPTION]", elapsed_ms, rows=0, source="supabase")
        # ì—ëŸ¬ë„ ë””ë²„ê·¸ì— í‘œì‹œ
        if debug_info:
            try:
                import streamlit as st
                with st.expander("ğŸ” DEBUG: expense_structure ì¡°íšŒ", expanded=False):
                    st.error(f"**ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨:** {str(e)}")
            except Exception:
                pass
        return pd.DataFrame()


@st.cache_data(ttl=60)  # 1ë¶„ ìºì‹œ (ë¹„ìš©êµ¬ì¡°ëŠ” ìì£¼ ë³€ê²½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì§§ê²Œ, ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í™•ë³´)
def load_expense_structure(year, month, store_id: str = None, client_mode: str = None):
    """
    ë¹„ìš© êµ¬ì¡° ë°ì´í„° ë¡œë“œ
    
    Args:
        year: ì—°ë„
        month: ì›”
        store_id: store_id (Noneì´ë©´ get_current_store_id() ì‚¬ìš©)
        client_mode: client_mode (Noneì´ë©´ get_read_client_mode() ì‚¬ìš©)
    """
    # ê°€ë“œ: ì˜¨ë¼ì¸ì—ì„œëŠ” anonìœ¼ë¡œ read ê¸ˆì§€ (DEVì—ì„œë§Œ í—ˆìš©)
    if client_mode is None:
        client_mode = get_read_client_mode()
    
    if client_mode == "anon" and not _is_dev_mode():
        error_msg = f"âŒ ë³´ì•ˆ ìœ„ë°˜: ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ anon í´ë¼ì´ì–¸íŠ¸ë¡œ ë°ì´í„° ì¡°íšŒ ì‹œë„ (load_expense_structure)"
        logger.error(error_msg)
        st.error(error_msg)
        st.warning("ğŸ’¡ ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”. ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.")
        return {}
    """
    ë¹„ìš©êµ¬ì¡° ë°ì´í„° ë¡œë“œ (íŠ¹ì • ì—°ë„/ì›”)
    ì„¸ì…˜ ìºì‹œ ìš°ì„  ì‚¬ìš© (í˜„ì¬ ì—°ë„/ì›”ë§Œ) â†’ ì—†ìœ¼ë©´ @st.cache_data ìºì‹œ ì‚¬ìš© â†’ ì—†ìœ¼ë©´ DB ì¡°íšŒ
    """
    from datetime import datetime
    
    # í˜„ì¬ ì—°ë„/ì›”ê³¼ ì¼ì¹˜í•˜ë©´ ì„¸ì…˜ ìºì‹œ í™•ì¸ (KST ê¸°ì¤€)
    current_year = current_year_kst()
    current_month = current_month_kst()
    if year == current_year and month == current_month:
        session_key = 'ss_expense_structure_df'
        if session_key in st.session_state:
            if _is_dev_mode():
                logger.debug(f"load_expense_structure: Session cache HIT for {year}-{month}")
            df = st.session_state[session_key]
            # ìºì‹œ íˆíŠ¸ë„ ê³„ì¸¡ (ë§¤ìš° ë¹ ë¦„)
            record_data_call(f"load_expense_structure({year}-{month})", 0.1, rows=len(df), source="session_cache")
            return df
    
    # store_idì™€ client_modeë¥¼ ìºì‹œ í‚¤ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ê¸° ìœ„í•´ ê°€ì ¸ì˜¤ê¸°
    if store_id is None:
        store_id = get_current_store_id()
    if client_mode is None:
        try:
            client_mode = get_read_client_mode()
        except Exception:
            client_mode = "unknown"
    
    # ê°€ë“œ: ì˜¨ë¼ì¸ì—ì„œëŠ” anonìœ¼ë¡œ read ê¸ˆì§€ (DEVì—ì„œë§Œ í—ˆìš©)
    if client_mode == "anon" and not _is_dev_mode():
        error_msg = f"âŒ ë³´ì•ˆ ìœ„ë°˜: ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ anon í´ë¼ì´ì–¸íŠ¸ë¡œ ë°ì´í„° ì¡°íšŒ ì‹œë„ (load_expense_structure)"
        logger.error(error_msg)
        st.error(error_msg)
        st.warning("ğŸ’¡ ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”. ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    
    # ê°œë°œëª¨ë“œì—ì„œ ìºì‹œ ìš°íšŒ ì˜µì…˜ í™•ì¸
    bypass_cache = False
    try:
        if _is_dev_mode():
            bypass_cache = st.session_state.get("_bypass_cache_expense_structure", False)
    except Exception:
        pass
    
    # @st.cache_data ìºì‹œ ë˜ëŠ” DB ì¡°íšŒ
    df = _load_expense_structure_impl(year, month, store_id, client_mode, bypass_cache=bypass_cache)
    
    # í˜„ì¬ ì—°ë„/ì›”ì´ë©´ ì„¸ì…˜ ìºì‹œì— ì €ì¥
    if year == current_year and month == current_month:
        st.session_state['ss_expense_structure_df'] = df
        if _is_dev_mode():
            logger.debug(f"load_expense_structure: Session cache SET for {year}-{month} ({len(df)} rows)")
    
    return df


@st.cache_data(ttl=60)  # 1ë¶„ ìºì‹œ
def load_expense_structure_range(year_start, month_start, year_end, month_end):
    """ë¹„ìš©êµ¬ì¡° ë°ì´í„° ë¡œë“œ (ê¸°ê°„ ë²”ìœ„)"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return pd.DataFrame()
    
    store_id = get_current_store_id()
    if not store_id:
        return pd.DataFrame()
    
    try:
        # ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ í›„ í•„í„°ë§
        result = supabase.table("expense_structure")\
            .select("*")\
            .eq("store_id", store_id)\
            .execute()
        
        if result.data:
            df = pd.DataFrame(result.data)
            # ê¸°ê°„ í•„í„°ë§
            def in_range(row):
                y, m = row['year'], row['month']
                if y < year_start or y > year_end:
                    return False
                if y == year_start and m < month_start:
                    return False
                if y == year_end and m > month_end:
                    return False
                return True
            
            df = df[df.apply(in_range, axis=1)]
            return df
        else:
            return pd.DataFrame(columns=['id', 'category', 'item_name', 'amount', 'notes', 'year', 'month'])
    except Exception as e:
        logger.error(f"Failed to load expense structure range: {e}")
        return pd.DataFrame()


def copy_expense_structure_from_previous_month(year, month):
    """ì „ì›” ë¹„ìš©êµ¬ì¡° ë°ì´í„°ë¥¼ í˜„ì¬ ì›”ë¡œ ë³µì‚¬"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False, "DEV MODEì—ì„œëŠ” ë³µì‚¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì „ì›” ê³„ì‚°
        prev_month = month - 1
        prev_year = year
        if prev_month == 0:
            prev_month = 12
            prev_year = year - 1
        
        # ì „ì›” ë°ì´í„° ë¡œë“œ
        prev_data = load_expense_structure(prev_year, prev_month)
        if prev_data.empty:
            return False, "ë³µì‚¬í•  ì „ì›” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # í˜„ì¬ ì›” ë°ì´í„° í™•ì¸
        current_data = load_expense_structure(year, month)
        if not current_data.empty:
            return False, "ì´ë¯¸ í˜„ì¬ ì›”ì— ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ì‚­ì œí•´ì£¼ì„¸ìš”."
        
        # ì „ì›” ë°ì´í„° ë³µì‚¬
        records = []
        for _, row in prev_data.iterrows():
            records.append({
                "store_id": store_id,
                "year": int(year),
                "month": int(month),
                "category": row['category'],
                "item_name": row['item_name'],
                "amount": float(row['amount']),
                "notes": row.get('notes')
            })
        
        if records:
            supabase.table("expense_structure").insert(records).execute()
            logger.info(f"Expense structure copied from {prev_year}-{prev_month} to {year}-{month}")
            return True, f"ì „ì›”({prev_year}ë…„ {prev_month}ì›”) ë°ì´í„°ê°€ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            return False, "ë³µì‚¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.error(f"Failed to copy expense structure: {e}")
        raise


def create_backup():
    """ë°ì´í„° ë°±ì—… (DB ê¸°ë°˜ì—ì„œëŠ” ë‹¨ìˆœ ë¡œê·¸ë§Œ)"""
    logger = logging.getLogger(__name__)
    logger.info("Backup requested (DB mode - data is already persisted in Supabase)")
    return True, "ë°ì´í„°ëŠ” Supabaseì— ìë™ìœ¼ë¡œ ì˜êµ¬ ì €ì¥ë©ë‹ˆë‹¤."


# ============================================
# Phase 1: ê³µê¸‰ì—…ì²´ ë° ë°œì£¼ ì´ë ¥ ê´€ë¦¬ í•¨ìˆ˜
# ============================================

def save_supplier(supplier_name, phone=None, email=None, delivery_days=None, 
                  min_order_amount=0, delivery_fee=0, notes=None):
    """ê³µê¸‰ì—…ì²´ ë“±ë¡/ìˆ˜ì •"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("suppliers").upsert({
            "store_id": store_id,
            "name": supplier_name,
            "phone": phone or "",
            "email": email or "",
            "delivery_days": delivery_days or "",
            "min_order_amount": float(min_order_amount) if min_order_amount else 0,
            "delivery_fee": float(delivery_fee) if delivery_fee else 0,
            "notes": notes or ""
        }, on_conflict="store_id,name").execute()
        
        logger.info(f"Supplier saved: {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to save supplier: {e}")
        raise


def delete_supplier(supplier_name):
    """ê³µê¸‰ì—…ì²´ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        supabase.table("suppliers").delete().eq("store_id", store_id).eq("name", supplier_name).execute()
        logger.info(f"Supplier deleted: {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to delete supplier: {e}")
        raise


def save_ingredient_supplier(ingredient_name, supplier_name, unit_price, is_default=True):
    """ì¬ë£Œ-ê³µê¸‰ì—…ì²´ ë§¤í•‘ ì €ì¥

    Notes
    -----
    - unit_price ì¸ìëŠ” **ë°œì£¼ ë‹¨ìœ„ ê¸°ì¤€ ë‹¨ê°€(ì›/ë°œì£¼ë‹¨ìœ„)** ë¡œ ì „ë‹¬ëœë‹¤ê³  ê°€ì •í•œë‹¤.
    - ingredients í…Œì´ë¸”ì˜ conversion_rate ì»¬ëŸ¼ì„ ì‚¬ìš©í•´
      ê¸°ë³¸ ë‹¨ìœ„ ë‹¨ê°€(ì›/ê¸°ë³¸ë‹¨ìœ„)ë¡œ í™˜ì‚°í•´ì„œ DBì— ì €ì¥í•œë‹¤.
      (1 ë°œì£¼ë‹¨ìœ„ = conversion_rate * ê¸°ë³¸ë‹¨ìœ„)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ID ë° ë³€í™˜ ë¹„ìœ¨ ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id,conversion_rate").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_row = ing_result.data[0]
        ingredient_id = ingredient_row['id']
        conversion_rate = ingredient_row.get('conversion_rate', 1.0) or 1.0
        
        # ê³µê¸‰ì—…ì²´ ID ì°¾ê¸°
        sup_result = supabase.table("suppliers").select("id").eq("store_id", store_id).eq("name", supplier_name).execute()
        if not sup_result.data:
            raise Exception(f"ê³µê¸‰ì—…ì²´ '{supplier_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        supplier_id = sup_result.data[0]['id']
        
        # ê¸°ë³¸ ê³µê¸‰ì—…ì²´ì¸ ê²½ìš°, ë‹¤ë¥¸ ê¸°ë³¸ ê³µê¸‰ì—…ì²´ í•´ì œ
        if is_default:
            # í•´ë‹¹ ì¬ë£Œì˜ ë‹¤ë¥¸ ê¸°ë³¸ ê³µê¸‰ì—…ì²´ í•´ì œ
            existing = supabase.table("ingredient_suppliers").select("id").eq("store_id", store_id).eq("ingredient_id", ingredient_id).eq("is_default", True).execute()
            if existing.data:
                for item in existing.data:
                    supabase.table("ingredient_suppliers").update({"is_default": False}).eq("id", item['id']).execute()
        
        # ë°œì£¼ ë‹¨ê°€(ì›/ë°œì£¼ë‹¨ìœ„)ë¥¼ ê¸°ë³¸ ë‹¨ìœ„ ë‹¨ê°€(ì›/ê¸°ë³¸ë‹¨ìœ„)ë¡œ í™˜ì‚°
        try:
            conv = float(conversion_rate)
            price_per_order_unit = float(unit_price)
            if conv > 0:
                base_unit_price = price_per_order_unit / conv
            else:
                base_unit_price = price_per_order_unit
        except Exception:
            base_unit_price = float(unit_price)

        # ì¬ë£Œ-ê³µê¸‰ì—…ì²´ ë§¤í•‘ ì €ì¥ (ê¸°ë³¸ ë‹¨ìœ„ ë‹¨ê°€ ê¸°ì¤€)
        supabase.table("ingredient_suppliers").upsert({
            "store_id": store_id,
            "ingredient_id": ingredient_id,
            "supplier_id": supplier_id,
            "unit_price": float(base_unit_price),
            "is_default": is_default
        }, on_conflict="store_id,ingredient_id,supplier_id").execute()
        
        logger.info(f"Ingredient-supplier mapping saved: {ingredient_name} -> {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to save ingredient-supplier mapping: {e}")
        raise


def delete_ingredient_supplier(ingredient_name, supplier_name):
    """ì¬ë£Œ-ê³µê¸‰ì—…ì²´ ë§¤í•‘ ì‚­ì œ"""
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_id = ing_result.data[0]['id']
        
        # ê³µê¸‰ì—…ì²´ ID ì°¾ê¸°
        sup_result = supabase.table("suppliers").select("id").eq("store_id", store_id).eq("name", supplier_name).execute()
        if not sup_result.data:
            raise Exception(f"ê³µê¸‰ì—…ì²´ '{supplier_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        supplier_id = sup_result.data[0]['id']
        
        supabase.table("ingredient_suppliers").delete().eq("store_id", store_id).eq("ingredient_id", ingredient_id).eq("supplier_id", supplier_id).execute()
        logger.info(f"Ingredient-supplier mapping deleted: {ingredient_name} -> {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to delete ingredient-supplier mapping: {e}")
        raise


def save_order(order_date, ingredient_name, supplier_name, quantity, unit_price, 
               total_amount, status="ì˜ˆì •", expected_delivery_date=None, notes=None):
    """ë°œì£¼ ì´ë ¥ ì €ì¥
    
    ì£¼ì˜
    ----
    - quantity, unit_price ëŠ” **ê¸°ë³¸ ë‹¨ìœ„ ê¸°ì¤€** ê°’ì´ë‹¤.
      (ì˜ˆ: quantity = g, unit_price = ì›/g)
    - UI ë‹¨ì—ì„œ ë°œì£¼ë‹¨ìœ„(ê°œ, ë°•ìŠ¤ ë“±)ë¥¼ ì‚¬ìš©í•˜ë”ë¼ë„,
      ì´ í•¨ìˆ˜ì— ë“¤ì–´ì˜¬ ë•ŒëŠ” ë°˜ë“œì‹œ ê¸°ë³¸ ë‹¨ìœ„ë¡œ í™˜ì‚°í•´ì„œ ë„£ì–´ì•¼ í•œë‹¤.
      (í™˜ì‚° ë¡œì§ì€ `order_service.py` ë“±ì— ëª¨ì•„ ê´€ë¦¬í•œë‹¤.)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        # ì¬ë£Œ ID ì°¾ê¸°
        ing_result = supabase.table("ingredients").select("id").eq("store_id", store_id).eq("name", ingredient_name).execute()
        if not ing_result.data:
            raise Exception(f"ì¬ë£Œ '{ingredient_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ingredient_id = ing_result.data[0]['id']
        
        # ê³µê¸‰ì—…ì²´ ID ì°¾ê¸°
        sup_result = supabase.table("suppliers").select("id").eq("store_id", store_id).eq("name", supplier_name).execute()
        if not sup_result.data:
            raise Exception(f"ê³µê¸‰ì—…ì²´ '{supplier_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        supplier_id = sup_result.data[0]['id']
        
        # ë°œì£¼ ì €ì¥
        result = supabase.table("orders").insert({
            "store_id": store_id,
            "order_date": order_date.strftime("%Y-%m-%d") if isinstance(order_date, datetime) else str(order_date),
            "ingredient_id": ingredient_id,
            "supplier_id": supplier_id,
            "quantity": float(quantity),
            "unit_price": float(unit_price),
            "total_amount": float(total_amount),
            "status": status,
            "expected_delivery_date": expected_delivery_date.strftime("%Y-%m-%d") if expected_delivery_date and isinstance(expected_delivery_date, datetime) else (str(expected_delivery_date) if expected_delivery_date else None),
            "notes": notes or ""
        }).execute()
        
        logger.info(f"Order saved: {ingredient_name} from {supplier_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to save order: {e}")
        raise


def update_order_status(order_id, status, actual_delivery_date=None):
    """ë°œì£¼ ìƒíƒœ ì—…ë°ì´íŠ¸
    
    - status ê°€ 'ì…ê³ ì™„ë£Œ' ì´ê³  actual_delivery_date ê°€ ìˆì„ ë•Œ ì¬ê³ (on_hand)ë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤.
    - ì¤‘ë³µ ì…ê³  ë°˜ì˜ì„ ë§‰ê¸° ìœ„í•´ orders.inventory_applied í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•œë‹¤.
      (ë‹¨, í•´ë‹¹ ì»¬ëŸ¼ì´ ì•„ì§ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ, ì—†ìœ¼ë©´ ì¡°ìš©íˆ ê±´ë„ˆë›´ë‹¤.)
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    store_id = get_current_store_id()
    if not store_id:
        raise Exception("No store_id found")
    
    try:
        update_data = {"status": status}
        if actual_delivery_date:
            update_data["actual_delivery_date"] = actual_delivery_date.strftime("%Y-%m-%d") if isinstance(actual_delivery_date, datetime) else str(actual_delivery_date)
        
        # ì…ê³  ì™„ë£Œ ì‹œ ì¬ê³  ë°˜ì˜ (inventory_applied í”Œë˜ê·¸ ê¸°ë°˜, idempotent)
        if status == "ì…ê³ ì™„ë£Œ" and actual_delivery_date:
            # ë°œì£¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (inventory_applied í¬í•¨ ì‹œë„)
            order_result = supabase.table("orders")\
                .select("ingredient_id,quantity,inventory_applied")\
                .eq("id", order_id)\
                .eq("store_id", store_id)\
                .execute()
            if order_result.data:
                row = order_result.data[0]
                ingredient_id = row.get("ingredient_id")
                quantity = row.get("quantity", 0)
                inventory_applied = bool(row.get("inventory_applied", False))

                # ì•„ì§ ì¬ê³  ë°˜ì˜ì´ ì•ˆ ëœ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                if ingredient_id and not inventory_applied:
                    inv_result = supabase.table("inventory")\
                        .select("on_hand")\
                        .eq("store_id", store_id)\
                        .eq("ingredient_id", ingredient_id)\
                        .execute()
                    if inv_result.data:
                        current_stock = float(inv_result.data[0].get("on_hand", 0) or 0)
                        new_stock = current_stock + float(quantity or 0)
                        supabase.table("inventory")\
                            .update({"on_hand": new_stock})\
                            .eq("store_id", store_id)\
                            .eq("ingredient_id", ingredient_id)\
                            .execute()

                    # ì¬ê³  ë°˜ì˜ ì™„ë£Œ í‘œì‹œ (ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¡°ìš©íˆ ë¬´ì‹œ)
                    try:
                        supabase.table("orders")\
                            .update({"inventory_applied": True})\
                            .eq("id", order_id)\
                            .eq("store_id", store_id)\
                            .execute()
                    except Exception as e:
                        logger.warning(f"inventory_applied ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”í•  ìˆ˜ ìˆìŒ): {e}")

        # ìƒíƒœ/ì…ê³ ì¼ ì—…ë°ì´íŠ¸
        supabase.table("orders").update(update_data).eq("id", order_id).eq("store_id", store_id).execute()
        logger.info(f"Order status updated: {order_id} -> {status}")
        return True
    except Exception as e:
        logger.error(f"Failed to update order status: {e}")
        raise


# ============================================
# Phase B: ì‹¤ì œì •ì‚° ë¹„ìš© í•­ëª© í…œí”Œë¦¿ ê´€ë¦¬
# ============================================

def load_cost_item_templates(store_id: str):
    """
    ë¹„ìš© í•­ëª© í…œí”Œë¦¿ ë¡œë“œ (is_active=trueë§Œ)
    
    Args:
        store_id: ë§¤ì¥ ID
    
    Returns:
        list: í…œí”Œë¦¿ í•­ëª© ë¦¬ìŠ¤íŠ¸ (category, item_name, item_type, is_recurring, recurring_value, sort_order)
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return []
        
        result = supabase.table("cost_item_templates")\
            .select("*")\
            .eq("store_id", store_id)\
            .eq("is_active", True)\
            .order("category")\
            .order("sort_order")\
            .order("item_name")\
            .execute()
        
        logger.info(f"Loaded {len(result.data) if result.data else 0} cost item templates")
        return result.data if result.data else []
    except Exception as e:
        logger.error(f"Failed to load cost item templates: {e}")
        return []


def save_cost_item_template(
    store_id: str,
    category: str,
    item_name: str,
    item_type: str = 'normal',
    is_recurring: bool = False,
    recurring_value: float = 0.0,
    sort_order: int = 0
):
    """
    ë¹„ìš© í•­ëª© í…œí”Œë¦¿ ì €ì¥/ì—…ë°ì´íŠ¸ (upsert)
    
    Args:
        store_id: ë§¤ì¥ ID
        category: ì¹´í…Œê³ ë¦¬ (ì„ì°¨ë£Œ, ì¸ê±´ë¹„, ì¬ë£Œë¹„, ê³µê³¼ê¸ˆ, ë¶€ê°€ì„¸&ì¹´ë“œìˆ˜ìˆ˜ë£Œ)
        item_name: í•­ëª©ëª…
        item_type: í•­ëª© ìœ í˜• ('normal' | 'fixed' | 'percent')
        is_recurring: ë°˜ë³µ ì—¬ë¶€
        recurring_value: ë°˜ë³µ ê°’
        sort_order: ì •ë ¬ ìˆœì„œ
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return False
        
        # upsert (store_id, category, item_name ê¸°ì¤€)
        supabase.table("cost_item_templates").upsert({
            "store_id": store_id,
            "category": category,
            "item_name": item_name,
            "item_type": item_type,
            "is_recurring": is_recurring,
            "recurring_value": float(recurring_value),
            "sort_order": int(sort_order),
            "is_active": True
        }, on_conflict="store_id,category,item_name").execute()
        
        logger.info(f"Cost item template saved: {category} - {item_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to save cost item template: {e}")
        raise


def soft_delete_cost_item_template(store_id: str, category: str, item_name: str):
    """
    ë¹„ìš© í•­ëª© í…œí”Œë¦¿ Soft Delete (is_active=falseë¡œ ì—…ë°ì´íŠ¸)
    
    Args:
        store_id: ë§¤ì¥ ID
        category: ì¹´í…Œê³ ë¦¬
        item_name: í•­ëª©ëª…
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return False
        
        supabase.table("cost_item_templates")\
            .update({"is_active": False})\
            .eq("store_id", store_id)\
            .eq("category", category)\
            .eq("item_name", item_name)\
            .execute()
        
        logger.info(f"Cost item template soft deleted: {category} - {item_name}")
        return True
    except Exception as e:
        logger.error(f"Failed to soft delete cost item template: {e}")
        raise


# ============================================
# Phase C: ì‹¤ì œì •ì‚° ì›”ë³„ ê¸ˆì•¡/ë¹„ìœ¨ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
# ============================================

def load_actual_settlement_items(store_id: str, year: int, month: int):
    """
    ì‹¤ì œì •ì‚° ì›”ë³„ í•­ëª© ê°’ ë¡œë“œ
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        list: ì €ì¥ëœ í•­ëª© ê°’ ë¦¬ìŠ¤íŠ¸ (template_id, amount, percent, status)
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return []
        
        result = supabase.table("actual_settlement_items")\
            .select("*")\
            .eq("store_id", store_id)\
            .eq("year", int(year))\
            .eq("month", int(month))\
            .execute()
        
        logger.info(f"Loaded {len(result.data) if result.data else 0} actual settlement items for {year}-{month}")
        return result.data if result.data else []
    except Exception as e:
        logger.error(f"Failed to load actual settlement items: {e}")
        return []


def upsert_actual_settlement_item(
    store_id: str,
    year: int,
    month: int,
    template_id: str,  # UUID ë¬¸ìì—´
    amount: float = None,
    percent: float = None,
    status: str = 'draft'
):
    """
    ì‹¤ì œì •ì‚° ì›”ë³„ í•­ëª© ê°’ ì €ì¥/ì—…ë°ì´íŠ¸ (upsert)
    Phase C.5: input_typeì— ë”°ë¼ amount ë˜ëŠ” percentë§Œ ì €ì¥ (ë‹¤ë¥¸ ê°’ì€ None ë˜ëŠ” 0)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
        template_id: í…œí”Œë¦¿ ID (cost_item_templates.id)
        amount: ê¸ˆì•¡ (input_type='amount'ì¼ ë•Œ)
        percent: ë¹„ìœ¨ (input_type='rate'ì¼ ë•Œ)
        status: ìƒíƒœ ('draft' | 'final')
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return False
        
        upsert_data = {
            "store_id": store_id,
            "year": int(year),
            "month": int(month),
            "template_id": template_id,  # UUID ë¬¸ìì—´ì´ë¯€ë¡œ int() ë³€í™˜ ì œê±°
            "status": status,
        }
        
        # Phase C.5: input_typeì— ë”°ë¼ ì„ íƒì  ì €ì¥
        # amountê°€ ìˆìœ¼ë©´ amount ì €ì¥, percentëŠ” None (ì˜ë¯¸ ëª…í™•)
        # percentê°€ ìˆìœ¼ë©´ percent ì €ì¥, amountëŠ” None
        if amount is not None:
            upsert_data["amount"] = float(amount)
            upsert_data["percent"] = None  # Phase C.5: ëª…í™•ì„±ì„ ìœ„í•´ None
        elif percent is not None:
            upsert_data["percent"] = float(percent)
            upsert_data["amount"] = None  # Phase C.5: ëª…í™•ì„±ì„ ìœ„í•´ None
        else:
            # ë‘˜ ë‹¤ Noneì´ë©´ 0ìœ¼ë¡œ ì €ì¥ (ê¸°ì¡´ ì •ì±… ìœ ì§€)
            upsert_data["amount"] = 0.0
            upsert_data["percent"] = 0.0
        
        # upsert (store_id, year, month, template_id ê¸°ì¤€)
        supabase.table("actual_settlement_items").upsert(
            upsert_data,
            on_conflict="store_id,year,month,template_id"
        ).execute()
        
        logger.info(f"Actual settlement item saved: {year}-{month}, template_id={template_id}, amount={amount}, percent={percent}")
        return True
    except Exception as e:
        logger.error(f"Failed to upsert actual settlement_item: {e}")
        raise


# ============================================
# Phase D: ì‹¤ì œì •ì‚° - sales í…Œì´ë¸”ì—ì„œ ì›”ë§¤ì¶œ ìë™ ë¶ˆëŸ¬ì˜¤ê¸°
# ============================================

# ============================================
# Phase 4.2-2: ë¹„ìš© êµ¬ì¡° ë° ì†ìµë¶„ê¸°ì  ê³µì‹ ì—”ì§„ í•¨ìˆ˜
# ============================================

@st.cache_data(ttl=60, show_spinner=False)
def get_fixed_costs(store_id: str, year: int, month: int) -> float:
    """
    ê³ ì •ë¹„ ì¡°íšŒ (SSOT ì—”ì§„)
    
    ìš°ì„ ìˆœìœ„:
    1. actual_settlement_items (final ìƒíƒœ) - input_type='amount'ì¸ í•­ëª© í•©ê³„
    2. expense_structure - ì„ì°¨ë£Œ, ì¸ê±´ë¹„, ê³µê³¼ê¸ˆ í•©ê³„
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        float: ê³ ì •ë¹„ í•©ê³„ (ì› ë‹¨ìœ„)
    """
    try:
        # 1ìˆœìœ„: actual_settlement_items (final ìƒíƒœ í™•ì¸)
        month_status = get_month_settlement_status(store_id, year, month)
        if month_status == 'final':
            try:
                total_sales = load_monthly_sales_total(store_id, year, month)
                expense_items = {}
                templates = load_cost_item_templates(store_id)
                saved_items = load_actual_settlement_items(store_id, year, month)
                
                saved_dict = {}
                for saved in saved_items:
                    template_id = saved.get('template_id')
                    if template_id:
                        saved_dict[template_id] = saved
                
                for template in templates:
                    if not template.get('is_active', True):
                        continue
                    category = template.get('category')
                    if not category:
                        continue
                    
                    if category not in expense_items:
                        expense_items[category] = []
                    
                    template_id = template.get('id')
                    saved = saved_dict.get(template_id, {})
                    
                    saved_amount = saved.get('amount')
                    saved_percent = saved.get('percent')
                    has_amount = saved_amount is not None and float(saved_amount or 0) > 0
                    has_percent = saved_percent is not None and float(saved_percent or 0) > 0
                    
                    if has_amount and not has_percent:
                        input_type = 'amount'
                    elif has_percent and not has_amount:
                        input_type = 'rate'
                    elif has_amount and has_percent:
                        input_type = 'amount'
                    else:
                        input_type = 'amount'
                    
                    item = {
                        'template_id': template_id,
                        'item_name': template.get('item_name', ''),
                        'input_type': input_type,
                        'amount': int(saved_amount or 0) if input_type == 'amount' else 0,
                        'rate': float(saved_percent or 0.0) if input_type == 'rate' else 0.0,
                    }
                    expense_items[category].append(item)
                
                # ê³ ì •ë¹„ ì¹´í…Œê³ ë¦¬ (ì„ì°¨ë£Œ, ì¸ê±´ë¹„, ê³µê³¼ê¸ˆ)ì˜ amount í•©ê³„
                fixed_categories = ['ì„ì°¨ë£Œ', 'ì¸ê±´ë¹„', 'ê³µê³¼ê¸ˆ']
                fixed_total = 0.0
                for cat in fixed_categories:
                    if cat in expense_items:
                        for item in expense_items[cat]:
                            if item.get('input_type') == 'amount':
                                fixed_total += float(item.get('amount', 0))
                
                if fixed_total > 0:
                    return fixed_total
            except Exception:
                pass
        
        # 2ìˆœìœ„: expense_structure
        expense_df = load_expense_structure(year, month, store_id)
        if not expense_df.empty:
            fixed_categories = ['ì„ì°¨ë£Œ', 'ì¸ê±´ë¹„', 'ê³µê³¼ê¸ˆ']
            fixed_costs = expense_df[expense_df['category'].isin(fixed_categories)]['amount'].sum()
            return float(fixed_costs)
        
        return 0.0
    except Exception as e:
        logger.error(f"Failed to get fixed costs: {e}")
        return 0.0


@st.cache_data(ttl=60, show_spinner=False)
def get_variable_cost_ratio(store_id: str, year: int, month: int) -> float:
    """
    ë³€ë™ë¹„ìœ¨ ì¡°íšŒ (SSOT ì—”ì§„)
    
    ìš°ì„ ìˆœìœ„:
    1. actual_settlement_items (final ìƒíƒœ) - input_type='rate'ì¸ í•­ëª© í•©ê³„
    2. expense_structure - ì¬ë£Œë¹„, ë¶€ê°€ì„¸&ì¹´ë“œìˆ˜ìˆ˜ë£Œ í•©ê³„
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        float: ë³€ë™ë¹„ìœ¨ (0.0 ~ 1.0, ì†Œìˆ˜ í˜•íƒœ)
    """
    try:
        # 1ìˆœìœ„: actual_settlement_items (final ìƒíƒœ í™•ì¸)
        month_status = get_month_settlement_status(store_id, year, month)
        if month_status == 'final':
            try:
                total_sales = load_monthly_sales_total(store_id, year, month)
                expense_items = {}
                templates = load_cost_item_templates(store_id)
                saved_items = load_actual_settlement_items(store_id, year, month)
                
                saved_dict = {}
                for saved in saved_items:
                    template_id = saved.get('template_id')
                    if template_id:
                        saved_dict[template_id] = saved
                
                for template in templates:
                    if not template.get('is_active', True):
                        continue
                    category = template.get('category')
                    if not category:
                        continue
                    
                    if category not in expense_items:
                        expense_items[category] = []
                    
                    template_id = template.get('id')
                    saved = saved_dict.get(template_id, {})
                    
                    saved_amount = saved.get('amount')
                    saved_percent = saved.get('percent')
                    has_amount = saved_amount is not None and float(saved_amount or 0) > 0
                    has_percent = saved_percent is not None and float(saved_percent or 0) > 0
                    
                    if has_amount and not has_percent:
                        input_type = 'amount'
                    elif has_percent and not has_amount:
                        input_type = 'rate'
                    elif has_amount and has_percent:
                        input_type = 'amount'
                    else:
                        input_type = 'amount'
                    
                    item = {
                        'template_id': template_id,
                        'item_name': template.get('item_name', ''),
                        'input_type': input_type,
                        'amount': int(saved_amount or 0) if input_type == 'amount' else 0,
                        'rate': float(saved_percent or 0.0) if input_type == 'rate' else 0.0,
                    }
                    expense_items[category].append(item)
                
                # ë³€ë™ë¹„ ì¹´í…Œê³ ë¦¬ (ì¬ë£Œë¹„, ë¶€ê°€ì„¸&ì¹´ë“œìˆ˜ìˆ˜ë£Œ)ì˜ rate í•©ê³„
                variable_categories = ['ì¬ë£Œë¹„', 'ë¶€ê°€ì„¸&ì¹´ë“œìˆ˜ìˆ˜ë£Œ']
                variable_rate_total = 0.0
                for cat in variable_categories:
                    if cat in expense_items:
                        for item in expense_items[cat]:
                            if item.get('input_type') == 'rate':
                                variable_rate_total += float(item.get('rate', 0.0))
                
                # %ë¥¼ ì†Œìˆ˜ë¡œ ë³€í™˜
                if variable_rate_total > 0:
                    return variable_rate_total / 100.0
            except Exception:
                pass
        
        # 2ìˆœìœ„: expense_structure
        expense_df = load_expense_structure(year, month, store_id)
        if not expense_df.empty:
            variable_categories = ['ì¬ë£Œë¹„', 'ë¶€ê°€ì„¸&ì¹´ë“œìˆ˜ìˆ˜ë£Œ']
            variable_df = expense_df[expense_df['category'].isin(variable_categories)]
            if not variable_df.empty:
                variable_cost_rate = variable_df['amount'].sum()  # % ë‹¨ìœ„
                return variable_cost_rate / 100.0  # ì†Œìˆ˜ë¡œ ë³€í™˜
        
        return 0.0
    except Exception as e:
        logger.error(f"Failed to get variable cost ratio: {e}")
        return 0.0


@st.cache_data(ttl=60, show_spinner=False)
def calculate_break_even_sales(store_id: str, year: int, month: int) -> float:
    """
    ì†ìµë¶„ê¸°ì  ë§¤ì¶œ ê³„ì‚° (SSOT ì—”ì§„)
    
    ê³µì‹: ê³ ì •ë¹„ / (1 - ë³€ë™ë¹„ìœ¨)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        float: ì†ìµë¶„ê¸°ì  ë§¤ì¶œ (ì› ë‹¨ìœ„), ê³„ì‚° ë¶ˆê°€ ì‹œ 0.0
    """
    try:
        fixed_costs = get_fixed_costs(store_id, year, month)
        variable_ratio = get_variable_cost_ratio(store_id, year, month)
        
        # ê³„ì‚° ì¡°ê±´: ê³ ì •ë¹„ > 0 AND ë³€ë™ë¹„ìœ¨ > 0 AND ë³€ë™ë¹„ìœ¨ < 1
        if fixed_costs > 0 and variable_ratio > 0 and variable_ratio < 1:
            denominator = 1.0 - variable_ratio
            if denominator > 0:
                breakeven = fixed_costs / denominator
                return float(breakeven)
        
        return 0.0
    except Exception as e:
        logger.error(f"Failed to calculate break even sales: {e}")
        return 0.0


# ============================================
# SSOT VIEW ê¸°ë°˜ ì¡°íšŒ í•¨ìˆ˜
# ============================================

@st.cache_data(ttl=60, show_spinner=False)
def load_official_daily_sales(store_id: str = None, start_date: str = None, end_date: str = None):
    """
    ê³µì‹ ë§¤ì¶œ SSOT ì¡°íšŒ (daily_close ê¸°ì¤€)
    
    SSOT ì •ì±…:
    - daily_closeê°€ ê³µì‹ ë§¤ì¶œ SSOT
    - is_official=true, source='daily_close'ë¡œ í‘œì‹œ
    
    Args:
        store_id: ë§¤ì¥ ID (Noneì´ë©´ í˜„ì¬ ë§¤ì¥)
        start_date: ì‹œì‘ì¼ (YYYY-MM-DD, ì„ íƒì‚¬í•­)
        end_date: ì¢…ë£Œì¼ (YYYY-MM-DD, ì„ íƒì‚¬í•­)
    
    Returns:
        pd.DataFrame: ê³µì‹ ë§¤ì¶œ ë°ì´í„° (store_id, date, total_sales, card_sales, cash_sales, visitors, memo, is_official, source)
    """
    try:
        if store_id is None:
            store_id = get_current_store_id()
        if not store_id:
            return pd.DataFrame()
        
        supabase = get_read_client()
        if not supabase:
            return pd.DataFrame()
        
        query = supabase.table("v_daily_sales_official").select("*").eq("store_id", store_id)
        
        if start_date:
            query = query.gte("date", start_date)
        if end_date:
            query = query.lte("date", end_date)
        
        result = query.order("date", desc=False).execute()
        
        if not result.data:
            return pd.DataFrame()
        
        df = pd.DataFrame(result.data)
        logger.info(f"Loaded {len(df)} official daily sales records")
        return df
    except Exception as e:
        logger.error(f"Failed to load official daily sales: {e}")
        return pd.DataFrame()


def get_day_record_status(store_id: str, date) -> dict:
    """
    íŠ¹ì • ë‚ ì§œì˜ ê¸°ë¡ ìƒíƒœ ì¡°íšŒ (ìµœì†Œ ì¿¼ë¦¬)
    
    SSOT ì •ì±…:
    - daily_close ì¡´ì¬ ì—¬ë¶€ (has_close)
    - sales ì¡´ì¬ ì—¬ë¶€ (has_sales)
    - naver_visitors ì¡´ì¬ ì—¬ë¶€ (has_visitors)
    - best_available / official ë·°ì—ì„œ ë§¤ì¶œ/ë°©ë¬¸ì ì¡°íšŒ
    
    Args:
        store_id: ë§¤ì¥ ID
        date: ë‚ ì§œ (datetime.date ë˜ëŠ” str)
    
    Returns:
        dict: {
            has_close: bool,
            has_sales: bool,
            has_visitors: bool,
            best_total_sales: float | None,
            official_total_sales: float | None,
            visitors_best: int | None,
            visitors_official: int | None
        }
    """
    try:
        supabase = get_read_client()
        if not supabase:
            return {
                "has_close": False,
                "has_sales": False,
                "has_visitors": False,
                "best_total_sales": None,
                "official_total_sales": None,
                "visitors_best": None,
                "visitors_official": None
            }
        
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        # 1. daily_close ì¡´ì¬ ì—¬ë¶€ ë° ê°’
        daily_close_result = supabase.table("daily_close")\
            .select("total_sales, visitors")\
            .eq("store_id", store_id)\
            .eq("date", date_str)\
            .limit(1)\
            .execute()
        
        has_close = daily_close_result.data and len(daily_close_result.data) > 0
        official_total_sales = None
        visitors_official = None
        if has_close:
            official_total_sales = float(daily_close_result.data[0].get('total_sales', 0) or 0)
            visitors_official = int(daily_close_result.data[0].get('visitors', 0) or 0)
        
        # 2. sales ì¡´ì¬ ì—¬ë¶€
        sales_result = supabase.table("sales")\
            .select("total_sales")\
            .eq("store_id", store_id)\
            .eq("date", date_str)\
            .limit(1)\
            .execute()
        
        has_sales = sales_result.data and len(sales_result.data) > 0
        
        # 3. naver_visitors ì¡´ì¬ ì—¬ë¶€
        visitors_result = supabase.table("naver_visitors")\
            .select("visitors")\
            .eq("store_id", store_id)\
            .eq("date", date_str)\
            .limit(1)\
            .execute()
        
        has_visitors = visitors_result.data and len(visitors_result.data) > 0
        visitors_best = None
        if has_visitors:
            visitors_best = int(visitors_result.data[0].get('visitors', 0) or 0)
        
        # 4. best_available ë·°ì—ì„œ ë§¤ì¶œ ì¡°íšŒ (daily_close ìš°ì„ , ì—†ìœ¼ë©´ sales)
        best_result = supabase.table("v_daily_sales_best_available")\
            .select("total_sales, visitors")\
            .eq("store_id", store_id)\
            .eq("date", date_str)\
            .limit(1)\
            .execute()
        
        best_total_sales = None
        if best_result.data and len(best_result.data) > 0:
            best_total_sales = float(best_result.data[0].get('total_sales', 0) or 0)
            # best_availableì˜ visitorsëŠ” daily_close ìš°ì„ , ì—†ìœ¼ë©´ naver_visitors
            if 'visitors' in best_result.data[0] and best_result.data[0]['visitors'] is not None:
                visitors_best = int(best_result.data[0]['visitors'] or 0)
        
        return {
            "has_close": has_close,
            "has_sales": has_sales,
            "has_visitors": has_visitors,
            "best_total_sales": best_total_sales,
            "official_total_sales": official_total_sales,
            "visitors_best": visitors_best,
            "visitors_official": visitors_official
        }
    except Exception as e:
        logger.error(f"Failed to get day record status: {e}")
        return {
            "has_close": False,
            "has_sales": False,
            "has_visitors": False,
            "best_total_sales": None,
            "official_total_sales": None,
            "visitors_best": None,
            "visitors_official": None
        }


@st.cache_data(ttl=60, show_spinner=False)
def load_best_available_daily_sales(store_id: str = None, start_date: str = None, end_date: str = None):
    """
    ìµœì„ ì˜ ë§¤ì¶œ ë°ì´í„° ì¡°íšŒ (daily_close ìš°ì„ , ì—†ìœ¼ë©´ sales ì‚¬ìš©)
    
    SSOT ì •ì±…:
    - daily_close ìˆìœ¼ë©´ is_official=true, source='daily_close'
    - salesë§Œ ìˆìœ¼ë©´ is_official=false, source='sales'
    
    Args:
        store_id: ë§¤ì¥ ID (Noneì´ë©´ í˜„ì¬ ë§¤ì¥)
        start_date: ì‹œì‘ì¼ (YYYY-MM-DD, ì„ íƒì‚¬í•­)
        end_date: ì¢…ë£Œì¼ (YYYY-MM-DD, ì„ íƒì‚¬í•­)
    
    Returns:
        pd.DataFrame: ë§¤ì¶œ ë°ì´í„° (store_id, date, total_sales, card_sales, cash_sales, visitors, memo, is_official, source)
    """
    try:
        if store_id is None:
            store_id = get_current_store_id()
        if not store_id:
            return pd.DataFrame()
        
        supabase = get_read_client()
        if not supabase:
            return pd.DataFrame()
        
        query = supabase.table("v_daily_sales_best_available").select("*").eq("store_id", store_id)
        
        if start_date:
            query = query.gte("date", start_date)
        if end_date:
            query = query.lte("date", end_date)
        
        result = query.order("date", desc=False).execute()
        
        if not result.data:
            return pd.DataFrame()
        
        df = pd.DataFrame(result.data)
        logger.info(f"Loaded {len(df)} best available daily sales records")
        return df
    except Exception as e:
        logger.error(f"Failed to load best available daily sales: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60, show_spinner=False)  # 1ë¶„ ìºì‹œ (ì›”ì´ ë°”ë€Œê±°ë‚˜ ì…ë ¥ ì¦‰ì‹œ ë°˜ì˜)
def load_monthly_official_sales_total(store_id: str, year: int, month: int) -> int:
    """
    ê³µì‹ ì›”ë§¤ì¶œ í•©ê³„ ì¡°íšŒ (official ì „ìš©: daily_closeë§Œ)
    
    SSOT ì •ì±…:
    - ë§ˆê°ë¥ /ì—°ì†ë§ˆê°/ê³µì‹ í™•ì • ì§€í‘œì—ë§Œ ì‚¬ìš©
    - ë§ˆê° ì—†ëŠ” ë‚ ì€ ì œì™¸
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        int: ê³µì‹ ì›”ë§¤ì¶œ í•©ê³„ (ì› ë‹¨ìœ„, daily_closeë§Œ)
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return 0
        
        # KST ê¸°ì¤€ ì›” ì‹œì‘/ë ê³„ì‚°
        KST = ZoneInfo("Asia/Seoul")
        start_kst = datetime(year, month, 1, 0, 0, 0, tzinfo=KST)
        
        # ë‹¤ìŒë‹¬ 1ì¼ 0ì‹œ (ë¯¸í¬í•¨)
        if month == 12:
            end_kst = datetime(year + 1, 1, 1, 0, 0, 0, tzinfo=KST)
        else:
            end_kst = datetime(year, month + 1, 1, 0, 0, 0, tzinfo=KST)
        
        # DATE íƒ€ì…ì´ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜ (YYYY-MM-DD)
        start_date_str = start_kst.date().isoformat()
        end_date_str = end_kst.date().isoformat()
        
        # v_daily_sales_official ë·° ì¡°íšŒ: store_id + ë‚ ì§œ ë²”ìœ„ í•„í„°
        # date >= start_date AND date < end_date
        result = supabase.table("v_daily_sales_official")\
            .select("total_sales")\
            .eq("store_id", store_id)\
            .gte("date", start_date_str)\
            .lt("date", end_date_str)\
            .execute()
        
        # í•©ì‚° (total_sales ì»¬ëŸ¼ ì‚¬ìš©)
        if result.data:
            total = sum(float(row.get('total_sales', 0) or 0) for row in result.data)
            row_count = len(result.data)
            logger.info(f"Monthly official sales total loaded: {year}-{month}, {row_count} rows, total={total:,.0f}ì›")
            return int(total)
        else:
            logger.info(f"Monthly official sales total loaded: {year}-{month}, 0 rows, total=0ì›")
            return 0
    except Exception as e:
        logger.error(f"Failed to load monthly official sales total: {e}")
        return 0


@st.cache_data(ttl=60, show_spinner=False)  # 1ë¶„ ìºì‹œ (ì›”ì´ ë°”ë€Œê±°ë‚˜ ì…ë ¥ ì¦‰ì‹œ ë°˜ì˜)
def load_monthly_sales_total(store_id: str, year: int, month: int) -> int:
    """
    ì›”ë§¤ì¶œ í•©ê³„ ì¡°íšŒ (best_available ê¸°ë°˜: daily_close ìš°ì„ , ì—†ìœ¼ë©´ sales)
    
    SSOT ì •ì±…:
    - í†µê³„/ë¶„ì„/KPIëŠ” best_available ì‚¬ìš© (ë§ˆê° ì—†ëŠ” ë‚ ë„ í¬í•¨)
    - is_official=falseì¸ ë‚ ì§œëŠ” ë¯¸ë§ˆê° ë°ì´í„°ë¡œ í‘œì‹œ
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        int: ì›”ë§¤ì¶œ í•©ê³„ (ì› ë‹¨ìœ„)
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return 0
        
        # KST ê¸°ì¤€ ì›” ì‹œì‘/ë ê³„ì‚°
        KST = ZoneInfo("Asia/Seoul")
        start_kst = datetime(year, month, 1, 0, 0, 0, tzinfo=KST)
        
        # ë‹¤ìŒë‹¬ 1ì¼ 0ì‹œ (ë¯¸í¬í•¨)
        if month == 12:
            end_kst = datetime(year + 1, 1, 1, 0, 0, 0, tzinfo=KST)
        else:
            end_kst = datetime(year, month + 1, 1, 0, 0, 0, tzinfo=KST)
        
        # DATE íƒ€ì…ì´ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜ (YYYY-MM-DD)
        start_date_str = start_kst.date().isoformat()
        end_date_str = end_kst.date().isoformat()
        
        # v_daily_sales_best_available ë·° ì¡°íšŒ: store_id + ë‚ ì§œ ë²”ìœ„ í•„í„°
        # date >= start_date AND date < end_date
        result = supabase.table("v_daily_sales_best_available")\
            .select("total_sales, is_official")\
            .eq("store_id", store_id)\
            .gte("date", start_date_str)\
            .lt("date", end_date_str)\
            .execute()
        
        # í•©ì‚° (total_sales ì»¬ëŸ¼ ì‚¬ìš©)
        if result.data:
            total = sum(float(row.get('total_sales', 0) or 0) for row in result.data)
            row_count = len(result.data)
            # ë¯¸ë§ˆê° ë‚ ì§œ ê°œìˆ˜ ê³„ì‚° (is_official=false)
            unofficial_count = sum(1 for row in result.data if not row.get('is_official', True))
            logger.info(f"Monthly sales total loaded (best_available): {year}-{month}, {row_count} rows, total={total:,.0f}ì›, unofficial={unofficial_count} days")
            return int(total)
        else:
            logger.info(f"Monthly sales total loaded (best_available): {year}-{month}, 0 rows, total=0ì›")
            return 0
    except Exception as e:
        logger.error(f"Failed to load monthly sales total: {e}")
        return 0


@st.cache_data(ttl=60, show_spinner=False)
def count_unofficial_days_in_month(store_id: str, year: int, month: int) -> int:
    """
    í•´ë‹¹ ì›”ì˜ ë¯¸ë§ˆê° ë‚ ì§œ ê°œìˆ˜ ì¡°íšŒ (is_official=false)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        int: ë¯¸ë§ˆê° ë‚ ì§œ ê°œìˆ˜
    """
    try:
        supabase = get_read_client()
        if not supabase:
            return 0
        
        # KST ê¸°ì¤€ ì›” ì‹œì‘/ë ê³„ì‚°
        KST = ZoneInfo("Asia/Seoul")
        start_kst = datetime(year, month, 1, 0, 0, 0, tzinfo=KST)
        if month == 12:
            end_kst = datetime(year + 1, 1, 1, 0, 0, 0, tzinfo=KST)
        else:
            end_kst = datetime(year, month + 1, 1, 0, 0, 0, tzinfo=KST)
        
        start_date_str = start_kst.date().isoformat()
        end_date_str = end_kst.date().isoformat()
        
        # v_daily_sales_best_availableì—ì„œ is_official=falseì¸ ë‚ ì§œ ê°œìˆ˜
        result = supabase.table("v_daily_sales_best_available")\
            .select("date, is_official")\
            .eq("store_id", store_id)\
            .gte("date", start_date_str)\
            .lt("date", end_date_str)\
            .execute()
        
        if result.data:
            unofficial_count = sum(1 for row in result.data if not row.get('is_official', True))
            return unofficial_count
        return 0
    except Exception as e:
        logger.error(f"Failed to count unofficial days: {e}")
        return 0


# ============================================
# Phase F: ì‹¤ì œì •ì‚° í™•ì •(Final) + ì ê¸ˆ(ì½ê¸°ì „ìš©) + í™•ì • í•´ì œ
# ============================================

@st.cache_data(ttl=10, show_spinner=False)  # 10ì´ˆ ìºì‹œ (ë” ì§§ê²Œ ì„¤ì •í•˜ì—¬ ë¹ ë¥¸ ë°˜ì˜)
def get_month_settlement_status(store_id: str, year: int, month: int) -> str:
    """
    ì›”ë³„ ì •ì‚° ìƒíƒœ ì¡°íšŒ (draft | final)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        str: 'draft' ë˜ëŠ” 'final'
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return 'draft'
        
        # status='final'ì´ 1ê°œë¼ë„ ìˆìœ¼ë©´ 'final', ì•„ë‹ˆë©´ 'draft'
        # count='exact' ëŒ€ì‹  ë‹¨ìˆœ selectë¡œ ë³€ê²½ (ë” ë¹ ë¦„)
        result = supabase.table("actual_settlement_items")\
            .select("status")\
            .eq("store_id", store_id)\
            .eq("year", int(year))\
            .eq("month", int(month))\
            .eq("status", "final")\
            .limit(1)\
            .execute()
        
        # finalì´ 1ê°œë¼ë„ ìˆìœ¼ë©´ 'final'
        if result.data and len(result.data) > 0:
            logger.info(f"Month settlement status: {year}-{month} = final")
            return 'final'
        else:
            logger.info(f"Month settlement status: {year}-{month} = draft")
            return 'draft'
    except Exception as e:
        logger.error(f"Failed to get month settlement status: {e}")
        return 'draft'  # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ì€ draft


def set_month_settlement_status(store_id: str, year: int, month: int, status: str) -> int:
    """
    ì›”ë³„ ì •ì‚° ìƒíƒœ ì„¤ì • (draft | final)
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
        status: 'draft' ë˜ëŠ” 'final'
    
    Returns:
        int: ì—…ë°ì´íŠ¸ëœ row count
    """
    if status not in ['draft', 'final']:
        raise ValueError(f"Invalid status: {status}. Must be 'draft' or 'final'")
    
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return 0
        
        # ì›” ì „ì²´ ì¼ê´„ ì—…ë°ì´íŠ¸
        # updated_atì€ PostgreSQLì˜ DEFAULT NOW() íŠ¸ë¦¬ê±° ë˜ëŠ” ìˆ˜ë™ ì„¤ì •
        # SupabaseëŠ” updated_at ìë™ ê°±ì‹ ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
        from datetime import datetime, timezone
        result = supabase.table("actual_settlement_items")\
            .update({
                "status": status,
                "updated_at": datetime.now(timezone.utc).isoformat()
            })\
            .eq("store_id", store_id)\
            .eq("year", int(year))\
            .eq("month", int(month))\
            .execute()
        
        affected_count = len(result.data) if result.data else 0
        logger.info(f"Month settlement status updated: {year}-{month} = {status}, affected={affected_count} rows")
        
        # ìºì‹œ ë¬´íš¨í™”
        try:
            get_month_settlement_status.clear()
            # load_actual_settlement_itemsëŠ” í•¨ìˆ˜ê°€ ì•„ë‹ˆë¯€ë¡œ ì§ì ‘ clear ë¶ˆê°€
            # ëŒ€ì‹  ìºì‹œ í‚¤ ê¸°ë°˜ìœ¼ë¡œ ë¬´íš¨í™” (í•„ìš” ì‹œ)
        except Exception:
            pass
        
        return affected_count
    except Exception as e:
        logger.error(f"Failed to set month settlement status: {e}")
        raise


# ============================================
# Phase H: ì‹¤ì œì •ì‚° ì›”ë³„ íˆìŠ¤í† ë¦¬
# ============================================

@st.cache_data(ttl=60, show_spinner=False)
def load_available_settlement_months(store_id: str, limit: int = 12) -> list:
    """
    ì‹¤ì œì •ì‚°ì´ ì‘ì„±ëœ ì›” ëª©ë¡ ì¡°íšŒ (ìµœì‹ ìˆœ)
    
    Args:
        store_id: ë§¤ì¥ ID
        limit: ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸ê°’: 12)
    
    Returns:
        list: [(year, month), ...] ìµœì‹ ìˆœ
    """
    try:
        supabase = get_read_client()
        if not supabase:
            logger.warning("Supabase client not available")
            return []
        
        # actual_settlement_itemsì—ì„œ year, month distinct ì¡°íšŒ
        result = supabase.table("actual_settlement_items")\
            .select("year, month")\
            .eq("store_id", store_id)\
            .order("year", desc=True)\
            .order("month", desc=True)\
            .execute()
        
        if not result.data:
            return []
        
        # distinct ì²˜ë¦¬ (set ì‚¬ìš©)
        seen = set()
        months = []
        for row in result.data:
            year = int(row.get('year', 0))
            month = int(row.get('month', 0))
            if year > 0 and month > 0:
                key = (year, month)
                if key not in seen:
                    seen.add(key)
                    months.append(key)
                    if len(months) >= limit:
                        break
        
        logger.info(f"Available settlement months loaded: {len(months)} months for store {store_id}")
        return months
    except Exception as e:
        logger.error(f"Failed to load available settlement months: {e}")
        return []


@st.cache_data(ttl=60, show_spinner=False)
def load_monthly_settlement_snapshot(store_id: str, year: int, month: int) -> dict:
    """
    Phase H.1: ì›”ë³„ ì‹¤ì œì •ì‚° ìŠ¤ëƒ…ìƒ· (íˆìŠ¤í† ë¦¬ìš© ê²½ëŸ‰ ë°ì´í„°)
    
    ì¤‘ìš”: ì´ í•¨ìˆ˜ëŠ” DB ê¸°ë°˜ìœ¼ë¡œë§Œ ê³„ì‚°í•©ë‹ˆë‹¤. session_stateë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - actual_settlement_items í…Œì´ë¸”ì—ì„œ ì €ì¥ëœ ê°’ ì¡°íšŒ
    - cost_item_templates í…Œì´ë¸”ì—ì„œ í…œí”Œë¦¿ ì¡°íšŒ
    - sales í…Œì´ë¸”ì—ì„œ ì›” ë§¤ì¶œ í•©ê³„ ì¡°íšŒ
    
    Args:
        store_id: ë§¤ì¥ ID
        year: ì—°ë„
        month: ì›”
    
    Returns:
        dict: {
            'status': 'draft' | 'final',
            'total_sales': int,
            'total_cost': float,
            'operating_profit': float,
            'profit_margin': float,
            'expense_items': dict  # ê³„ì‚°ìš©
        }
    """
    try:
        # Phase F: ìƒíƒœ ì¡°íšŒ (DB ê¸°ë°˜)
        month_status = get_month_settlement_status(store_id, year, month)
        
        # Phase D: ë§¤ì¶œ ì¡°íšŒ (DB ê¸°ë°˜, sales í…Œì´ë¸”)
        total_sales = load_monthly_sales_total(store_id, year, month)
        
        # Phase H.1: ë¹„ìš© í•­ëª© ë¡œë“œ (DB ê¸°ë°˜, session_state ì‚¬ìš© ì•ˆ í•¨)
        # actual_settlement_items + cost_item_templatesì—ì„œë§Œ ë¡œë“œ
        expense_items = {}
        templates = load_cost_item_templates(store_id)
        saved_items = load_actual_settlement_items(store_id, year, month)
        
        # saved_itemsë¥¼ template_id ê¸°ì¤€ìœ¼ë¡œ dictë¡œ ë³€í™˜
        saved_dict = {}
        for saved in saved_items:
            template_id = saved.get('template_id')
            if template_id:
                saved_dict[template_id] = saved
        
        # í…œí”Œë¦¿ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        for template in templates:
            if not template.get('is_active', True):
                continue
            
            category = template.get('category')
            if not category:
                continue
            
            if category not in expense_items:
                expense_items[category] = []
            
            template_id = template.get('id')
            saved = saved_dict.get(template_id, {})
            
            # input_type ì¶”ë¡ 
            saved_amount = saved.get('amount')
            saved_percent = saved.get('percent')
            has_amount = saved_amount is not None and float(saved_amount or 0) > 0
            has_percent = saved_percent is not None and float(saved_percent or 0) > 0
            
            if has_amount and not has_percent:
                input_type = 'amount'
            elif has_percent and not has_amount:
                input_type = 'rate'
            elif has_amount and has_percent:
                input_type = 'amount'  # amount ìš°ì„ 
            else:
                # ê¸°ë³¸ê°’: ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ê°’ (ì„ì°¨ë£Œ/ì¬ë£Œë¹„/ì¸ê±´ë¹„/ê³µê³¼ê¸ˆ/ë¶€ê°€ì„¸&ì¹´ë“œìˆ˜ìˆ˜ë£Œ)
                input_type = 'amount'
            
            item = {
                'template_id': template_id,
                'item_name': template.get('item_name', ''),
                'input_type': input_type,
                'amount': int(saved_amount or 0) if input_type == 'amount' else 0,
                'rate': float(saved_percent or 0.0) if input_type == 'rate' else 0.0,
            }
            expense_items[category].append(item)
        
        # Phase H: ì´ê³„ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
        # _calculate_totals í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë™ì¼í•œ ë¡œì§ êµ¬í˜„
        category_totals = {}
        for cat, items in expense_items.items():
            category_total = 0.0
            for item in items:
                input_type = item.get('input_type', 'amount')
                if input_type == 'amount':
                    used_amount = float(item.get('amount', 0))
                else:
                    rate = item.get('rate', 0.0)
                    used_amount = (float(total_sales) * rate / 100) if total_sales > 0 else 0.0
                category_total += used_amount
            category_totals[cat] = category_total
        
        total_cost = sum(category_totals.values())
        operating_profit = float(total_sales) - total_cost
        profit_margin = (operating_profit / float(total_sales) * 100) if total_sales > 0 else 0.0
        
        return {
            'status': month_status,
            'total_sales': total_sales,
            'total_cost': total_cost,
            'operating_profit': operating_profit,
            'profit_margin': profit_margin,
            'expense_items': expense_items,  # ì„±ì í‘œ í‰ê°€ìš©
        }
    except Exception as e:
        logger.error(f"Failed to load monthly settlement snapshot: {e}")
        return {
            'status': 'draft',
            'total_sales': 0,
            'total_cost': 0.0,
            'operating_profit': 0.0,
            'profit_margin': 0.0,
            'expense_items': {},
        }


# ============================================
# PHASE 10 / STEP 10-4: ì„¤ê³„ ë°ì´í„° DBí™” í•¨ìˆ˜
# ============================================

def load_menu_role_tags(store_id: str) -> dict:
    """
    ë©”ë‰´ë³„ ì—­í•  íƒœê·¸ ì¡°íšŒ (DB)
    
    Args:
        store_id: ë§¤ì¥ ID
    
    Returns:
        dict: {menu_id: role_tag} í˜•íƒœ
        ì˜ˆ: {'uuid-1': 'ë¯¸ë¼', 'uuid-2': 'ë³¼ë¥¨', ...}
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return {}
    
    if not store_id:
        return {}
    
    try:
        result = supabase.table("menu_portfolio_state").select("menu_id,role_tag").eq("store_id", store_id).execute()
        if result.data:
            return {item['menu_id']: item['role_tag'] for item in result.data if item.get('role_tag')}
        return {}
    except Exception as e:
        logger.error(f"Failed to load menu role tags: {e}")
        if _is_dev_mode():
            import streamlit as st
            st.error(f"ë©”ë‰´ ì—­í•  íƒœê·¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def upsert_menu_role_tag(store_id: str, menu_id: str, role_tag: str) -> bool:
    """
    ë©”ë‰´ ì—­í•  íƒœê·¸ ì €ì¥/ìˆ˜ì • (DB)
    
    Args:
        store_id: ë§¤ì¥ ID
        menu_id: ë©”ë‰´ ID (UUID)
        role_tag: ì—­í•  íƒœê·¸ ('ë¯¸ë¼', 'ë³¼ë¥¨', 'ë§ˆì§„' ë˜ëŠ” None)
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    if not store_id or not menu_id:
        return False
    
    try:
        # role_tagê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì´ë©´ ì‚­ì œ (NULLë¡œ ì„¤ì •)
        data = {
            "store_id": store_id,
            "menu_id": menu_id,
            "role_tag": role_tag if role_tag and role_tag != "ë¯¸ë¶„ë¥˜" else None
        }
        
        supabase.table("menu_portfolio_state").upsert(
            data,
            on_conflict="store_id,menu_id"
        ).execute()
        
        logger.info(f"Menu role tag upserted: {menu_id} -> {role_tag}")
        return True
    except Exception as e:
        logger.error(f"Failed to upsert menu role tag: {e}")
        if _is_dev_mode():
            import streamlit as st
            st.error(f"ë©”ë‰´ ì—­í•  íƒœê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def load_ingredient_structure_state(store_id: str) -> dict:
    """
    ì¬ë£Œë³„ ì„¤ê³„ ìƒíƒœ ì¡°íšŒ (DB)
    
    Args:
        store_id: ë§¤ì¥ ID
    
    Returns:
        dict: {ingredient_id: {is_substitutable, order_type, substitute_memo, strategy_memo}} í˜•íƒœ
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return {}
    
    if not store_id:
        return {}
    
    try:
        result = supabase.table("ingredient_structure_state").select(
            "ingredient_id,is_substitutable,order_type,substitute_memo,strategy_memo"
        ).eq("store_id", store_id).execute()
        
        if result.data:
            return {
                item['ingredient_id']: {
                    'is_substitutable': item.get('is_substitutable'),
                    'order_type': item.get('order_type'),
                    'substitute_memo': item.get('substitute_memo'),
                    'strategy_memo': item.get('strategy_memo')
                }
                for item in result.data
            }
        return {}
    except Exception as e:
        logger.error(f"Failed to load ingredient structure state: {e}")
        if _is_dev_mode():
            import streamlit as st
            st.error(f"ì¬ë£Œ ì„¤ê³„ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def upsert_ingredient_structure_state(
    store_id: str,
    ingredient_id: str,
    is_substitutable: Optional[bool] = None,
    order_type: Optional[str] = None,
    substitute_memo: Optional[str] = None,
    strategy_memo: Optional[str] = None
) -> bool:
    """
    ì¬ë£Œ ì„¤ê³„ ìƒíƒœ ì €ì¥/ìˆ˜ì • (DB)
    
    Args:
        store_id: ë§¤ì¥ ID
        ingredient_id: ì¬ë£Œ ID (UUID)
        is_substitutable: ëŒ€ì²´ ê°€ëŠ¥ ì—¬ë¶€
        order_type: ë°œì£¼ ìœ í˜• ('single', 'multi', 'unset')
        substitute_memo: ëŒ€ì²´ ë©”ëª¨
        strategy_memo: ì „ëµ ë©”ëª¨
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    if not store_id or not ingredient_id:
        return False
    
    try:
        # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (ë¶€ë¶„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´)
        existing = supabase.table("ingredient_structure_state").select("*").eq("store_id", store_id).eq("ingredient_id", ingredient_id).execute()
        
        data = {
            "store_id": store_id,
            "ingredient_id": ingredient_id
        }
        
        # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê¸°ì¡´ ê°’ ìœ ì§€, ì—†ìœ¼ë©´ ìƒˆ ê°’ ì‚¬ìš©
        if existing.data:
            existing_data = existing.data[0]
            data['is_substitutable'] = is_substitutable if is_substitutable is not None else existing_data.get('is_substitutable')
            data['order_type'] = order_type if order_type is not None else existing_data.get('order_type')
            data['substitute_memo'] = substitute_memo if substitute_memo is not None else existing_data.get('substitute_memo')
            data['strategy_memo'] = strategy_memo if strategy_memo is not None else existing_data.get('strategy_memo')
        else:
            data['is_substitutable'] = is_substitutable
            data['order_type'] = order_type
            data['substitute_memo'] = substitute_memo
            data['strategy_memo'] = strategy_memo
        
        # order_type ë³€í™˜ (í•œê¸€ -> ì˜ë¬¸)
        if data.get('order_type') == 'ë‹¨ì¼':
            data['order_type'] = 'single'
        elif data.get('order_type') == 'ë³µìˆ˜':
            data['order_type'] = 'multi'
        elif data.get('order_type') == 'ë¯¸ì„¤ì •':
            data['order_type'] = 'unset'
        
        supabase.table("ingredient_structure_state").upsert(
            data,
            on_conflict="store_id,ingredient_id"
        ).execute()
        
        logger.info(f"Ingredient structure state upserted: {ingredient_id}")
        return True
    except Exception as e:
        logger.error(f"Failed to upsert ingredient structure state: {e}")
        if _is_dev_mode():
            import streamlit as st
            st.error(f"ì¬ë£Œ ì„¤ê³„ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def upsert_design_routine_log(store_id: str, routine_type: str, period_key: str) -> bool:
    """
    ì„¤ê³„ ë£¨í‹´ ë¡œê·¸ ì €ì¥ (DB)
    
    Args:
        store_id: ë§¤ì¥ ID
        routine_type: ë£¨í‹´ íƒ€ì… ('weekly_design_check', 'monthly_structure_review')
        period_key: ê¸°ê°„ í‚¤ (ì˜ˆ: '2026-W04', '2026-01')
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return False
    
    if not store_id:
        return False
    
    try:
        supabase.table("design_routine_log").upsert(
            {
                "store_id": store_id,
                "routine_type": routine_type,
                "period_key": period_key
            },
            on_conflict="store_id,routine_type,period_key"
        ).execute()
        
        logger.info(f"Design routine log upserted: {routine_type} / {period_key}")
        return True
    except Exception as e:
        logger.error(f"Failed to upsert design routine log: {e}")
        if _is_dev_mode():
            import streamlit as st
            st.error(f"ì„¤ê³„ ë£¨í‹´ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def load_design_routine_logs(store_id: str, routine_type: Optional[str] = None, limit: int = 10) -> list:
    """
    ì„¤ê³„ ë£¨í‹´ ë¡œê·¸ ì¡°íšŒ (DB)
    
    Args:
        store_id: ë§¤ì¥ ID
        routine_type: ë£¨í‹´ íƒ€ì… í•„í„° (ì„ íƒ, Noneì´ë©´ ì „ì²´)
        limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜
    
    Returns:
        list: ë£¨í‹´ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
    """
    supabase = _check_supabase_for_dev_mode()
    if not supabase:
        return []
    
    if not store_id:
        return []
    
    try:
        query = supabase.table("design_routine_log").select("*").eq("store_id", store_id).order("completed_at", desc=True).limit(limit)
        
        if routine_type:
            query = query.eq("routine_type", routine_type)
        
        result = query.execute()
        return result.data if result.data else []
    except Exception as e:
        logger.error(f"Failed to load design routine logs: {e}")
        if _is_dev_mode():
            import streamlit as st
            st.error(f"ì„¤ê³„ ë£¨í‹´ ë¡œê·¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []
